{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBpHNI3wthDr"
      },
      "source": [
        "<center><h1 style=\"text-align: center;\"><u>TFM - Detección temprana del cáncer a partir de los resultados de análisis de sangre</u></h1>\n",
        "<center><img src=\"https://nachocarnes.es/wp-content/uploads/2018/04/ejWGXui6_400x400.png\" alt=\"Drawing\" style=\"align=left\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# INTRODUCCIÓN\n",
        "\n",
        "En este notebook se lleva a cabo el contraste del modelo CancerA1DE para la detección prematura de cáncer frente a otros modelos de predicción.\n",
        "\n",
        "El artículo sobre el que se basa esta investigación es \"Early Cancer Detection from Multianalyte Blood Test Results\" presente en : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6548890/\n",
        "\n",
        "El contenido abarca un repaso de los datos, su análisis a todos los niveles y los diferentes enfoques para entrenar, validar y testear los distintos modelos.\n",
        "\n",
        "Los datos se encontrarán en la siguiente ruta en local : C:\\Users\\danie\\OneDrive\\Documentos\\Master\\Lusku\\TFM\\Proposiciones\\Deteccion Cancer\\Datos\n",
        "\n",
        "IMPORTANTE : Cada vez que tenga que rellenarse a mano el valor de una variable, se mostrará con : \n",
        "\n",
        "                    (I) Introducir valor de 'nombreDeLaVariable'\n",
        "\n",
        "Para descargar las librerías usadas en este proyecto se puede hacer usar el comando \"pip install -r requirements.txt\" en el terminal\n",
        "\n",
        "Los bloques de código que empiezan por # P , forman parte del proceso principal y son necesarios ejecutarse para seguir el flujo del proceso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# P\n",
        "# Carga de librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import normaltest\n",
        "\n",
        "# Entrenar el modelo\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Selección de las variables por tipo\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Modelos\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, adjusted_rand_score, r2_score, silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "# Conversion del dataFrame a tipo numeric\n",
        "def convert_to_numeric(column):\n",
        "    if column.dtype in ['object','category']:\n",
        "        # Verificar si hay letras en todos los registros\n",
        "        contains_letters = any(isinstance(val, str) and any(c.isalpha() for c in val) for val in column)\n",
        "        if not contains_letters :\n",
        "            return pd.to_numeric(column, errors='coerce')\n",
        "    return column\n",
        "\n",
        "def discretizar_df_arboles_1(df, max_depth=40, n_bins=18, rango_discretizacion=(-np.inf, np.inf)):\n",
        "    df_discretizado = pd.DataFrame()\n",
        "    \n",
        "    # Iterar sobre todas las columnas del dataframe original\n",
        "    for columna in df.columns:\n",
        "        if df[columna].dtype.kind in 'biufc' or columna.name == 'Tumor type': # (CHULO) Comprueba si el tipo de datos de la columna es numérico ('b' para booleano, 'i' para entero, 'u' para sin signo, 'f' para flotante o 'c' para complejo)\n",
        "            # Si la columna es numérica, realizar la discretización\n",
        "            dt = DecisionTreeRegressor(max_depth=max_depth)\n",
        "            dt.fit(df[columna].values.reshape(-1, 1), df[columna])\n",
        "            puntos_corte = dt.tree_.threshold[dt.tree_.threshold != -2] # Extrae los puntos de corte del árbol de decisión para la columna numérica específica, ignorando aquellos puntos de corte asociados con nodos hoja (-2)\n",
        "            puntos_corte = np.sort(puntos_corte)\n",
        "            puntos_corte = np.concatenate(([rango_discretizacion[0]], puntos_corte, [rango_discretizacion[1]]))\n",
        "            df_discretizado[f'{columna}'] = pd.cut(df[columna], bins=puntos_corte, labels=range(len(puntos_corte)-1))\n",
        "        else:\n",
        "            # Si la columna no es numérica, simplemente copiarla al dataframe resultante\n",
        "            df_discretizado[columna] = df[columna]\n",
        "            \n",
        "    return df_discretizado.apply(convert_to_numeric)\n",
        "\n",
        "# Discretizar dataFrame y mostrar correlación respecto a la variable objetivo\n",
        "def discretizar_df_arboles(df, imprimir=\"SI\", max_depth=15, rango_discretizacion=(-np.inf, np.inf)):\n",
        "    df_discretizado = pd.DataFrame()\n",
        "    \n",
        "    # Iterar sobre todas las columnas del dataframe original\n",
        "    for columna in df.select_dtypes(include=['number']).columns:\n",
        "        if df[columna].dtype.kind in 'biufc' or columna.name != 'Tumor type': # (CHULO) Comprueba si el tipo de datos de la columna es numérico ('b' para booleano, 'i' para entero, 'u' para sin signo, 'f' para flotante o 'c' para complejo)\n",
        "            # Si la columna es numérica, realizar la discretización\n",
        "            dt = DecisionTreeRegressor(max_depth=max_depth)\n",
        "            dt.fit(df[columna].values.reshape(-1, 1), df[columna])\n",
        "            puntos_corte = dt.tree_.threshold[dt.tree_.threshold != -2] # Extrae los puntos de corte del árbol de decisión para la columna numérica específica, ignorando aquellos puntos de corte asociados con nodos hoja (-2)\n",
        "            puntos_corte = np.sort(puntos_corte)\n",
        "            puntos_corte = np.concatenate(([rango_discretizacion[0]], puntos_corte, [rango_discretizacion[1]]))\n",
        "            # print(f\"\\t Columna : {columna} \\n Puntos de Corte : \\n {puntos_corte}\")\n",
        "            df_discretizado[f'{columna}'] = pd.cut(df[columna], bins=puntos_corte, labels=range(len(puntos_corte)-1))\n",
        "        else:\n",
        "            # Si la columna no es numérica, simplemente copiarla al dataframe resultante\n",
        "            df_discretizado[columna] = df[columna]\n",
        "            \n",
        "   # Calcular el coeficiente de correlación entre las variables numéricas discretas y la variable objetivo binaria\n",
        "    correlaciones_discretas = df_discretizado.corrwith(df_discretizado['Tumor type'])\n",
        "\n",
        "    # Ordenar las correlaciones de mayor a menor\n",
        "    correlaciones_discretas_ordenadas = correlaciones_discretas.abs().sort_values(ascending=False)\n",
        "\n",
        "    # Obtener las top 20 variables numéricas discretas con las correlaciones más altas\n",
        "    top_20_correlaciones_discretas = correlaciones_discretas_ordenadas.nlargest(20)\n",
        "\n",
        "    if imprimir == \"SI\":\n",
        "        # Imprimir las top 20 correlaciones\n",
        "        print(top_20_correlaciones_discretas)\n",
        "\n",
        "    return df_discretizado\n",
        "\n",
        "\n",
        "def escalado_dataFrame(df) :\n",
        "    if df.empty:\n",
        "        raise ValueError(\"El DataFrame está vacío, no se puede realizar el escalado.\")\n",
        "\n",
        "    # Crear un objeto StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Normalizar df_imputacion_iterativa\n",
        "    df_normalized = df.select_dtypes(include=['number']).copy()  # Crear una copia del DataFrame original\n",
        "    \n",
        "    if not df_normalized.empty:\n",
        "        df_normalized[df_normalized.columns] = scaler.fit_transform(df_normalized)\n",
        "    else :\n",
        "        print(\"Esto está vacío\")\n",
        "    return df_normalized\n",
        "\n",
        "def calcular_ganancia_informacion(df_features, target, imprimir = 'SI'):\n",
        "    \n",
        "    # Extraer las características de interés del DataFrame\n",
        "    X_interest = df_features.values\n",
        "    \n",
        "    # Extraer la variable objetivo del DataFrame principal\n",
        "    y = target.values\n",
        "    \n",
        "    # Calcular la Ganancia de Información utilizando Mutual Information\n",
        "    information_gain = mutual_info_classif(X_interest, y, discrete_features=False, random_state=42, n_neighbors=7)\n",
        "    \n",
        "    # Crear un DataFrame para visualizar los resultados\n",
        "    ig_results = pd.DataFrame({'Feature': df_features.columns, 'Information Gain': information_gain})\n",
        "    \n",
        "    # Ordenar los resultados por Ganancia de Información en orden descendente\n",
        "    ig_results_sorted = ig_results.sort_values(by='Information Gain', ascending=False)\n",
        "\n",
        "    if imprimir == \"SI\":\n",
        "        print(ig_results_sorted)\n",
        "\n",
        "# División del conjunto de datos en entrenamiento, validacion y test \n",
        "\n",
        "\n",
        "def split_data(X, y, train_size=0.6, val_size=0.2, test_size=0.2, random_state=None):\n",
        "    \"\"\"\n",
        "    Divide un conjunto de datos en entrenamiento, validación y test.\n",
        "\n",
        "    Args:\n",
        "        X: Matriz de características.\n",
        "        y: Vector de etiquetas.\n",
        "        train_size: Porcentaje de datos para entrenamiento (por defecto: 0.6).\n",
        "        val_size: Porcentaje de datos para validación (por defecto: 0.2).\n",
        "        test_size: Porcentaje de datos para test (por defecto: 0.2).\n",
        "        random_state: Semilla para la aleatorización (por defecto: None).\n",
        "\n",
        "    Returns:\n",
        "        Tuple: (X_train, X_val, X_test, y_train, y_val, y_test).\n",
        "    \"\"\"\n",
        "    assert train_size + val_size + test_size == 1.0, \"La suma de train_size, val_size y test_size debe ser igual a 1.0\"\n",
        "\n",
        "    # Dividir los datos en entrenamiento y test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Calcular porcentaje respecto al tamaño original\n",
        "    val_size_relative = val_size / (1.0 - test_size)\n",
        "\n",
        "    # Dividir los datos de entrenamiento en entrenamiento y validación\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size_relative, random_state=random_state)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "def mostrar_cross_validation(model, X_train, y_train):\n",
        "    cv_scores = cross_val_score(\n",
        "                estimator = model,\n",
        "                X         = X_train,\n",
        "                y         = y_train,\n",
        "                scoring   = 'neg_root_mean_squared_error',\n",
        "                cv        = 5\n",
        "            )\n",
        "    print(\"Cross validation : \")\n",
        "    print(f\"Métricas validación cruzada: {cv_scores}\")\n",
        "    print(f\"Média métricas de validación cruzada: {cv_scores.mean()}\")\n",
        "    print(\"\")\n",
        "\n",
        "def mostrar_score(X_train, y_train, model):\n",
        "    score = round(model.score(X_train, y_train), 3)*100\n",
        "    print(f\"Tanto por ciento de acierto : {score} %\")\n",
        "    print(\"\")\n",
        "\n",
        "def mostrar_estadisticas(y_val, y_pred) :\n",
        "    mse = round(mean_squared_error(y_val, y_pred),3)\n",
        "    accuracy = round(accuracy_score(y_val, y_pred),3)\n",
        "    precision = round(precision_score(y_val, y_pred),3)\n",
        "    recall = round(recall_score(y_val, y_pred),3)\n",
        "    f1 = round(f1_score(y_val, y_pred),3)\n",
        "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1-score:\", f1)\n",
        "    print(\"Error cuadrático medio en el conjunto de validación:\", mse)\n",
        "    print(\"Matriz de Confusión :\\n\", conf_matrix)\n",
        "    print(\"\")\n",
        "\n",
        "def mostrar_curva_ROC(y_val, y_pred) :\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
        "\n",
        "    # Calcular el área bajo la curva ROC (AUC)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plotear la curva ROC\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Tasa de Falsos Positivos')\n",
        "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "    plt.title('Curva ROC')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    \n",
        "def evaluate_model(model, X, y, set_name):\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred)\n",
        "    recall = recall_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    print(f\"Metrics for {set_name} set:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Función para mostrar métricas y añadirlas a un DataFrame\n",
        "def mostrar_estadisticas_guardar_tabla(y_val, y_pred, set_name, model_name, print_roc = 'NO'):\n",
        "    '''\n",
        "    Ejemplo de uso :\n",
        "\n",
        "    # Fase de entrenamiento\n",
        "    results_df = mostrar_estadisticas_guardar_tabla(y_train, kmeans.predict(X_train_prep), \"Training\", results_df, model_name)\n",
        "\n",
        "    # Fase de validación\n",
        "    results_df = mostrar_estadisticas_guardar_tabla(y_val, kmeans.predict(X_val_prep), \"Validation\", results_df, model_name)\n",
        "\n",
        "    # Fase de prueba\n",
        "    results_df = mostrar_estadisticas_guardar_tabla(y_test, kmeans.predict(X_test_prep), \"Test\", results_df, model_name)\n",
        "\n",
        "    # Importante: Al final de todos los modelos (fuera del método): Guardar los resultados en un archivo Excel\n",
        "    results_df.to_excel('model_results.xlsx', index=False)\n",
        "\n",
        "    '''\n",
        "    global tabla_results_df\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    precision = precision_score(y_val, y_pred, average='weighted')\n",
        "    recall = recall_score(y_val, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    rand_index = adjusted_rand_score(y_val, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
        "    # Calcular el área bajo la curva ROC (AUC)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    if conf_matrix.shape == (2, 2):  # Asegúrate de que es una matriz de confusión 2x2\n",
        "        tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    else:\n",
        "        tn = fp = fn = tp = None  # Si no es una matriz 2x2, asigna valores None\n",
        "    \n",
        "    global_score = calcular_puntuacion_global(accuracy, precision, recall, f1, rand_index, r2, mse, tn, fp, fn, tp, roc_auc)\n",
        "    \n",
        "    # Imprimir todas las métricas\n",
        "    print(f\"Metrics for {set_name} set :\")\n",
        "    print(f\" - Accuracy: {accuracy:.4f}\")\n",
        "    print(f\" - Precision: {precision:.4f}\")\n",
        "    print(f\" - Recall: {recall:.4f}\")\n",
        "    print(f\" - F1-Score: {f1:.4f}\")\n",
        "    print(f\" - Adjusted Rand Index: {rand_index:.4f}\")\n",
        "    print(f\" - Mean Squared Error: {mse:.4f}\")\n",
        "    print(f\" - R-squared: {r2:.4f}\")\n",
        "    print(f\" - Área bajo la curva : {roc_auc:.3f}\")\n",
        "    print(f\" - Confusion Matrix: \\n{conf_matrix}\")\n",
        "    #if tn is not None and fp is not None and fn is not None and tp is not None:\n",
        "    #   print(f\"\\tTN: {tn}\\n\\tFP: {fp}\\n\\tFN: {fn}\\n\\tTP: {tp}\")\n",
        "    print(f\" - Global Score : {global_score}\")\n",
        "    print(f\"\")\n",
        "    \n",
        "    \n",
        "    new_row = pd.DataFrame({\n",
        "        'Model': [model_name],\n",
        "        'Set': [set_name],\n",
        "        'Accuracy': [accuracy],\n",
        "        'Precision': [precision],\n",
        "        'Recall': [recall],\n",
        "        'F1-Score': [f1],\n",
        "        'Adjusted Rand Index': [rand_index],\n",
        "        'Mean Squared Error': [mse],\n",
        "        'R-squared': [r2],\n",
        "        'AUC-ROC': [roc_auc],\n",
        "        'TN': [tn],\n",
        "        'FP': [fp],\n",
        "        'FN': [fn],\n",
        "        'TP': [tp],\n",
        "        'Global Score' : [global_score]\n",
        "    })\n",
        "\n",
        "    if (print_roc == 'SI') :\n",
        "        plot_ROC(fpr, tpr, roc_auc)\n",
        "    \n",
        "    tabla_results_df = pd.concat([tabla_results_df, new_row], ignore_index=True)\n",
        "    \n",
        "    return tabla_results_df\n",
        "\n",
        "def plot_ROC(fpr, tpr, roc_auc):\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Tasa de Falsos Positivos')\n",
        "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "    plt.title('Curva ROC')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "def calcular_puntuacion_global(accuracy, precision, recall, f1, rand_index, r2, mse, tn, fp, fn, tp, auc_roc):\n",
        "    # Definir ponderaciones para cada métrica\n",
        "    weights = {\n",
        "        'accuracy': 0.12,\n",
        "        'precision': 0.12,\n",
        "        'recall': 0.12,\n",
        "        'f1': 0.12,\n",
        "        'rand_index': 0.1,\n",
        "        'r2': 0.05,\n",
        "        'mse': 0.05,\n",
        "        'tpr': 0.1,\n",
        "        'fpr': 0.1,\n",
        "        'auc_roc': 0.12,\n",
        "    }\n",
        "    \n",
        "    # Normalizar las métricas\n",
        "    mse_norm = (1 - mse)  # Invertir MSE ya que menor es mejor\n",
        "    r2_norm = (r2 + 1) / 2  # Normalizar R2 para que esté entre 0 y 1\n",
        "    tpr_norm = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    fpr_norm = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
        "    \n",
        "    # Calcular la puntuación global\n",
        "    global_score = (accuracy * weights['accuracy'] +\n",
        "                    precision * weights['precision'] +\n",
        "                    recall * weights['recall'] +\n",
        "                    f1 * weights['f1'] +\n",
        "                    rand_index * weights['rand_index'] +\n",
        "                    r2_norm * weights['r2'] +\n",
        "                    mse_norm * weights['mse'] +\n",
        "                    tpr_norm * weights['tpr'] +\n",
        "                    (1 - fpr_norm) * weights['fpr'] +\n",
        "                    auc_roc * weights['auc_roc'])  # Invertir FPR ya que menor es mejor\n",
        "    \n",
        "    return round(global_score * 100, 2)\n",
        "\n",
        "# Funciones para aprendizaje no supervisado\n",
        "def optimal_cluster_number(X_train, X_val, model, max_clusters=10, method='elbow', plot_grafica = 'NO'):\n",
        "    \"\"\"\n",
        "    Encuentra el número óptimo de clusters para un modelo de clustering utilizando el método del codo (Elbow Method)\n",
        "    u otros métodos.\n",
        "    \"\"\"\n",
        "    if method == 'elbow':\n",
        "        distortions = []\n",
        "        for i in range(1, max_clusters + 1):\n",
        "            model.n_clusters = i\n",
        "            model.fit(X_train)\n",
        "            distortions.append(model.inertia_)\n",
        "        if plot_grafica == 'SI':\n",
        "            # Plotting the elbow curve\n",
        "            plt.plot(range(1, len(distortions) + 1), distortions, marker='o')\n",
        "            plt.xlabel('Número de clusters')\n",
        "            plt.ylabel('Distorsión')\n",
        "            plt.title('Método del codo para encontrar el número óptimo de clusters')\n",
        "            plt.show()\n",
        "\n",
        "        # Finding the optimal number of clusters based on the elbow point\n",
        "        optimal_k = np.argmin(np.gradient(distortions)) + 1\n",
        "        if optimal_k == 1:  # Ensure that the optimal number of clusters is greater than 1\n",
        "            optimal_k = 2\n",
        "        return optimal_k\n",
        "\n",
        "    elif method == 'silhouette':\n",
        "        silhouette_scores = []\n",
        "        for i in range(2, max_clusters + 1):\n",
        "            model.n_clusters = i\n",
        "            model.fit(X_train)\n",
        "            labels = model.predict(X_val)\n",
        "            silhouette_scores.append(silhouette_score(X_val, labels))\n",
        "        \n",
        "        if plot_grafica == 'SI':\n",
        "            # Plotting the silhouette scores\n",
        "            plt.plot(range(2, len(silhouette_scores) + 2), silhouette_scores, marker='o')\n",
        "            plt.xlabel('Número de clusters')\n",
        "            plt.ylabel('Silhouette Score')\n",
        "            plt.title('Silhouette Score para encontrar el número óptimo de clusters')\n",
        "            plt.show()\n",
        "\n",
        "        # Finding the optimal number of clusters based on silhouette score\n",
        "        optimal_k = np.argmax(silhouette_scores) + 2\n",
        "        return optimal_k\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Método no válido. Métodos disponibles: 'elbow', 'silhouette', etc.\")\n",
        "\n",
        "\n",
        "# Función para motrar estadísticas para modelos de aprendizaje no supervisado   \n",
        "def mostrar_estadisticas_guardar_tabla_NS(X, labels, set_name, model_name):\n",
        "    '''\n",
        "    Ejemplo de uso :\n",
        "\n",
        "    # Fase de entrenamiento\n",
        "    results_df = mostrar_estadisticas_guardar_tabla(X_train, kmeans.predict(X_train), \"Training\", model_name, results_df)\n",
        "\n",
        "    # Fase de validación\n",
        "    results_df = mostrar_estadisticas_guardar_tabla(X_val, kmeans.predict(X_val), \"Validation\", model_name, results_df)\n",
        "\n",
        "    # Fase de prueba\n",
        "    results_df = mostrar_estadisticas_guardar_tabla(X_test, kmeans.predict(X_test), \"Test\", model_name, results_df)\n",
        "\n",
        "    # Importante: Al final de todos los modelos (fuera del método): Guardar los resultados en un archivo Excel\n",
        "    results_df.to_excel('model_results.xlsx', index=False)\n",
        "    '''\n",
        "    global tabla_results_NS_df\n",
        "    silhouette_avg = silhouette_score(X, labels)\n",
        "    db_score = davies_bouldin_score(X, labels)\n",
        "    ch_score = calinski_harabasz_score(X, labels)\n",
        "\n",
        "    global_score = calcular_puntuacion_global_NS(silhouette_avg, db_score, ch_score)\n",
        "    \n",
        "    # Imprimir todas las métricas\n",
        "    print(f\"Metrics for {set_name} set ({model_name}):\")\n",
        "    print(f\" - Silhouette Score: {silhouette_avg:.4f}\")\n",
        "    print(f\" - Davies-Bouldin Index: {db_score:.4f}\")\n",
        "    print(f\" - Calinski-Harabasz Index: {ch_score:.4f}\")\n",
        "    print(f\" - Global Score: {global_score:.4f}\")\n",
        "    print(f\"\")\n",
        "    \n",
        "    new_row = pd.DataFrame({\n",
        "        'Model': [model_name],\n",
        "        'Set': [set_name],\n",
        "        'Silhouette Score': [silhouette_avg],\n",
        "        'Davies-Bouldin Index': [db_score],\n",
        "        'Calinski-Harabasz Index': [ch_score],\n",
        "        'Global Score': [global_score]\n",
        "    })\n",
        "    \n",
        "    tabla_results_NS_df = pd.concat([tabla_results_NS_df, new_row], ignore_index=True)\n",
        "    \n",
        "    return tabla_results_NS_df\n",
        "\n",
        "def calcular_puntuacion_global_NS(silhouette_avg, db_score, ch_score):\n",
        "    # Normalizando los valores para que estén en el rango de 0 a 100\n",
        "    normalized_silhouette = (silhouette_avg + 1) * 50  # Ajustando el rango del Silhouette Score de -1 a 1 a 0 a 100\n",
        "    normalized_davies_bouldin = (1 - db_score) * 50  # Ajustando el rango del Davies-Bouldin Index de 0 a 1 a 0 a 100\n",
        "\n",
        "    # Calculando el puntaje global promediando los puntajes normalizados\n",
        "    global_score = (normalized_silhouette + normalized_davies_bouldin + ch_score) / 3\n",
        "\n",
        "    return global_score\n",
        "\n",
        "def show_save_results_no_supervised(X, labels, set_name, model_name):\n",
        "    global tabla_results_NS_df\n",
        "    silhouette_avg = silhouette_score(X, labels)\n",
        "    db_score = davies_bouldin_score(X, labels)\n",
        "    ch_score = calinski_harabasz_score(X, labels)\n",
        "    global_score = calcular_global_score(silhouette_avg, db_score, ch_score)\n",
        "\n",
        "    # Imprimir todas las métricas\n",
        "    print(f\"Metrics for {set_name} set ({model_name}):\")\n",
        "    print(f\" - Silhouette Score: {silhouette_avg:.4f}\")\n",
        "    print(f\" - Davies-Bouldin Index: {db_score:.4f}\")\n",
        "    print(f\" - Calinski-Harabasz Index: {ch_score:.4f}\")\n",
        "    print(f\" - Global Score: {global_score:.4f}\")\n",
        "    print(f\"\")\n",
        "\n",
        "    new_row = pd.DataFrame({\n",
        "            'Model': [model_name],\n",
        "            'Set': [set_name],\n",
        "            'Silhouette Score': [silhouette_avg],\n",
        "            'Davies-Bouldin Index': [db_score],\n",
        "            'Calinski-Harabasz Index': [ch_score],\n",
        "            'Global Score': [global_score]\n",
        "        })\n",
        "        \n",
        "    tabla_results_NS_df = pd.concat([tabla_results_NS_df, new_row], ignore_index=True)\n",
        "        \n",
        "    return tabla_results_NS_df\n",
        "\n",
        "def calcular_global_score(silhouette_score, davies_bouldin_index, calinski_harabasz_index):\n",
        "    # Normalizar los valores para que estén en el rango de 0 a 100\n",
        "    normalized_silhouette = (silhouette_score + 1) * 50  # Ajustando el rango del Silhouette Score de -1 a 1 a 0 a 100\n",
        "    normalized_davies_bouldin = (1 - davies_bouldin_index) * 100  # Ajustando el rango del Davies-Bouldin Index de 0 a 1 a 0 a 100\n",
        "\n",
        "    # Calculando el puntaje global promediando los puntajes normalizados\n",
        "    global_score = (normalized_silhouette + normalized_davies_bouldin + calinski_harabasz_index) / 3\n",
        "\n",
        "    return global_score\n",
        "\n",
        "def encontrar_numero_optimo_clusters(X_train, X_val, model, max_clusters=10, plot_grafica = 'NO'):\n",
        "    wcss = []\n",
        "    silhouette_scores = []\n",
        "    davies_bouldin_scores = []\n",
        "    calinski_harabasz_scores = []\n",
        "    global_scores = []\n",
        "\n",
        "    for i in range(2, max_clusters+1):\n",
        "        model.n_clusters = i\n",
        "        model.fit(X_train)\n",
        "\n",
        "        # Predecir las etiquetas para los datos de validación\n",
        "        labels = model.predict(X_val)\n",
        "\n",
        "        # Calcular las métricas\n",
        "        silhouette = silhouette_score(X_val, labels)\n",
        "        davies_bouldin = davies_bouldin_score(X_val, labels)\n",
        "        calinski_harabasz = calinski_harabasz_score(X_val, labels)\n",
        "        \n",
        "        global_score = calcular_global_score(silhouette, davies_bouldin, calinski_harabasz)\n",
        "        \n",
        "        wcss.append(model.inertia_)\n",
        "        silhouette_scores.append(silhouette)\n",
        "        davies_bouldin_scores.append(davies_bouldin)\n",
        "        calinski_harabasz_scores.append(calinski_harabasz)\n",
        "        global_scores.append(global_score)\n",
        "\n",
        "    if plot_grafica == 'SI':\n",
        "        # Plot para el método del codo\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.plot(range(2, max_clusters+1), wcss, marker='o')\n",
        "        plt.title('Método del Codo')\n",
        "        plt.xlabel('Número de Clústeres')\n",
        "        plt.ylabel('WCSS')\n",
        "        plt.show()\n",
        "\n",
        "        # Plot para las métricas de validación\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.plot(range(2, max_clusters+1), silhouette_scores, marker='o', label='Silhouette Score')\n",
        "        plt.plot(range(2, max_clusters+1), davies_bouldin_scores, marker='o', label='Davies-Bouldin Index')\n",
        "        plt.plot(range(2, max_clusters+1), calinski_harabasz_scores, marker='o', label='Calinski-Harabasz Index')\n",
        "        plt.plot(range(2, max_clusters+1), global_scores, marker='o', label='Global Score')\n",
        "        plt.title('Métricas de Validación para Diferentes Números de Clústeres')\n",
        "        plt.xlabel('Número de Clústeres')\n",
        "        plt.ylabel('Valor de la Métrica')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    # Encontrar el número óptimo de clústeres basado en el puntaje global\n",
        "    numero_optimo_clusters = range(2, max_clusters+1)[np.argmax(global_scores)]\n",
        "    return numero_optimo_clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Procesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carga de la URL de donde se encuentran los datos \n",
        "# (I) Introducir valor de nombreArchivo y variar la ruta en local donde se guardan los datos\n",
        "nombreArchivo = 'Tables_S1_to_S11' #nombre del archivo del dataset\n",
        "url_datos = f'C:/Users/danie/OneDrive/Documentos/Master/Lusku/TFM/Proposiciones/Deteccion Cancer/Datos/{nombreArchivo}.xlsx'\n",
        "\n",
        "# Se procede a hacer una carga de los datos. \n",
        "df_original= pd.read_excel(url_datos, sheet_name='Table S6')\n",
        "\n",
        "# Crear una copia del DataFrame original para realizar los cambios\n",
        "df6 = df_original.copy()\n",
        "\n",
        "# Recorrer las columnas del DataFrame para eliminar las cadenas de texto : ['*', '**']\n",
        "for columna in df6.columns:\n",
        "    if df6[columna].dtype == 'object':\n",
        "        # Aplicar la sustitución para cada secuencia en secuencias_a_buscar\n",
        "        for secuencia in ['*', '**']:\n",
        "            df6[columna] = df6[columna].apply(lambda x: x.replace(secuencia, '') if isinstance(x, str) and secuencia in x else x)\n",
        "\n",
        "df_prep = df6.apply(convert_to_numeric)\n",
        "\n",
        "# Relleno de nulos de la variable \"AJCC Stage\"\n",
        "df_prep[\"AJCC Stage\"] = df_prep[\"AJCC Stage\"].fillna(\"0\")\n",
        "\n",
        "# Calcular la media solo para las columnas numéricas\n",
        "numeric_columns = df_prep.select_dtypes(include=['number'])\n",
        "mean_values = numeric_columns.mean()\n",
        "\n",
        "# Rellenar los valores nulos con la media correspondiente\n",
        "df = df_prep.copy()  # Copiar el DataFrame preprocesado para evitar modificarlo\n",
        "for col in mean_values.index:\n",
        "    df[col].fillna(mean_values[col], inplace=True)\n",
        "\n",
        "\n",
        "# Binarización \"Tumor Type\" 0 -> NO CANCER; 1 -> SI CANCER + 'CancerSEEK Test Result'\n",
        "df['Tumor type'] = df['Tumor type'].apply(lambda x: 0 if str(x).strip().lower() == \"normal\" else 1).astype(int)\n",
        "#df['CancerSEEK Test Result'] = df['CancerSEEK Test Result'].apply(lambda x: 0 if str(x).strip().lower() == \"negative\" else 1).astype(int)\n",
        "\n",
        "# Conservar solo las columnas 'CA19-9 (U/ml)', 'CA-125 (U/ml)','HGF (pg/ml)','OPN (pg/ml)', 'Omega score', 'Prolactin (pg/ml)', 'CEA (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)'\n",
        "columnas_a_conservar = ['Tumor type','CA19-9 (U/ml)', 'CA-125 (U/ml)','HGF (pg/ml)','OPN (pg/ml)', 'Omega score', 'Prolactin (pg/ml)', 'CEA (pg/ml)', 'Myeloperoxidase (ng/ml)', 'TIMP-1 (pg/ml)']\n",
        "\n",
        "## --- CHECKPOINT ----- Datos limpios\n",
        "\n",
        "# Columna objetivo\n",
        "Y_column = df['Tumor type'].copy()\n",
        "# Reducción del dataFrame\n",
        "df_reduced = df[columnas_a_conservar].copy()\n",
        "#Copia del dataFrame entero\n",
        "df_full = df.copy()\n",
        "\n",
        "''' INICIO - Verificacion del information gain'''\n",
        "# Information Gain inicial\n",
        "df_discretizado = discretizar_df_arboles_1(df_reduced.drop(columns=['Tumor type']))\n",
        "df_reduced_discretizado_escalated = escalado_dataFrame(df_discretizado)\n",
        "calcular_ganancia_informacion(df_reduced_discretizado_escalated, Y_column, imprimir = \"NO\")\n",
        "\n",
        "# Information Gain usando arboles de decision (acorde a : \"..the cancer antigen markers are no longer the top predictive features. Instead, we observe the opposite trend for the purity and accuracy measurements..\")\n",
        "df_discretizado_full = discretizar_df_arboles(df_full, imprimir =\"NO\") # Columnas de este segundo enfoque guardadas en columnas_segundo_enfoque\n",
        "df_discretizado_reduced = discretizar_df_arboles(df_reduced,imprimir =\"NO\")\n",
        "\n",
        "''' FIN - Verificacion del information gain'''\n",
        "\n",
        "# Crear un DataFrame para almacenar los resultados en una tabla para luego poder compararlos - APRENDIZAJE SUPERVISADO\n",
        "tabla_results_df = pd.DataFrame(columns=['Model', 'Set', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Adjusted Rand Index', 'Mean Squared Error', 'R-squared','AUC-ROC', 'TN', 'FP', 'FN', 'TP', 'Global Score'])\n",
        "\n",
        "# Crear un DataFrame para almacenar los resultados en una tabla para luego poder compararlos - APRENDIZAJE NO SUPERVISADO\n",
        "tabla_results_NS_df = pd.DataFrame(columns=['Model', 'Set', 'Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index', 'Global Score'])\n",
        "\n",
        "## --- CHECKPOINT ----- Datos discretizados + Information gain\n",
        "# TODO Una vez hechos los modelos, habrá que estudiar cómo influye el usar esta serie de variables en la predicción\n",
        "columnas_segundo_enfoque = ['Tumor type','OPN (pg/ml)','IL-6 (pg/ml)','IL-8 (pg/ml)','HGF (pg/ml)','Prolactin (pg/ml)','Omega score','GDF15 (ng/ml)','CYFRA 21-1 (pg/ml)','Myeloperoxidase (ng/ml)','sEGFR (pg/ml)']\n",
        "df_reduced_segundo_enfoque = df[columnas_segundo_enfoque].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' Valores para X\n",
        "1. df : entero, limpio, sin normalizar ni discretizar\n",
        "2. df_reduced : reducido, limpio, sin normalizar ni discretizar\n",
        "3. df_reduced_discretizado_escalated --> Acorde a la Tabla 1\n",
        "4. df_discretizado_full.drop(columns=['Tumor type']) --> Acorde a la Figura S3 (usando todas las variables) discretizado con arbol de decisión\n",
        "5. df_discretizado_reduced.drop(columns=['Tumor type']) --> Acorde a la Figura S3; discretizado con arbol de decisión\n",
        "'''\n",
        "\n",
        "y = df_reduced['Tumor type']\n",
        "X = df_reduced.drop(columns='Tumor type')\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, train_size=0.6, val_size=0.2, test_size=0.2, random_state=42)\n",
        "\n",
        "numeric_cols = X_train.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
        "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.to_list()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "                   [('scale', StandardScaler(), numeric_cols),\n",
        "                    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)],\n",
        "                remainder = 'passthrough',\n",
        "                verbose_feature_names_out = False\n",
        "               ).set_output(transform=\"pandas\")\n",
        "\n",
        "# TODO DUDA - Añadir un proceso de discretización? Puede mejorar el resultado. Ver cómo influye usar la función 'discretizar_df_arboles' ó la función sklearn.preprocessing.KBinsDiscretizer\n",
        "X_train_prep = preprocessor.fit_transform(X_train)\n",
        "X_val_prep = preprocessor.transform(X_val)\n",
        "X_test_prep  = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aprendizaje supervisado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regresión lineal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.43555844 -0.40375505 -0.41374517 -0.41624435 -0.41977734]\n",
            "Média métricas de validación cruzada: -0.41781607165280094\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.7952\n",
            " - Precision: 0.8251\n",
            " - Recall: 0.7952\n",
            " - F1-Score: 0.7950\n",
            " - Adjusted Rand Index: 0.3478\n",
            " - Mean Squared Error: 0.2048\n",
            " - R-squared: 0.1673\n",
            " - Área bajo la curva : 0.810\n",
            " - Confusion Matrix: \n",
            "[[438  37]\n",
            " [186 428]]\n",
            " - Global Score : 74.81\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8159\n",
            " - Precision: 0.8271\n",
            " - Recall: 0.8159\n",
            " - F1-Score: 0.8155\n",
            " - Adjusted Rand Index: 0.3976\n",
            " - Mean Squared Error: 0.1841\n",
            " - R-squared: 0.2610\n",
            " - Área bajo la curva : 0.820\n",
            " - Confusion Matrix: \n",
            "[[153  18]\n",
            " [ 49 144]]\n",
            " - Global Score : 76.76\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.7940\n",
            " - Precision: 0.8303\n",
            " - Recall: 0.7940\n",
            " - F1-Score: 0.7917\n",
            " - Adjusted Rand Index: 0.3437\n",
            " - Mean Squared Error: 0.2060\n",
            " - R-squared: 0.1694\n",
            " - Área bajo la curva : 0.806\n",
            " - Confusion Matrix: \n",
            "[[157   9]\n",
            " [ 66 132]]\n",
            " - Global Score : 74.65\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0  Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "1  Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "2  Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "3  Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "4  Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "5  Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "\n",
              "   Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP   FN  \\\n",
              "0             0.347828            0.204775   0.167334  0.809587  438  37  186   \n",
              "1             0.397597            0.184066   0.261037  0.820425  153  18   49   \n",
              "2             0.343680            0.206044   0.169405  0.806225  157   9   66   \n",
              "3             0.347828            0.204775   0.167334  0.809587  438  37  186   \n",
              "4             0.397597            0.184066   0.261037  0.820425  153  18   49   \n",
              "5             0.343680            0.206044   0.169405  0.806225  157   9   66   \n",
              "\n",
              "    TP  Global Score  \n",
              "0  428         74.81  \n",
              "1  144         76.76  \n",
              "2  132         74.65  \n",
              "3  428         74.81  \n",
              "4  144         76.76  \n",
              "5  132         74.65  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Crear una instancia del modelo de regresión lineal\n",
        "model_LR = LinearRegression()\n",
        "model_name = \"Regresion Lineal\"\n",
        "\n",
        "# Definir un umbral\n",
        "umbral = 0.5\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model_LR, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_LR.fit(X_train_prep, y_train)\n",
        "\n",
        "#print(\"Fase de ENTRENAMIENTO estadísticas :\")\n",
        "#mostrar_score(X_train_prep, y_train, model_LR)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, np.where(model_LR.predict(X_train_prep) > umbral, 1, 0), \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "y_pred = model_LR.predict(X_val_prep)\n",
        "\n",
        "# Binarizar las predicciones\n",
        "y_pred_bin = np.where(y_pred > umbral, 1, 0)\n",
        "\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_pred_bin, \"Validation\", model_name, print_roc = \"NO\")\n",
        "\n",
        "# Predicciones\n",
        "y_test_pred = model_LR.predict(X_test_prep)\n",
        "\n",
        "y_test_pred_bin = np.where(y_test_pred > umbral, 1, 0)\n",
        "\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred_bin, \"Test\", model_name, print_roc = \"NO\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regresión logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regresión Logística\n",
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.40068748 -0.38313051 -0.35838578 -0.47409982 -0.42933879]\n",
            "Média métricas de validación cruzada: -0.4091284780006096\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.8356\n",
            " - Precision: 0.8437\n",
            " - Recall: 0.8356\n",
            " - F1-Score: 0.8363\n",
            " - Adjusted Rand Index: 0.4501\n",
            " - Mean Squared Error: 0.1644\n",
            " - R-squared: 0.3316\n",
            " - Área bajo la curva : 0.841\n",
            " - Confusion Matrix: \n",
            "[[420  55]\n",
            " [124 490]]\n",
            " - Global Score : 79.14\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8269\n",
            " - Precision: 0.8287\n",
            " - Recall: 0.8269\n",
            " - F1-Score: 0.8271\n",
            " - Adjusted Rand Index: 0.4259\n",
            " - Mean Squared Error: 0.1731\n",
            " - R-squared: 0.3052\n",
            " - Área bajo la curva : 0.828\n",
            " - Confusion Matrix: \n",
            "[[145  26]\n",
            " [ 37 156]]\n",
            " - Global Score : 77.87\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8269\n",
            " - Precision: 0.8391\n",
            " - Recall: 0.8269\n",
            " - F1-Score: 0.8270\n",
            " - Adjusted Rand Index: 0.4259\n",
            " - Mean Squared Error: 0.1731\n",
            " - R-squared: 0.3023\n",
            " - Área bajo la curva : 0.833\n",
            " - Confusion Matrix: \n",
            "[[150  16]\n",
            " [ 47 151]]\n",
            " - Global Score : 78.15\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0     Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "1     Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "2     Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "3     Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "4     Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "5     Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "6  Regresión Logística    Training  0.835629   0.843677  0.835629  0.836301   \n",
              "7  Regresión Logística  Validation  0.826923   0.828750  0.826923  0.827081   \n",
              "8  Regresión Logística        Test  0.826923   0.839082  0.826923  0.826964   \n",
              "\n",
              "   Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP   FN  \\\n",
              "0             0.347828            0.204775   0.167334  0.809587  438  37  186   \n",
              "1             0.397597            0.184066   0.261037  0.820425  153  18   49   \n",
              "2             0.343680            0.206044   0.169405  0.806225  157   9   66   \n",
              "3             0.347828            0.204775   0.167334  0.809587  438  37  186   \n",
              "4             0.397597            0.184066   0.261037  0.820425  153  18   49   \n",
              "5             0.343680            0.206044   0.169405  0.806225  157   9   66   \n",
              "6             0.450090            0.164371   0.331627  0.841128  420  55  124   \n",
              "7             0.425939            0.173077   0.305154  0.828122  145  26   37   \n",
              "8             0.425926            0.173077   0.302300  0.833120  150  16   47   \n",
              "\n",
              "    TP  Global Score  \n",
              "0  428         74.81  \n",
              "1  144         76.76  \n",
              "2  132         74.65  \n",
              "3  428         74.81  \n",
              "4  144         76.76  \n",
              "5  132         74.65  \n",
              "6  490         79.14  \n",
              "7  156         77.87  \n",
              "8  151         78.15  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_name = \"Regresión Logística\"\n",
        "print(model_name)\n",
        "# Crear una instancia del modelo de regresión logística\n",
        "model_LogR = LogisticRegression()\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model_LogR, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_LogR.fit(X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = model_LogR.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_val_pred = model_LogR.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = model_LogR.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Arbol de decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Árbol de Decisión\n",
            "Mejores hiperparámetros: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 32, 'min_samples_leaf': 2, 'min_samples_split': 10, 'splitter': 'best'}\n",
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.38907088 -0.39492189 -0.34534918 -0.40068748 -0.33942212]\n",
            "Média métricas de validación cruzada: -0.3738903096983308\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.9431\n",
            " - Precision: 0.9434\n",
            " - Recall: 0.9431\n",
            " - F1-Score: 0.9431\n",
            " - Adjusted Rand Index: 0.7850\n",
            " - Mean Squared Error: 0.0569\n",
            " - R-squared: 0.7685\n",
            " - Área bajo la curva : 0.944\n",
            " - Confusion Matrix: \n",
            "[[450  25]\n",
            " [ 37 577]]\n",
            " - Global Score : 92.45\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8544\n",
            " - Precision: 0.8561\n",
            " - Recall: 0.8544\n",
            " - F1-Score: 0.8538\n",
            " - Adjusted Rand Index: 0.5010\n",
            " - Mean Squared Error: 0.1456\n",
            " - R-squared: 0.4154\n",
            " - Área bajo la curva : 0.851\n",
            " - Confusion Matrix: \n",
            "[[137  34]\n",
            " [ 19 174]]\n",
            " - Global Score : 81.09\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8544\n",
            " - Precision: 0.8547\n",
            " - Recall: 0.8544\n",
            " - F1-Score: 0.8545\n",
            " - Adjusted Rand Index: 0.5010\n",
            " - Mean Squared Error: 0.1456\n",
            " - R-squared: 0.4130\n",
            " - Área bajo la curva : 0.854\n",
            " - Confusion Matrix: \n",
            "[[141  25]\n",
            " [ 28 170]]\n",
            " - Global Score : 81.16\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.912764</td>\n",
              "      <td>0.913816</td>\n",
              "      <td>0.912764</td>\n",
              "      <td>0.912948</td>\n",
              "      <td>0.681169</td>\n",
              "      <td>0.087236</td>\n",
              "      <td>0.645277</td>\n",
              "      <td>0.913821</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>58</td>\n",
              "      <td>556</td>\n",
              "      <td>88.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.835315</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.835215</td>\n",
              "      <td>0.447825</td>\n",
              "      <td>0.164835</td>\n",
              "      <td>0.338242</td>\n",
              "      <td>0.834894</td>\n",
              "      <td>142</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>78.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.813215</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.810794</td>\n",
              "      <td>0.383806</td>\n",
              "      <td>0.189560</td>\n",
              "      <td>0.235853</td>\n",
              "      <td>0.812127</td>\n",
              "      <td>138</td>\n",
              "      <td>28</td>\n",
              "      <td>41</td>\n",
              "      <td>157</td>\n",
              "      <td>75.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.912764</td>\n",
              "      <td>0.913816</td>\n",
              "      <td>0.912764</td>\n",
              "      <td>0.912948</td>\n",
              "      <td>0.681169</td>\n",
              "      <td>0.087236</td>\n",
              "      <td>0.645277</td>\n",
              "      <td>0.913821</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>58</td>\n",
              "      <td>556</td>\n",
              "      <td>88.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.835315</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.835215</td>\n",
              "      <td>0.447825</td>\n",
              "      <td>0.164835</td>\n",
              "      <td>0.338242</td>\n",
              "      <td>0.834894</td>\n",
              "      <td>142</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>78.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.813215</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.810794</td>\n",
              "      <td>0.383806</td>\n",
              "      <td>0.189560</td>\n",
              "      <td>0.235853</td>\n",
              "      <td>0.812127</td>\n",
              "      <td>138</td>\n",
              "      <td>28</td>\n",
              "      <td>41</td>\n",
              "      <td>157</td>\n",
              "      <td>75.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.912764</td>\n",
              "      <td>0.913816</td>\n",
              "      <td>0.912764</td>\n",
              "      <td>0.912948</td>\n",
              "      <td>0.681169</td>\n",
              "      <td>0.087236</td>\n",
              "      <td>0.645277</td>\n",
              "      <td>0.913821</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>58</td>\n",
              "      <td>556</td>\n",
              "      <td>88.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.835315</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.835215</td>\n",
              "      <td>0.447825</td>\n",
              "      <td>0.164835</td>\n",
              "      <td>0.338242</td>\n",
              "      <td>0.834894</td>\n",
              "      <td>142</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>78.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.813215</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.810794</td>\n",
              "      <td>0.383806</td>\n",
              "      <td>0.189560</td>\n",
              "      <td>0.235853</td>\n",
              "      <td>0.812127</td>\n",
              "      <td>138</td>\n",
              "      <td>28</td>\n",
              "      <td>41</td>\n",
              "      <td>157</td>\n",
              "      <td>75.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.936639</td>\n",
              "      <td>0.937199</td>\n",
              "      <td>0.936639</td>\n",
              "      <td>0.936740</td>\n",
              "      <td>0.762363</td>\n",
              "      <td>0.063361</td>\n",
              "      <td>0.742359</td>\n",
              "      <td>0.937377</td>\n",
              "      <td>448</td>\n",
              "      <td>27</td>\n",
              "      <td>42</td>\n",
              "      <td>572</td>\n",
              "      <td>91.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.837912</td>\n",
              "      <td>0.837976</td>\n",
              "      <td>0.837912</td>\n",
              "      <td>0.837938</td>\n",
              "      <td>0.455242</td>\n",
              "      <td>0.162088</td>\n",
              "      <td>0.349271</td>\n",
              "      <td>0.837484</td>\n",
              "      <td>142</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>163</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.804945</td>\n",
              "      <td>0.806541</td>\n",
              "      <td>0.804945</td>\n",
              "      <td>0.805251</td>\n",
              "      <td>0.370240</td>\n",
              "      <td>0.195055</td>\n",
              "      <td>0.213703</td>\n",
              "      <td>0.805616</td>\n",
              "      <td>135</td>\n",
              "      <td>31</td>\n",
              "      <td>40</td>\n",
              "      <td>158</td>\n",
              "      <td>75.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.943067</td>\n",
              "      <td>0.943447</td>\n",
              "      <td>0.943067</td>\n",
              "      <td>0.943141</td>\n",
              "      <td>0.785002</td>\n",
              "      <td>0.056933</td>\n",
              "      <td>0.768496</td>\n",
              "      <td>0.943554</td>\n",
              "      <td>450</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>577</td>\n",
              "      <td>92.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.856113</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.853779</td>\n",
              "      <td>0.501006</td>\n",
              "      <td>0.145604</td>\n",
              "      <td>0.415447</td>\n",
              "      <td>0.851362</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>19</td>\n",
              "      <td>174</td>\n",
              "      <td>81.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.854704</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.501008</td>\n",
              "      <td>0.145604</td>\n",
              "      <td>0.413046</td>\n",
              "      <td>0.853992</td>\n",
              "      <td>141</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>170</td>\n",
              "      <td>81.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.943067</td>\n",
              "      <td>0.943447</td>\n",
              "      <td>0.943067</td>\n",
              "      <td>0.943141</td>\n",
              "      <td>0.785002</td>\n",
              "      <td>0.056933</td>\n",
              "      <td>0.768496</td>\n",
              "      <td>0.943554</td>\n",
              "      <td>450</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>577</td>\n",
              "      <td>92.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.856113</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.853779</td>\n",
              "      <td>0.501006</td>\n",
              "      <td>0.145604</td>\n",
              "      <td>0.415447</td>\n",
              "      <td>0.851362</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>19</td>\n",
              "      <td>174</td>\n",
              "      <td>81.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Árbol de Decisión</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.854704</td>\n",
              "      <td>0.854396</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.501008</td>\n",
              "      <td>0.145604</td>\n",
              "      <td>0.413046</td>\n",
              "      <td>0.853992</td>\n",
              "      <td>141</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>170</td>\n",
              "      <td>81.16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0   Árbol de Decisión    Training  0.912764   0.913816  0.912764  0.912948   \n",
              "1   Árbol de Decisión  Validation  0.835165   0.835315  0.835165  0.835215   \n",
              "2   Árbol de Decisión        Test  0.810440   0.813215  0.810440  0.810794   \n",
              "3   Árbol de Decisión    Training  0.912764   0.913816  0.912764  0.912948   \n",
              "4   Árbol de Decisión  Validation  0.835165   0.835315  0.835165  0.835215   \n",
              "5   Árbol de Decisión        Test  0.810440   0.813215  0.810440  0.810794   \n",
              "6   Árbol de Decisión    Training  0.912764   0.913816  0.912764  0.912948   \n",
              "7   Árbol de Decisión  Validation  0.835165   0.835315  0.835165  0.835215   \n",
              "8   Árbol de Decisión        Test  0.810440   0.813215  0.810440  0.810794   \n",
              "9   Árbol de Decisión    Training  0.936639   0.937199  0.936639  0.936740   \n",
              "10  Árbol de Decisión  Validation  0.837912   0.837976  0.837912  0.837938   \n",
              "11  Árbol de Decisión        Test  0.804945   0.806541  0.804945  0.805251   \n",
              "12  Árbol de Decisión    Training  0.943067   0.943447  0.943067  0.943141   \n",
              "13  Árbol de Decisión  Validation  0.854396   0.856113  0.854396  0.853779   \n",
              "14  Árbol de Decisión        Test  0.854396   0.854704  0.854396  0.854492   \n",
              "15  Árbol de Decisión    Training  0.943067   0.943447  0.943067  0.943141   \n",
              "16  Árbol de Decisión  Validation  0.854396   0.856113  0.854396  0.853779   \n",
              "17  Árbol de Decisión        Test  0.854396   0.854704  0.854396  0.854492   \n",
              "\n",
              "    Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  FN  \\\n",
              "0              0.681169            0.087236   0.645277  0.913821  438  37  58   \n",
              "1              0.447825            0.164835   0.338242  0.834894  142  29  31   \n",
              "2              0.383806            0.189560   0.235853  0.812127  138  28  41   \n",
              "3              0.681169            0.087236   0.645277  0.913821  438  37  58   \n",
              "4              0.447825            0.164835   0.338242  0.834894  142  29  31   \n",
              "5              0.383806            0.189560   0.235853  0.812127  138  28  41   \n",
              "6              0.681169            0.087236   0.645277  0.913821  438  37  58   \n",
              "7              0.447825            0.164835   0.338242  0.834894  142  29  31   \n",
              "8              0.383806            0.189560   0.235853  0.812127  138  28  41   \n",
              "9              0.762363            0.063361   0.742359  0.937377  448  27  42   \n",
              "10             0.455242            0.162088   0.349271  0.837484  142  29  30   \n",
              "11             0.370240            0.195055   0.213703  0.805616  135  31  40   \n",
              "12             0.785002            0.056933   0.768496  0.943554  450  25  37   \n",
              "13             0.501006            0.145604   0.415447  0.851362  137  34  19   \n",
              "14             0.501008            0.145604   0.413046  0.853992  141  25  28   \n",
              "15             0.785002            0.056933   0.768496  0.943554  450  25  37   \n",
              "16             0.501006            0.145604   0.415447  0.851362  137  34  19   \n",
              "17             0.501008            0.145604   0.413046  0.853992  141  25  28   \n",
              "\n",
              "     TP  Global Score  \n",
              "0   556         88.56  \n",
              "1   162         78.81  \n",
              "2   157         75.91  \n",
              "3   556         88.56  \n",
              "4   162         78.81  \n",
              "5   157         75.91  \n",
              "6   556         88.56  \n",
              "7   162         78.81  \n",
              "8   157         75.91  \n",
              "9   572         91.63  \n",
              "10  163         79.14  \n",
              "11  158         75.20  \n",
              "12  577         92.45  \n",
              "13  174         81.09  \n",
              "14  170         81.16  \n",
              "15  577         92.45  \n",
              "16  174         81.09  \n",
              "17  170         81.16  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "model_name = \"Árbol de Decisión\"\n",
        "print(model_name)\n",
        "model_DT_leaf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Definir los parámetros a ajustar\n",
        "params = {'max_leaf_nodes': range(2, 50)}  # Probando diferentes valores para max_leaf_nodes\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None,5, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_leaf_nodes': range(2, 50)\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda en rejilla con validación cruzada\n",
        "grid_search = GridSearchCV(model_DT_leaf, param_grid, n_jobs=-1, cv=5)\n",
        "grid_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "\n",
        "model_DT = grid_search.best_estimator_\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_DT.fit(X_train_prep, y_train)\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model_DT, X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = model_DT.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_val_pred = model_DT.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = model_DT.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest\n",
            "Mejores parámetros encontrados: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': False}\n",
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.33180076 -0.27091418 -0.30289127 -0.29522189 -0.30358837]\n",
            "Média métricas de validación cruzada: -0.30088329355512755\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 1.0000\n",
            " - Precision: 1.0000\n",
            " - Recall: 1.0000\n",
            " - F1-Score: 1.0000\n",
            " - Adjusted Rand Index: 1.0000\n",
            " - Mean Squared Error: 0.0000\n",
            " - R-squared: 1.0000\n",
            " - Área bajo la curva : 1.000\n",
            " - Confusion Matrix: \n",
            "[[475   0]\n",
            " [  0 614]]\n",
            " - Global Score : 100.0\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8764\n",
            " - Precision: 0.8798\n",
            " - Recall: 0.8764\n",
            " - F1-Score: 0.8756\n",
            " - Adjusted Rand Index: 0.5654\n",
            " - Mean Squared Error: 0.1236\n",
            " - R-squared: 0.5037\n",
            " - Área bajo la curva : 0.873\n",
            " - Confusion Matrix: \n",
            "[[139  32]\n",
            " [ 13 180]]\n",
            " - Global Score : 83.82\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8956\n",
            " - Precision: 0.8960\n",
            " - Recall: 0.8956\n",
            " - F1-Score: 0.8953\n",
            " - Adjusted Rand Index: 0.6250\n",
            " - Mean Squared Error: 0.1044\n",
            " - R-squared: 0.5792\n",
            " - Área bajo la curva : 0.893\n",
            " - Confusion Matrix: \n",
            "[[143  23]\n",
            " [ 15 183]]\n",
            " - Global Score : 86.24\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_21280\\3849515159.py:270: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  tabla_results_df = pd.concat([tabla_results_df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Training</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>614</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.876374</td>\n",
              "      <td>0.879788</td>\n",
              "      <td>0.876374</td>\n",
              "      <td>0.875637</td>\n",
              "      <td>0.565425</td>\n",
              "      <td>0.123626</td>\n",
              "      <td>0.503681</td>\n",
              "      <td>0.872754</td>\n",
              "      <td>139</td>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>180</td>\n",
              "      <td>83.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.895604</td>\n",
              "      <td>0.895972</td>\n",
              "      <td>0.895604</td>\n",
              "      <td>0.895349</td>\n",
              "      <td>0.624954</td>\n",
              "      <td>0.104396</td>\n",
              "      <td>0.579165</td>\n",
              "      <td>0.892844</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>183</td>\n",
              "      <td>86.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0  Random Forest    Training  1.000000   1.000000  1.000000  1.000000   \n",
              "1  Random Forest  Validation  0.876374   0.879788  0.876374  0.875637   \n",
              "2  Random Forest        Test  0.895604   0.895972  0.895604  0.895349   \n",
              "\n",
              "   Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  FN  \\\n",
              "0             1.000000            0.000000   1.000000  1.000000  475   0   0   \n",
              "1             0.565425            0.123626   0.503681  0.872754  139  32  13   \n",
              "2             0.624954            0.104396   0.579165  0.892844  143  23  15   \n",
              "\n",
              "    TP  Global Score  \n",
              "0  614        100.00  \n",
              "1  180         83.82  \n",
              "2  183         86.24  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_name = \"Random Forest\"\n",
        "print(model_name)\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "rf_params = {\n",
        "    \"n_estimators\": [100, 200, 300, 400, 500],  \n",
        "    \"max_depth\": [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],  \n",
        "    \"max_features\": [None, \"sqrt\", \"log2\"], \n",
        "    \"min_samples_split\": [2, 5, 10], \n",
        "    \"min_samples_leaf\": [1, 2, 4], \n",
        "    \"bootstrap\": [True, False]  \n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=RF,\n",
        "                                   param_distributions=rf_params,\n",
        "                                   n_iter=100,  \n",
        "                                   cv=5,  \n",
        "                                   verbose=0, \n",
        "                                   random_state=42,\n",
        "                                   n_jobs=-1) \n",
        "\n",
        "random_search.fit(X_train_prep, y_train)\n",
        "\n",
        "print(\"Mejores parámetros encontrados:\", random_search.best_params_)\n",
        "\n",
        "model_RF = random_search.best_estimator_\n",
        "\n",
        "model_RF.fit(X_train_prep, y_train)\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model_RF, X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = model_RF.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_val_pred = model_RF.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = model_RF.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN\n",
            "Best parameters for KNN:  {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.8522\n",
            " - Precision: 0.8564\n",
            " - Recall: 0.8522\n",
            " - F1-Score: 0.8527\n",
            " - Adjusted Rand Index: 0.4956\n",
            " - Mean Squared Error: 0.1478\n",
            " - R-squared: 0.3988\n",
            " - Área bajo la curva : 0.855\n",
            " - Confusion Matrix: \n",
            "[[418  57]\n",
            " [104 510]]\n",
            " - Global Score : 81.04\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.7857\n",
            " - Precision: 0.7873\n",
            " - Recall: 0.7857\n",
            " - F1-Score: 0.7859\n",
            " - Adjusted Rand Index: 0.3247\n",
            " - Mean Squared Error: 0.2143\n",
            " - R-squared: 0.1397\n",
            " - Área bajo la curva : 0.787\n",
            " - Confusion Matrix: \n",
            "[[137  34]\n",
            " [ 44 149]]\n",
            " - Global Score : 72.93\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.7940\n",
            " - Precision: 0.8000\n",
            " - Recall: 0.7940\n",
            " - F1-Score: 0.7943\n",
            " - Adjusted Rand Index: 0.3438\n",
            " - Mean Squared Error: 0.2060\n",
            " - R-squared: 0.1694\n",
            " - Área bajo la curva : 0.797\n",
            " - Confusion Matrix: \n",
            "[[139  27]\n",
            " [ 48 150]]\n",
            " - Global Score : 74.04\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.856418</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.852701</td>\n",
              "      <td>0.495592</td>\n",
              "      <td>0.147842</td>\n",
              "      <td>0.398838</td>\n",
              "      <td>0.855309</td>\n",
              "      <td>418</td>\n",
              "      <td>57</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>81.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.787289</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785909</td>\n",
              "      <td>0.324677</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.139715</td>\n",
              "      <td>0.786595</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>44</td>\n",
              "      <td>149</td>\n",
              "      <td>72.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.799964</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.794316</td>\n",
              "      <td>0.343845</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.797463</td>\n",
              "      <td>139</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>150</td>\n",
              "      <td>74.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "1      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "2      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "3      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "4      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "5      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "6   Regresión Logística    Training  0.835629   0.843677  0.835629  0.836301   \n",
              "7   Regresión Logística  Validation  0.826923   0.828750  0.826923  0.827081   \n",
              "8   Regresión Logística        Test  0.826923   0.839082  0.826923  0.826964   \n",
              "9                   KNN    Training  0.852158   0.856418  0.852158  0.852701   \n",
              "10                  KNN  Validation  0.785714   0.787289  0.785714  0.785909   \n",
              "11                  KNN        Test  0.793956   0.799964  0.793956  0.794316   \n",
              "\n",
              "    Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  \\\n",
              "0              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "1              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "2              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "3              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "4              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "5              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "6              0.450090            0.164371   0.331627  0.841128  420  55   \n",
              "7              0.425939            0.173077   0.305154  0.828122  145  26   \n",
              "8              0.425926            0.173077   0.302300  0.833120  150  16   \n",
              "9              0.495592            0.147842   0.398838  0.855309  418  57   \n",
              "10             0.324677            0.214286   0.139715  0.786595  137  34   \n",
              "11             0.343845            0.206044   0.169405  0.797463  139  27   \n",
              "\n",
              "     FN   TP  Global Score  \n",
              "0   186  428         74.81  \n",
              "1    49  144         76.76  \n",
              "2    66  132         74.65  \n",
              "3   186  428         74.81  \n",
              "4    49  144         76.76  \n",
              "5    66  132         74.65  \n",
              "6   124  490         79.14  \n",
              "7    37  156         77.87  \n",
              "8    47  151         78.15  \n",
              "9   104  510         81.04  \n",
              "10   44  149         72.93  \n",
              "11   48  150         74.04  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "model_name = \"KNN\"\n",
        "print(model_name)\n",
        "# Parámetros de búsqueda para KNN\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy')\n",
        "grid_search_knn.fit(X_train_prep, y_train)\n",
        "\n",
        "print(\"Best parameters for KNN: \", grid_search_knn.best_params_)\n",
        "\n",
        "y_train_pred = grid_search_knn.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_val_pred = grid_search_knn.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = grid_search_knn.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVN\n",
            "      CA19-9 (U/ml)  CA-125 (U/ml)  HGF (pg/ml)  OPN (pg/ml)  Omega score  \\\n",
            "1333      -0.092602      -0.107994    -0.309247     0.050290    -0.143176   \n",
            "1784      -0.092321      16.603266     0.504689     3.463351     0.336480   \n",
            "1465      -0.092602      -0.106787    -0.057182    -0.739401    -0.163334   \n",
            "1252      -0.092602      -0.107994    -0.309247    -0.413678    -0.177269   \n",
            "53        -0.092251      -0.107994    -0.312427    -0.139405    -0.158614   \n",
            "...             ...            ...          ...          ...          ...   \n",
            "797       -0.091747      -0.108175    -0.287776     0.012175    -0.155475   \n",
            "1669      -0.093555      -0.109863    -0.319221    -0.389669    -0.167576   \n",
            "766       -0.086317      -0.074770     0.218594     1.107403    -0.122682   \n",
            "75        -0.092251      -0.107994    -0.312427    -0.024325    -0.058391   \n",
            "1541      -0.053513      -0.096282    -0.280971    -0.422183    -0.132929   \n",
            "\n",
            "      Prolactin (pg/ml)  CEA (pg/ml)  Myeloperoxidase (ng/ml)  TIMP-1 (pg/ml)  \n",
            "1333          -0.362952    -0.130982                -0.250333       -1.017092  \n",
            "1784           0.506493    -0.116108                 0.069232        1.860676  \n",
            "1465          -0.385378    -0.129505                -0.321950       -0.224166  \n",
            "1252          -0.325200    -0.110392                -0.361861       -0.472180  \n",
            "53            -0.333856    -0.156455                -0.283847       -0.709295  \n",
            "...                 ...          ...                      ...             ...  \n",
            "797           -0.168136    -0.104257                -0.190397       -0.569358  \n",
            "1669          -0.438204    -0.111057                -0.371178       -0.205878  \n",
            "766           -0.286075    -0.142170                -0.170511        0.129632  \n",
            "75            -0.440049    -0.082846                -0.342670       -0.468926  \n",
            "1541          -0.448495    -0.139981                -0.341140        0.000447  \n",
            "\n",
            "[1089 rows x 9 columns]\n",
            "Mejores parámetros:  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.8466\n",
            " - Precision: 0.8501\n",
            " - Recall: 0.8466\n",
            " - F1-Score: 0.8472\n",
            " - Adjusted Rand Index: 0.4802\n",
            " - Mean Squared Error: 0.1534\n",
            " - R-squared: 0.3764\n",
            " - Área bajo la curva : 0.849\n",
            " - Confusion Matrix: \n",
            "[[412  63]\n",
            " [104 510]]\n",
            " - Global Score : 80.33\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8214\n",
            " - Precision: 0.8213\n",
            " - Recall: 0.8214\n",
            " - F1-Score: 0.8213\n",
            " - Adjusted Rand Index: 0.4116\n",
            " - Mean Squared Error: 0.1786\n",
            " - R-squared: 0.2831\n",
            " - Área bajo la curva : 0.820\n",
            " - Confusion Matrix: \n",
            "[[137  34]\n",
            " [ 31 162]]\n",
            " - Global Score : 77.11\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8214\n",
            " - Precision: 0.8266\n",
            " - Recall: 0.8214\n",
            " - F1-Score: 0.8218\n",
            " - Adjusted Rand Index: 0.4117\n",
            " - Mean Squared Error: 0.1786\n",
            " - R-squared: 0.2802\n",
            " - Área bajo la curva : 0.825\n",
            " - Confusion Matrix: \n",
            "[[143  23]\n",
            " [ 42 156]]\n",
            " - Global Score : 77.31\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.856418</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.852701</td>\n",
              "      <td>0.495592</td>\n",
              "      <td>0.147842</td>\n",
              "      <td>0.398838</td>\n",
              "      <td>0.855309</td>\n",
              "      <td>418</td>\n",
              "      <td>57</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>81.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.787289</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785909</td>\n",
              "      <td>0.324677</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.139715</td>\n",
              "      <td>0.786595</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>44</td>\n",
              "      <td>149</td>\n",
              "      <td>72.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.799964</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.794316</td>\n",
              "      <td>0.343845</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.797463</td>\n",
              "      <td>139</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>150</td>\n",
              "      <td>74.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.846648</td>\n",
              "      <td>0.850097</td>\n",
              "      <td>0.846648</td>\n",
              "      <td>0.847172</td>\n",
              "      <td>0.480168</td>\n",
              "      <td>0.153352</td>\n",
              "      <td>0.376434</td>\n",
              "      <td>0.848994</td>\n",
              "      <td>412</td>\n",
              "      <td>63</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>80.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821337</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821327</td>\n",
              "      <td>0.411647</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.283095</td>\n",
              "      <td>0.820274</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>77.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.826572</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821762</td>\n",
              "      <td>0.411656</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.280151</td>\n",
              "      <td>0.824662</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>156</td>\n",
              "      <td>77.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "1      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "2      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "3      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "4      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "5      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "6   Regresión Logística    Training  0.835629   0.843677  0.835629  0.836301   \n",
              "7   Regresión Logística  Validation  0.826923   0.828750  0.826923  0.827081   \n",
              "8   Regresión Logística        Test  0.826923   0.839082  0.826923  0.826964   \n",
              "9                   KNN    Training  0.852158   0.856418  0.852158  0.852701   \n",
              "10                  KNN  Validation  0.785714   0.787289  0.785714  0.785909   \n",
              "11                  KNN        Test  0.793956   0.799964  0.793956  0.794316   \n",
              "12                  SVN    Training  0.846648   0.850097  0.846648  0.847172   \n",
              "13                  SVN  Validation  0.821429   0.821337  0.821429  0.821327   \n",
              "14                  SVN        Test  0.821429   0.826572  0.821429  0.821762   \n",
              "\n",
              "    Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  \\\n",
              "0              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "1              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "2              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "3              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "4              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "5              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "6              0.450090            0.164371   0.331627  0.841128  420  55   \n",
              "7              0.425939            0.173077   0.305154  0.828122  145  26   \n",
              "8              0.425926            0.173077   0.302300  0.833120  150  16   \n",
              "9              0.495592            0.147842   0.398838  0.855309  418  57   \n",
              "10             0.324677            0.214286   0.139715  0.786595  137  34   \n",
              "11             0.343845            0.206044   0.169405  0.797463  139  27   \n",
              "12             0.480168            0.153352   0.376434  0.848994  412  63   \n",
              "13             0.411647            0.178571   0.283095  0.820274  137  34   \n",
              "14             0.411656            0.178571   0.280151  0.824662  143  23   \n",
              "\n",
              "     FN   TP  Global Score  \n",
              "0   186  428         74.81  \n",
              "1    49  144         76.76  \n",
              "2    66  132         74.65  \n",
              "3   186  428         74.81  \n",
              "4    49  144         76.76  \n",
              "5    66  132         74.65  \n",
              "6   124  490         79.14  \n",
              "7    37  156         77.87  \n",
              "8    47  151         78.15  \n",
              "9   104  510         81.04  \n",
              "10   44  149         72.93  \n",
              "11   48  150         74.04  \n",
              "12  104  510         80.33  \n",
              "13   31  162         77.11  \n",
              "14   42  156         77.31  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model_name = \"SVN\"\n",
        "print(model_name)\n",
        "# Define la cuadrícula de parámetros para buscar\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Crea un objeto GridSearchCV\n",
        "grid_search_svm = GridSearchCV(SVC(), param_grid, refit=True)\n",
        "print(X_train_prep)\n",
        "# Ajusta el objeto GridSearchCV a los datos\n",
        "grid_search_svm.fit(X_train_prep, y_train)\n",
        "\n",
        "# Imprime los mejores parámetros\n",
        "print(\"Mejores parámetros: \", grid_search_svm.best_params_)\n",
        "\n",
        "y_train_pred = grid_search_svm.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_val_pred = grid_search_svm.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = grid_search_svm.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gaussiano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes - Gaussian\n",
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.47891314 -0.48367856 -0.48367856 -0.49307126 -0.52583048]\n",
            "Média métricas de validación cruzada: -0.49303440260524434\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.7594\n",
            " - Precision: 0.8315\n",
            " - Recall: 0.7594\n",
            " - F1-Score: 0.7543\n",
            " - Adjusted Rand Index: 0.2674\n",
            " - Mean Squared Error: 0.2406\n",
            " - R-squared: 0.0217\n",
            " - Área bajo la curva : 0.784\n",
            " - Confusion Matrix: \n",
            "[[465  10]\n",
            " [252 362]]\n",
            " - Global Score : 71.38\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.7665\n",
            " - Precision: 0.8093\n",
            " - Recall: 0.7665\n",
            " - F1-Score: 0.7615\n",
            " - Adjusted Rand Index: 0.2820\n",
            " - Mean Squared Error: 0.2335\n",
            " - R-squared: 0.0625\n",
            " - Área bajo la curva : 0.776\n",
            " - Confusion Matrix: \n",
            "[[161  10]\n",
            " [ 75 118]]\n",
            " - Global Score : 71.4\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.7582\n",
            " - Precision: 0.8154\n",
            " - Recall: 0.7582\n",
            " - F1-Score: 0.7525\n",
            " - Adjusted Rand Index: 0.2644\n",
            " - Mean Squared Error: 0.2418\n",
            " - R-squared: 0.0254\n",
            " - Área bajo la curva : 0.774\n",
            " - Confusion Matrix: \n",
            "[[159   7]\n",
            " [ 81 117]]\n",
            " - Global Score : 70.79\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Naive Bayes - Bernouilli</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Naive Bayes - Bernouilli</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Naive Bayes - Bernouilli</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.759412</td>\n",
              "      <td>0.831542</td>\n",
              "      <td>0.759412</td>\n",
              "      <td>0.754310</td>\n",
              "      <td>0.267385</td>\n",
              "      <td>0.240588</td>\n",
              "      <td>0.021711</td>\n",
              "      <td>0.784262</td>\n",
              "      <td>465</td>\n",
              "      <td>10</td>\n",
              "      <td>252</td>\n",
              "      <td>362</td>\n",
              "      <td>71.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.766484</td>\n",
              "      <td>0.809282</td>\n",
              "      <td>0.766484</td>\n",
              "      <td>0.761488</td>\n",
              "      <td>0.282026</td>\n",
              "      <td>0.233516</td>\n",
              "      <td>0.062509</td>\n",
              "      <td>0.776460</td>\n",
              "      <td>161</td>\n",
              "      <td>10</td>\n",
              "      <td>75</td>\n",
              "      <td>118</td>\n",
              "      <td>71.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.815378</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.752494</td>\n",
              "      <td>0.264371</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.025435</td>\n",
              "      <td>0.774370</td>\n",
              "      <td>159</td>\n",
              "      <td>7</td>\n",
              "      <td>81</td>\n",
              "      <td>117</td>\n",
              "      <td>70.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Naive Bayes - Bernoulli</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.814509</td>\n",
              "      <td>0.820274</td>\n",
              "      <td>0.814509</td>\n",
              "      <td>0.815240</td>\n",
              "      <td>0.395110</td>\n",
              "      <td>0.185491</td>\n",
              "      <td>0.245747</td>\n",
              "      <td>0.818109</td>\n",
              "      <td>402</td>\n",
              "      <td>73</td>\n",
              "      <td>129</td>\n",
              "      <td>485</td>\n",
              "      <td>76.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Naive Bayes - Bernoulli</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.791105</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.791133</td>\n",
              "      <td>0.337388</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.161773</td>\n",
              "      <td>0.790110</td>\n",
              "      <td>132</td>\n",
              "      <td>39</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>73.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Naive Bayes - Bernoulli</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.833036</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827225</td>\n",
              "      <td>0.425943</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.830686</td>\n",
              "      <td>145</td>\n",
              "      <td>21</td>\n",
              "      <td>42</td>\n",
              "      <td>156</td>\n",
              "      <td>78.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Naive Bayes - Multinomial</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.814509</td>\n",
              "      <td>0.820274</td>\n",
              "      <td>0.814509</td>\n",
              "      <td>0.815240</td>\n",
              "      <td>0.395110</td>\n",
              "      <td>0.185491</td>\n",
              "      <td>0.245747</td>\n",
              "      <td>0.818109</td>\n",
              "      <td>402</td>\n",
              "      <td>73</td>\n",
              "      <td>129</td>\n",
              "      <td>485</td>\n",
              "      <td>76.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Naive Bayes - Multinomial</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.791105</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.791133</td>\n",
              "      <td>0.337388</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.161773</td>\n",
              "      <td>0.790110</td>\n",
              "      <td>132</td>\n",
              "      <td>39</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>73.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Naive Bayes - Multinomial</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.833036</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827225</td>\n",
              "      <td>0.425943</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.830686</td>\n",
              "      <td>145</td>\n",
              "      <td>21</td>\n",
              "      <td>42</td>\n",
              "      <td>156</td>\n",
              "      <td>78.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Naive Bayes - Gaussian</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.759412</td>\n",
              "      <td>0.831542</td>\n",
              "      <td>0.759412</td>\n",
              "      <td>0.754310</td>\n",
              "      <td>0.267385</td>\n",
              "      <td>0.240588</td>\n",
              "      <td>0.021711</td>\n",
              "      <td>0.784262</td>\n",
              "      <td>465</td>\n",
              "      <td>10</td>\n",
              "      <td>252</td>\n",
              "      <td>362</td>\n",
              "      <td>71.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Naive Bayes - Gaussian</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.766484</td>\n",
              "      <td>0.809282</td>\n",
              "      <td>0.766484</td>\n",
              "      <td>0.761488</td>\n",
              "      <td>0.282026</td>\n",
              "      <td>0.233516</td>\n",
              "      <td>0.062509</td>\n",
              "      <td>0.776460</td>\n",
              "      <td>161</td>\n",
              "      <td>10</td>\n",
              "      <td>75</td>\n",
              "      <td>118</td>\n",
              "      <td>71.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Naive Bayes - Gaussian</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.815378</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.752494</td>\n",
              "      <td>0.264371</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.025435</td>\n",
              "      <td>0.774370</td>\n",
              "      <td>159</td>\n",
              "      <td>7</td>\n",
              "      <td>81</td>\n",
              "      <td>117</td>\n",
              "      <td>70.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Model         Set  Accuracy  Precision    Recall  \\\n",
              "0            Regresion Lineal    Training  0.795225   0.825122  0.795225   \n",
              "1            Regresion Lineal  Validation  0.815934   0.827130  0.815934   \n",
              "2            Regresion Lineal        Test  0.793956   0.830307  0.793956   \n",
              "3            Regresion Lineal    Training  0.795225   0.825122  0.795225   \n",
              "4            Regresion Lineal  Validation  0.815934   0.827130  0.815934   \n",
              "5            Regresion Lineal        Test  0.793956   0.830307  0.793956   \n",
              "6         Regresión Logística    Training  0.835629   0.843677  0.835629   \n",
              "7         Regresión Logística  Validation  0.826923   0.828750  0.826923   \n",
              "8         Regresión Logística        Test  0.826923   0.839082  0.826923   \n",
              "9         Regresión Logística    Training  0.835629   0.843677  0.835629   \n",
              "10        Regresión Logística  Validation  0.826923   0.828750  0.826923   \n",
              "11        Regresión Logística        Test  0.826923   0.839082  0.826923   \n",
              "12                Naive Bayes    Training  0.835629   0.843677  0.835629   \n",
              "13                Naive Bayes  Validation  0.826923   0.828750  0.826923   \n",
              "14                Naive Bayes        Test  0.826923   0.839082  0.826923   \n",
              "15                Naive Bayes    Training  0.835629   0.843677  0.835629   \n",
              "16                Naive Bayes  Validation  0.826923   0.828750  0.826923   \n",
              "17                Naive Bayes        Test  0.826923   0.839082  0.826923   \n",
              "18                Naive Bayes    Training  0.835629   0.843677  0.835629   \n",
              "19                Naive Bayes  Validation  0.826923   0.828750  0.826923   \n",
              "20                Naive Bayes        Test  0.826923   0.839082  0.826923   \n",
              "21                Naive Bayes    Training  0.835629   0.843677  0.835629   \n",
              "22                Naive Bayes  Validation  0.826923   0.828750  0.826923   \n",
              "23                Naive Bayes        Test  0.826923   0.839082  0.826923   \n",
              "24                Naive Bayes    Training  0.835629   0.843677  0.835629   \n",
              "25                Naive Bayes  Validation  0.826923   0.828750  0.826923   \n",
              "26                Naive Bayes        Test  0.826923   0.839082  0.826923   \n",
              "27   Naive Bayes - Bernouilli    Training  0.835629   0.843677  0.835629   \n",
              "28   Naive Bayes - Bernouilli  Validation  0.826923   0.828750  0.826923   \n",
              "29   Naive Bayes - Bernouilli        Test  0.826923   0.839082  0.826923   \n",
              "30                Naive Bayes    Training  0.759412   0.831542  0.759412   \n",
              "31                Naive Bayes  Validation  0.766484   0.809282  0.766484   \n",
              "32                Naive Bayes        Test  0.758242   0.815378  0.758242   \n",
              "33    Naive Bayes - Bernoulli    Training  0.814509   0.820274  0.814509   \n",
              "34    Naive Bayes - Bernoulli  Validation  0.791209   0.791105  0.791209   \n",
              "35    Naive Bayes - Bernoulli        Test  0.826923   0.833036  0.826923   \n",
              "36  Naive Bayes - Multinomial    Training  0.814509   0.820274  0.814509   \n",
              "37  Naive Bayes - Multinomial  Validation  0.791209   0.791105  0.791209   \n",
              "38  Naive Bayes - Multinomial        Test  0.826923   0.833036  0.826923   \n",
              "39     Naive Bayes - Gaussian    Training  0.759412   0.831542  0.759412   \n",
              "40     Naive Bayes - Gaussian  Validation  0.766484   0.809282  0.766484   \n",
              "41     Naive Bayes - Gaussian        Test  0.758242   0.815378  0.758242   \n",
              "\n",
              "    F1-Score  Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC  \\\n",
              "0   0.794968             0.347828            0.204775   0.167334  0.809587   \n",
              "1   0.815546             0.397597            0.184066   0.261037  0.820425   \n",
              "2   0.791730             0.343680            0.206044   0.169405  0.806225   \n",
              "3   0.794968             0.347828            0.204775   0.167334  0.809587   \n",
              "4   0.815546             0.397597            0.184066   0.261037  0.820425   \n",
              "5   0.791730             0.343680            0.206044   0.169405  0.806225   \n",
              "6   0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "7   0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "8   0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "9   0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "10  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "11  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "12  0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "13  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "14  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "15  0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "16  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "17  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "18  0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "19  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "20  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "21  0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "22  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "23  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "24  0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "25  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "26  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "27  0.836301             0.450090            0.164371   0.331627  0.841128   \n",
              "28  0.827081             0.425939            0.173077   0.305154  0.828122   \n",
              "29  0.826964             0.425926            0.173077   0.302300  0.833120   \n",
              "30  0.754310             0.267385            0.240588   0.021711  0.784262   \n",
              "31  0.761488             0.282026            0.233516   0.062509  0.776460   \n",
              "32  0.752494             0.264371            0.241758   0.025435  0.774370   \n",
              "33  0.815240             0.395110            0.185491   0.245747  0.818109   \n",
              "34  0.791133             0.337388            0.208791   0.161773  0.790110   \n",
              "35  0.827225             0.425943            0.173077   0.302300  0.830686   \n",
              "36  0.815240             0.395110            0.185491   0.245747  0.818109   \n",
              "37  0.791133             0.337388            0.208791   0.161773  0.790110   \n",
              "38  0.827225             0.425943            0.173077   0.302300  0.830686   \n",
              "39  0.754310             0.267385            0.240588   0.021711  0.784262   \n",
              "40  0.761488             0.282026            0.233516   0.062509  0.776460   \n",
              "41  0.752494             0.264371            0.241758   0.025435  0.774370   \n",
              "\n",
              "     TN  FP   FN   TP  Global Score  \n",
              "0   438  37  186  428         74.81  \n",
              "1   153  18   49  144         76.76  \n",
              "2   157   9   66  132         74.65  \n",
              "3   438  37  186  428         74.81  \n",
              "4   153  18   49  144         76.76  \n",
              "5   157   9   66  132         74.65  \n",
              "6   420  55  124  490         79.14  \n",
              "7   145  26   37  156         77.87  \n",
              "8   150  16   47  151         78.15  \n",
              "9   420  55  124  490         79.14  \n",
              "10  145  26   37  156         77.87  \n",
              "11  150  16   47  151         78.15  \n",
              "12  420  55  124  490         79.14  \n",
              "13  145  26   37  156         77.87  \n",
              "14  150  16   47  151         78.15  \n",
              "15  420  55  124  490         79.14  \n",
              "16  145  26   37  156         77.87  \n",
              "17  150  16   47  151         78.15  \n",
              "18  420  55  124  490         79.14  \n",
              "19  145  26   37  156         77.87  \n",
              "20  150  16   47  151         78.15  \n",
              "21  420  55  124  490         79.14  \n",
              "22  145  26   37  156         77.87  \n",
              "23  150  16   47  151         78.15  \n",
              "24  420  55  124  490         79.14  \n",
              "25  145  26   37  156         77.87  \n",
              "26  150  16   47  151         78.15  \n",
              "27  420  55  124  490         79.14  \n",
              "28  145  26   37  156         77.87  \n",
              "29  150  16   47  151         78.15  \n",
              "30  465  10  252  362         71.38  \n",
              "31  161  10   75  118         71.40  \n",
              "32  159   7   81  117         70.79  \n",
              "33  402  73  129  485         76.49  \n",
              "34  132  39   37  156         73.49  \n",
              "35  145  21   42  156         78.00  \n",
              "36  402  73  129  485         76.49  \n",
              "37  132  39   37  156         73.49  \n",
              "38  145  21   42  156         78.00  \n",
              "39  465  10  252  362         71.38  \n",
              "40  161  10   75  118         71.40  \n",
              "41  159   7   81  117         70.79  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model_NB = GaussianNB(var_smoothing=1e-9)\n",
        "model_name = \"Naive Bayes - Gaussian\"\n",
        "print(model_name)\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model_NB, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_NB.fit(X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = model_NB.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_pred = model_NB.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = model_NB.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bernouilli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "model_NB = BernoulliNB()\n",
        "model_name = \"Naive Bayes - Bernoulli\"\n",
        "print(model_name)\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model_NB, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_NB.fit(X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = model_NB.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_pred = model_NB.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = model_NB.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AdaBoost 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.35838578 -0.27091418 -0.31037119 -0.30289127 -0.27153769]\n",
            "Média métricas de validación cruzada: -0.30282002265725105\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 1.0000\n",
            " - Precision: 1.0000\n",
            " - Recall: 1.0000\n",
            " - F1-Score: 1.0000\n",
            " - Adjusted Rand Index: 1.0000\n",
            " - Mean Squared Error: 0.0000\n",
            " - R-squared: 1.0000\n",
            " - Área bajo la curva : 1.000\n",
            " - Confusion Matrix: \n",
            "[[475   0]\n",
            " [  0 614]]\n",
            " - Global Score : 100.0\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8901\n",
            " - Precision: 0.8906\n",
            " - Recall: 0.8901\n",
            " - F1-Score: 0.8899\n",
            " - Adjusted Rand Index: 0.6077\n",
            " - Mean Squared Error: 0.1099\n",
            " - R-squared: 0.5588\n",
            " - Área bajo la curva : 0.888\n",
            " - Confusion Matrix: \n",
            "[[147  24]\n",
            " [ 16 177]]\n",
            " - Global Score : 85.58\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.9286\n",
            " - Precision: 0.9287\n",
            " - Recall: 0.9286\n",
            " - F1-Score: 0.9286\n",
            " - Adjusted Rand Index: 0.7340\n",
            " - Mean Squared Error: 0.0714\n",
            " - R-squared: 0.7121\n",
            " - Área bajo la curva : 0.929\n",
            " - Confusion Matrix: \n",
            "[[154  12]\n",
            " [ 14 184]]\n",
            " - Global Score : 90.55\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.856418</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.852701</td>\n",
              "      <td>0.495592</td>\n",
              "      <td>0.147842</td>\n",
              "      <td>0.398838</td>\n",
              "      <td>0.855309</td>\n",
              "      <td>418</td>\n",
              "      <td>57</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>81.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.787289</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785909</td>\n",
              "      <td>0.324677</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.139715</td>\n",
              "      <td>0.786595</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>44</td>\n",
              "      <td>149</td>\n",
              "      <td>72.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.799964</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.794316</td>\n",
              "      <td>0.343845</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.797463</td>\n",
              "      <td>139</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>150</td>\n",
              "      <td>74.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.846648</td>\n",
              "      <td>0.850097</td>\n",
              "      <td>0.846648</td>\n",
              "      <td>0.847172</td>\n",
              "      <td>0.480168</td>\n",
              "      <td>0.153352</td>\n",
              "      <td>0.376434</td>\n",
              "      <td>0.848994</td>\n",
              "      <td>412</td>\n",
              "      <td>63</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>80.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821337</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821327</td>\n",
              "      <td>0.411647</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.283095</td>\n",
              "      <td>0.820274</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>77.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.826572</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821762</td>\n",
              "      <td>0.411656</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.280151</td>\n",
              "      <td>0.824662</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>156</td>\n",
              "      <td>77.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>AdaBoost 1</td>\n",
              "      <td>Training</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>614</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>AdaBoost 1</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.890110</td>\n",
              "      <td>0.890577</td>\n",
              "      <td>0.890110</td>\n",
              "      <td>0.889909</td>\n",
              "      <td>0.607662</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.558828</td>\n",
              "      <td>0.888374</td>\n",
              "      <td>147</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>177</td>\n",
              "      <td>85.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AdaBoost 1</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928693</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928604</td>\n",
              "      <td>0.733959</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.712060</td>\n",
              "      <td>0.928502</td>\n",
              "      <td>154</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>184</td>\n",
              "      <td>90.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "1      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "2      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "3      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "4      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "5      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "6   Regresión Logística    Training  0.835629   0.843677  0.835629  0.836301   \n",
              "7   Regresión Logística  Validation  0.826923   0.828750  0.826923  0.827081   \n",
              "8   Regresión Logística        Test  0.826923   0.839082  0.826923  0.826964   \n",
              "9                   KNN    Training  0.852158   0.856418  0.852158  0.852701   \n",
              "10                  KNN  Validation  0.785714   0.787289  0.785714  0.785909   \n",
              "11                  KNN        Test  0.793956   0.799964  0.793956  0.794316   \n",
              "12                  SVN    Training  0.846648   0.850097  0.846648  0.847172   \n",
              "13                  SVN  Validation  0.821429   0.821337  0.821429  0.821327   \n",
              "14                  SVN        Test  0.821429   0.826572  0.821429  0.821762   \n",
              "15           AdaBoost 1    Training  1.000000   1.000000  1.000000  1.000000   \n",
              "16           AdaBoost 1  Validation  0.890110   0.890577  0.890110  0.889909   \n",
              "17           AdaBoost 1        Test  0.928571   0.928693  0.928571  0.928604   \n",
              "\n",
              "    Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  \\\n",
              "0              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "1              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "2              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "3              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "4              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "5              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "6              0.450090            0.164371   0.331627  0.841128  420  55   \n",
              "7              0.425939            0.173077   0.305154  0.828122  145  26   \n",
              "8              0.425926            0.173077   0.302300  0.833120  150  16   \n",
              "9              0.495592            0.147842   0.398838  0.855309  418  57   \n",
              "10             0.324677            0.214286   0.139715  0.786595  137  34   \n",
              "11             0.343845            0.206044   0.169405  0.797463  139  27   \n",
              "12             0.480168            0.153352   0.376434  0.848994  412  63   \n",
              "13             0.411647            0.178571   0.283095  0.820274  137  34   \n",
              "14             0.411656            0.178571   0.280151  0.824662  143  23   \n",
              "15             1.000000            0.000000   1.000000  1.000000  475   0   \n",
              "16             0.607662            0.109890   0.558828  0.888374  147  24   \n",
              "17             0.733959            0.071429   0.712060  0.928502  154  12   \n",
              "\n",
              "     FN   TP  Global Score  \n",
              "0   186  428         74.81  \n",
              "1    49  144         76.76  \n",
              "2    66  132         74.65  \n",
              "3   186  428         74.81  \n",
              "4    49  144         76.76  \n",
              "5    66  132         74.65  \n",
              "6   124  490         79.14  \n",
              "7    37  156         77.87  \n",
              "8    47  151         78.15  \n",
              "9   104  510         81.04  \n",
              "10   44  149         72.93  \n",
              "11   48  150         74.04  \n",
              "12  104  510         80.33  \n",
              "13   31  162         77.11  \n",
              "14   42  156         77.31  \n",
              "15    0  614        100.00  \n",
              "16   16  177         85.58  \n",
              "17   14  184         90.55  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model_name = \"AdaBoost 1\"\n",
        "print(model_name)\n",
        "\n",
        "# Inicializar el clasificador débil (stump)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=2) # max_depth=1 menos sobreajuste, resultados ligeramente peores \n",
        "\n",
        "# Inicializar el modelo AdaBoost\n",
        "model = AdaBoostClassifier(estimator=base_estimator, n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(model, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model.fit(X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_pred = model.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = model.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AdaBoost 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros: {'learning_rate': 0.07, 'n_estimators': 200}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.28734789 -0.21417647 -0.25341701 -0.23461857 -0.24476077]\n",
            "Média métricas de validación cruzada: -0.24686414084382471\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for Training set :\n",
            " - Accuracy: 0.9780\n",
            " - Precision: 0.9780\n",
            " - Recall: 0.9780\n",
            " - F1-Score: 0.9780\n",
            " - Adjusted Rand Index: 0.9137\n",
            " - Mean Squared Error: 0.0220\n",
            " - R-squared: 0.9104\n",
            " - Área bajo la curva : 0.977\n",
            " - Confusion Matrix: \n",
            "[[462  13]\n",
            " [ 11 603]]\n",
            " - Global Score : 97.02\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.9286\n",
            " - Precision: 0.9292\n",
            " - Recall: 0.9286\n",
            " - F1-Score: 0.9284\n",
            " - Adjusted Rand Index: 0.7340\n",
            " - Mean Squared Error: 0.0714\n",
            " - R-squared: 0.7132\n",
            " - Área bajo la curva : 0.927\n",
            " - Confusion Matrix: \n",
            "[[154  17]\n",
            " [  9 184]]\n",
            " - Global Score : 90.51\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.9423\n",
            " - Precision: 0.9423\n",
            " - Recall: 0.9423\n",
            " - F1-Score: 0.9423\n",
            " - Adjusted Rand Index: 0.7819\n",
            " - Mean Squared Error: 0.0577\n",
            " - R-squared: 0.7674\n",
            " - Área bajo la curva : 0.941\n",
            " - Confusion Matrix: \n",
            "[[154  12]\n",
            " [  9 189]]\n",
            " - Global Score : 92.3\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.827130</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815546</td>\n",
              "      <td>0.397597</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.820425</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>76.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Regresion Lineal</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.830307</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.791730</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.806225</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>66</td>\n",
              "      <td>132</td>\n",
              "      <td>74.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.843677</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836301</td>\n",
              "      <td>0.450090</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.841128</td>\n",
              "      <td>420</td>\n",
              "      <td>55</td>\n",
              "      <td>124</td>\n",
              "      <td>490</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827081</td>\n",
              "      <td>0.425939</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.828122</td>\n",
              "      <td>145</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>156</td>\n",
              "      <td>77.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regresión Logística</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.839082</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826964</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.833120</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>78.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.856418</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>0.852701</td>\n",
              "      <td>0.495592</td>\n",
              "      <td>0.147842</td>\n",
              "      <td>0.398838</td>\n",
              "      <td>0.855309</td>\n",
              "      <td>418</td>\n",
              "      <td>57</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>81.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.787289</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785909</td>\n",
              "      <td>0.324677</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.139715</td>\n",
              "      <td>0.786595</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>44</td>\n",
              "      <td>149</td>\n",
              "      <td>72.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.799964</td>\n",
              "      <td>0.793956</td>\n",
              "      <td>0.794316</td>\n",
              "      <td>0.343845</td>\n",
              "      <td>0.206044</td>\n",
              "      <td>0.169405</td>\n",
              "      <td>0.797463</td>\n",
              "      <td>139</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>150</td>\n",
              "      <td>74.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.846648</td>\n",
              "      <td>0.850097</td>\n",
              "      <td>0.846648</td>\n",
              "      <td>0.847172</td>\n",
              "      <td>0.480168</td>\n",
              "      <td>0.153352</td>\n",
              "      <td>0.376434</td>\n",
              "      <td>0.848994</td>\n",
              "      <td>412</td>\n",
              "      <td>63</td>\n",
              "      <td>104</td>\n",
              "      <td>510</td>\n",
              "      <td>80.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821337</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821327</td>\n",
              "      <td>0.411647</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.283095</td>\n",
              "      <td>0.820274</td>\n",
              "      <td>137</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>77.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.826572</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.821762</td>\n",
              "      <td>0.411656</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.280151</td>\n",
              "      <td>0.824662</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>156</td>\n",
              "      <td>77.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>AdaBoost 1</td>\n",
              "      <td>Training</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>614</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>AdaBoost 1</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.890110</td>\n",
              "      <td>0.890577</td>\n",
              "      <td>0.890110</td>\n",
              "      <td>0.889909</td>\n",
              "      <td>0.607662</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.558828</td>\n",
              "      <td>0.888374</td>\n",
              "      <td>147</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>177</td>\n",
              "      <td>85.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>AdaBoost 1</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928693</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928604</td>\n",
              "      <td>0.733959</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.712060</td>\n",
              "      <td>0.928502</td>\n",
              "      <td>154</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>184</td>\n",
              "      <td>90.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>AdaBoost 2</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.977961</td>\n",
              "      <td>0.977957</td>\n",
              "      <td>0.977961</td>\n",
              "      <td>0.977956</td>\n",
              "      <td>0.913688</td>\n",
              "      <td>0.022039</td>\n",
              "      <td>0.910386</td>\n",
              "      <td>0.977358</td>\n",
              "      <td>462</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>603</td>\n",
              "      <td>97.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>AdaBoost 2</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.929217</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928441</td>\n",
              "      <td>0.733961</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.713238</td>\n",
              "      <td>0.926976</td>\n",
              "      <td>154</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>184</td>\n",
              "      <td>90.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>AdaBoost 2</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.942345</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.942262</td>\n",
              "      <td>0.781936</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>0.767433</td>\n",
              "      <td>0.941128</td>\n",
              "      <td>154</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>189</td>\n",
              "      <td>92.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "1      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "2      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "3      Regresion Lineal    Training  0.795225   0.825122  0.795225  0.794968   \n",
              "4      Regresion Lineal  Validation  0.815934   0.827130  0.815934  0.815546   \n",
              "5      Regresion Lineal        Test  0.793956   0.830307  0.793956  0.791730   \n",
              "6   Regresión Logística    Training  0.835629   0.843677  0.835629  0.836301   \n",
              "7   Regresión Logística  Validation  0.826923   0.828750  0.826923  0.827081   \n",
              "8   Regresión Logística        Test  0.826923   0.839082  0.826923  0.826964   \n",
              "9                   KNN    Training  0.852158   0.856418  0.852158  0.852701   \n",
              "10                  KNN  Validation  0.785714   0.787289  0.785714  0.785909   \n",
              "11                  KNN        Test  0.793956   0.799964  0.793956  0.794316   \n",
              "12                  SVN    Training  0.846648   0.850097  0.846648  0.847172   \n",
              "13                  SVN  Validation  0.821429   0.821337  0.821429  0.821327   \n",
              "14                  SVN        Test  0.821429   0.826572  0.821429  0.821762   \n",
              "15           AdaBoost 1    Training  1.000000   1.000000  1.000000  1.000000   \n",
              "16           AdaBoost 1  Validation  0.890110   0.890577  0.890110  0.889909   \n",
              "17           AdaBoost 1        Test  0.928571   0.928693  0.928571  0.928604   \n",
              "18           AdaBoost 2    Training  0.977961   0.977957  0.977961  0.977956   \n",
              "19           AdaBoost 2  Validation  0.928571   0.929217  0.928571  0.928441   \n",
              "20           AdaBoost 2        Test  0.942308   0.942345  0.942308  0.942262   \n",
              "\n",
              "    Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  \\\n",
              "0              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "1              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "2              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "3              0.347828            0.204775   0.167334  0.809587  438  37   \n",
              "4              0.397597            0.184066   0.261037  0.820425  153  18   \n",
              "5              0.343680            0.206044   0.169405  0.806225  157   9   \n",
              "6              0.450090            0.164371   0.331627  0.841128  420  55   \n",
              "7              0.425939            0.173077   0.305154  0.828122  145  26   \n",
              "8              0.425926            0.173077   0.302300  0.833120  150  16   \n",
              "9              0.495592            0.147842   0.398838  0.855309  418  57   \n",
              "10             0.324677            0.214286   0.139715  0.786595  137  34   \n",
              "11             0.343845            0.206044   0.169405  0.797463  139  27   \n",
              "12             0.480168            0.153352   0.376434  0.848994  412  63   \n",
              "13             0.411647            0.178571   0.283095  0.820274  137  34   \n",
              "14             0.411656            0.178571   0.280151  0.824662  143  23   \n",
              "15             1.000000            0.000000   1.000000  1.000000  475   0   \n",
              "16             0.607662            0.109890   0.558828  0.888374  147  24   \n",
              "17             0.733959            0.071429   0.712060  0.928502  154  12   \n",
              "18             0.913688            0.022039   0.910386  0.977358  462  13   \n",
              "19             0.733961            0.071429   0.713238  0.926976  154  17   \n",
              "20             0.781936            0.057692   0.767433  0.941128  154  12   \n",
              "\n",
              "     FN   TP  Global Score  \n",
              "0   186  428         74.81  \n",
              "1    49  144         76.76  \n",
              "2    66  132         74.65  \n",
              "3   186  428         74.81  \n",
              "4    49  144         76.76  \n",
              "5    66  132         74.65  \n",
              "6   124  490         79.14  \n",
              "7    37  156         77.87  \n",
              "8    47  151         78.15  \n",
              "9   104  510         81.04  \n",
              "10   44  149         72.93  \n",
              "11   48  150         74.04  \n",
              "12  104  510         80.33  \n",
              "13   31  162         77.11  \n",
              "14   42  156         77.31  \n",
              "15    0  614        100.00  \n",
              "16   16  177         85.58  \n",
              "17   14  184         90.55  \n",
              "18   11  603         97.02  \n",
              "19    9  184         90.51  \n",
              "20    9  189         92.30  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import  GridSearchCV\n",
        "\n",
        "model_name = \"AdaBoost 2\"\n",
        "print(model_name)\n",
        "\n",
        "# Inicializar el clasificador débil (stump)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# Configurar la búsqueda de hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 250, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.07, 0.10, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Inicializar el modelo AdaBoost\n",
        "ada = AdaBoostClassifier(estimator=base_estimator, n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=ada, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Entrenar el modelo con búsqueda de hiperparámetros\n",
        "grid_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Mejores hiperparámetros: {best_params}\")\n",
        "\n",
        "# Mejor modelo\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(best_model, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "best_model.fit(X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = best_model.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "\n",
        "y_pred = best_model.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "\n",
        "y_test_pred = best_model.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      CA19-9 (U/ml)  CA-125 (U/ml)  HGF (pg/ml)  OPN (pg/ml)  Omega score  \\\n",
            "1333      -0.092602      -0.107994    -0.309247     0.050290    -0.143176   \n",
            "1784      -0.092321      16.603266     0.504689     3.463351     0.336480   \n",
            "1465      -0.092602      -0.106787    -0.057182    -0.739401    -0.163334   \n",
            "1252      -0.092602      -0.107994    -0.309247    -0.413678    -0.177269   \n",
            "53        -0.092251      -0.107994    -0.312427    -0.139405    -0.158614   \n",
            "...             ...            ...          ...          ...          ...   \n",
            "797       -0.091747      -0.108175    -0.287776     0.012175    -0.155475   \n",
            "1669      -0.093555      -0.109863    -0.319221    -0.389669    -0.167576   \n",
            "766       -0.086317      -0.074770     0.218594     1.107403    -0.122682   \n",
            "75        -0.092251      -0.107994    -0.312427    -0.024325    -0.058391   \n",
            "1541      -0.053513      -0.096282    -0.280971    -0.422183    -0.132929   \n",
            "\n",
            "      Prolactin (pg/ml)  CEA (pg/ml)  Myeloperoxidase (ng/ml)  TIMP-1 (pg/ml)  \n",
            "1333          -0.362952    -0.130982                -0.250333       -1.017092  \n",
            "1784           0.506493    -0.116108                 0.069232        1.860676  \n",
            "1465          -0.385378    -0.129505                -0.321950       -0.224166  \n",
            "1252          -0.325200    -0.110392                -0.361861       -0.472180  \n",
            "53            -0.333856    -0.156455                -0.283847       -0.709295  \n",
            "...                 ...          ...                      ...             ...  \n",
            "797           -0.168136    -0.104257                -0.190397       -0.569358  \n",
            "1669          -0.438204    -0.111057                -0.371178       -0.205878  \n",
            "766           -0.286075    -0.142170                -0.170511        0.129632  \n",
            "75            -0.440049    -0.082846                -0.342670       -0.468926  \n",
            "1541          -0.448495    -0.139981                -0.341140        0.000447  \n",
            "\n",
            "[1089 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "print(X_train_prep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting\n",
            "Mejores hiperparámetros: {'learning_rate': 0.5, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Cross validation : \n",
            "Métricas validación cruzada: [-0.25341701 -0.24419875 -0.21417647 -0.23461857 -0.25400025]\n",
            "Média métricas de validación cruzada: -0.24008220989590182\n",
            "\n",
            "Metrics for Training set :\n",
            " - Accuracy: 1.0000\n",
            " - Precision: 1.0000\n",
            " - Recall: 1.0000\n",
            " - F1-Score: 1.0000\n",
            " - Adjusted Rand Index: 1.0000\n",
            " - Mean Squared Error: 0.0000\n",
            " - R-squared: 1.0000\n",
            " - Área bajo la curva : 1.000\n",
            " - Confusion Matrix: \n",
            "[[475   0]\n",
            " [  0 614]]\n",
            " - Global Score : 100.0\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for Validation set :\n",
            " - Accuracy: 0.9451\n",
            " - Precision: 0.9452\n",
            " - Recall: 0.9451\n",
            " - F1-Score: 0.9450\n",
            " - Adjusted Rand Index: 0.7917\n",
            " - Mean Squared Error: 0.0549\n",
            " - R-squared: 0.7794\n",
            " - Área bajo la curva : 0.944\n",
            " - Confusion Matrix: \n",
            "[[159  12]\n",
            " [  8 185]]\n",
            " - Global Score : 92.67\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_12012\\2767002191.py:270: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  tabla_results_df = pd.concat([tabla_results_df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for Test set :\n",
            " - Accuracy: 0.9313\n",
            " - Precision: 0.9313\n",
            " - Recall: 0.9313\n",
            " - F1-Score: 0.9313\n",
            " - Adjusted Rand Index: 0.7434\n",
            " - Mean Squared Error: 0.0687\n",
            " - R-squared: 0.7231\n",
            " - Área bajo la curva : 0.931\n",
            " - Confusion Matrix: \n",
            "[[153  13]\n",
            " [ 12 186]]\n",
            " - Global Score : 90.88\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>Training</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>614</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.945198</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.945012</td>\n",
              "      <td>0.791723</td>\n",
              "      <td>0.054945</td>\n",
              "      <td>0.779414</td>\n",
              "      <td>0.944187</td>\n",
              "      <td>159</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>185</td>\n",
              "      <td>92.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.931319</td>\n",
              "      <td>0.931298</td>\n",
              "      <td>0.931319</td>\n",
              "      <td>0.931301</td>\n",
              "      <td>0.743431</td>\n",
              "      <td>0.068681</td>\n",
              "      <td>0.723135</td>\n",
              "      <td>0.930540</td>\n",
              "      <td>153</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>186</td>\n",
              "      <td>90.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0  Gradient Boosting    Training  1.000000   1.000000  1.000000  1.000000   \n",
              "1  Gradient Boosting  Validation  0.945055   0.945198  0.945055  0.945012   \n",
              "2  Gradient Boosting        Test  0.931319   0.931298  0.931319  0.931301   \n",
              "\n",
              "   Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  FN  \\\n",
              "0             1.000000            0.000000   1.000000  1.000000  475   0   0   \n",
              "1             0.791723            0.054945   0.779414  0.944187  159  12   8   \n",
              "2             0.743431            0.068681   0.723135  0.930540  153  13  12   \n",
              "\n",
              "    TP  Global Score  \n",
              "0  614        100.00  \n",
              "1  185         92.67  \n",
              "2  186         90.88  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_name = \"Gradient Boosting\"\n",
        "print(model_name)\n",
        "\n",
        "# Configurar la búsqueda de hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 250, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.07, 0.10, 0.5, 1.0],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "# Inicializar el modelo AdaBoost\n",
        "GradBoost = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=GradBoost, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Entrenar el modelo con búsqueda de hiperparámetros\n",
        "grid_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Mejores hiperparámetros: {best_params}\")\n",
        "\n",
        "# Mejor modelo\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Cross validation\n",
        "mostrar_cross_validation(best_model, X_train_prep, y_train)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "best_model.fit(X_train_prep, y_train)\n",
        "\n",
        "y_train_pred = best_model.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"SI\")\n",
        "\n",
        "y_pred = best_model.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_pred, \"Validation\",model_name, print_roc = \"SI\")\n",
        "\n",
        "y_test_pred = best_model.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"SI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Redes Neuronales Artificiales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artificial Network Layers (ANN)\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Mejores parámetros encontrados: {'model__optimizer': 'Adam', 'model__neurons': 5, 'model__init_mode': 'normal', 'model__dropout_rate': 0.0, 'model__activation': 'sigmoid', 'epochs': 50, 'batch_size': 10}\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.8118\n",
            " - Precision: 0.8297\n",
            " - Recall: 0.8118\n",
            " - F1-Score: 0.8122\n",
            " - Adjusted Rand Index: 0.3882\n",
            " - Mean Squared Error: 0.1882\n",
            " - R-squared: 0.2345\n",
            " - Área bajo la curva : 0.822\n",
            " - Confusion Matrix: \n",
            "[[428  47]\n",
            " [158 456]]\n",
            " - Global Score : 76.51\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8159\n",
            " - Precision: 0.8246\n",
            " - Recall: 0.8159\n",
            " - F1-Score: 0.8157\n",
            " - Adjusted Rand Index: 0.3976\n",
            " - Mean Squared Error: 0.1841\n",
            " - R-squared: 0.2610\n",
            " - Área bajo la curva : 0.820\n",
            " - Confusion Matrix: \n",
            "[[151  20]\n",
            " [ 47 146]]\n",
            " - Global Score : 76.71\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8077\n",
            " - Precision: 0.8323\n",
            " - Recall: 0.8077\n",
            " - F1-Score: 0.8068\n",
            " - Adjusted Rand Index: 0.3769\n",
            " - Mean Squared Error: 0.1923\n",
            " - R-squared: 0.2248\n",
            " - Área bajo la curva : 0.817\n",
            " - Confusion Matrix: \n",
            "[[154  12]\n",
            " [ 58 140]]\n",
            " - Global Score : 76.08\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Training</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>614</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.876374</td>\n",
              "      <td>0.879788</td>\n",
              "      <td>0.876374</td>\n",
              "      <td>0.875637</td>\n",
              "      <td>0.565425</td>\n",
              "      <td>0.123626</td>\n",
              "      <td>0.503681</td>\n",
              "      <td>0.872754</td>\n",
              "      <td>139</td>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>180</td>\n",
              "      <td>83.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.895604</td>\n",
              "      <td>0.895972</td>\n",
              "      <td>0.895604</td>\n",
              "      <td>0.895349</td>\n",
              "      <td>0.624954</td>\n",
              "      <td>0.104396</td>\n",
              "      <td>0.579165</td>\n",
              "      <td>0.892844</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>183</td>\n",
              "      <td>86.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.813590</td>\n",
              "      <td>0.822818</td>\n",
              "      <td>0.813590</td>\n",
              "      <td>0.814348</td>\n",
              "      <td>0.392806</td>\n",
              "      <td>0.186410</td>\n",
              "      <td>0.242013</td>\n",
              "      <td>0.819439</td>\n",
              "      <td>411</td>\n",
              "      <td>64</td>\n",
              "      <td>139</td>\n",
              "      <td>475</td>\n",
              "      <td>76.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.789031</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.788598</td>\n",
              "      <td>0.331003</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0.150744</td>\n",
              "      <td>0.788519</td>\n",
              "      <td>135</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>152</td>\n",
              "      <td>73.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.895604</td>\n",
              "      <td>0.895972</td>\n",
              "      <td>0.895604</td>\n",
              "      <td>0.895349</td>\n",
              "      <td>0.624954</td>\n",
              "      <td>0.104396</td>\n",
              "      <td>0.579165</td>\n",
              "      <td>0.892844</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>183</td>\n",
              "      <td>86.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.813590</td>\n",
              "      <td>0.822818</td>\n",
              "      <td>0.813590</td>\n",
              "      <td>0.814348</td>\n",
              "      <td>0.392806</td>\n",
              "      <td>0.186410</td>\n",
              "      <td>0.242013</td>\n",
              "      <td>0.819439</td>\n",
              "      <td>411</td>\n",
              "      <td>64</td>\n",
              "      <td>139</td>\n",
              "      <td>475</td>\n",
              "      <td>76.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.789031</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.788598</td>\n",
              "      <td>0.331003</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0.150744</td>\n",
              "      <td>0.788519</td>\n",
              "      <td>135</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>152</td>\n",
              "      <td>73.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.815287</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807971</td>\n",
              "      <td>0.376989</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.224778</td>\n",
              "      <td>0.812036</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>75.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.825011</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.812735</td>\n",
              "      <td>0.390664</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.250008</td>\n",
              "      <td>0.817835</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>143</td>\n",
              "      <td>76.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.828625</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.788820</td>\n",
              "      <td>0.337222</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>67</td>\n",
              "      <td>131</td>\n",
              "      <td>74.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.813590</td>\n",
              "      <td>0.822818</td>\n",
              "      <td>0.813590</td>\n",
              "      <td>0.814348</td>\n",
              "      <td>0.392806</td>\n",
              "      <td>0.186410</td>\n",
              "      <td>0.242013</td>\n",
              "      <td>0.819439</td>\n",
              "      <td>411</td>\n",
              "      <td>64</td>\n",
              "      <td>139</td>\n",
              "      <td>475</td>\n",
              "      <td>76.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.789031</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.788598</td>\n",
              "      <td>0.331003</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0.150744</td>\n",
              "      <td>0.788519</td>\n",
              "      <td>135</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>152</td>\n",
              "      <td>73.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.815287</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807971</td>\n",
              "      <td>0.376989</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.224778</td>\n",
              "      <td>0.812036</td>\n",
              "      <td>143</td>\n",
              "      <td>23</td>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>75.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.825011</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.812735</td>\n",
              "      <td>0.390664</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.250008</td>\n",
              "      <td>0.817835</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>143</td>\n",
              "      <td>76.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.828625</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.788820</td>\n",
              "      <td>0.337222</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>67</td>\n",
              "      <td>131</td>\n",
              "      <td>74.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.825011</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.812735</td>\n",
              "      <td>0.390664</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.250008</td>\n",
              "      <td>0.817835</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>143</td>\n",
              "      <td>76.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.828625</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.788820</td>\n",
              "      <td>0.337222</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>67</td>\n",
              "      <td>131</td>\n",
              "      <td>74.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.825011</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.812735</td>\n",
              "      <td>0.390664</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.250008</td>\n",
              "      <td>0.817835</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>143</td>\n",
              "      <td>76.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.828625</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.788820</td>\n",
              "      <td>0.337222</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>67</td>\n",
              "      <td>131</td>\n",
              "      <td>74.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.825011</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.812735</td>\n",
              "      <td>0.390664</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.250008</td>\n",
              "      <td>0.817835</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>143</td>\n",
              "      <td>76.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.828625</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.788820</td>\n",
              "      <td>0.337222</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>67</td>\n",
              "      <td>131</td>\n",
              "      <td>74.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.825122</td>\n",
              "      <td>0.795225</td>\n",
              "      <td>0.794968</td>\n",
              "      <td>0.347828</td>\n",
              "      <td>0.204775</td>\n",
              "      <td>0.167334</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>186</td>\n",
              "      <td>428</td>\n",
              "      <td>74.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.825011</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.812735</td>\n",
              "      <td>0.390664</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.250008</td>\n",
              "      <td>0.817835</td>\n",
              "      <td>153</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>143</td>\n",
              "      <td>76.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.828625</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.788820</td>\n",
              "      <td>0.337222</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>67</td>\n",
              "      <td>131</td>\n",
              "      <td>74.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Artificial Network Layers (ANN)</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.825528</td>\n",
              "      <td>0.837177</td>\n",
              "      <td>0.825528</td>\n",
              "      <td>0.826200</td>\n",
              "      <td>0.423344</td>\n",
              "      <td>0.174472</td>\n",
              "      <td>0.290554</td>\n",
              "      <td>0.832885</td>\n",
              "      <td>423</td>\n",
              "      <td>52</td>\n",
              "      <td>138</td>\n",
              "      <td>476</td>\n",
              "      <td>78.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Artificial Network Layers (ANN)</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.829271</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.824229</td>\n",
              "      <td>0.418763</td>\n",
              "      <td>0.175824</td>\n",
              "      <td>0.294125</td>\n",
              "      <td>0.826864</td>\n",
              "      <td>149</td>\n",
              "      <td>22</td>\n",
              "      <td>42</td>\n",
              "      <td>151</td>\n",
              "      <td>77.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Artificial Network Layers (ANN)</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.832502</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815677</td>\n",
              "      <td>0.397571</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.258002</td>\n",
              "      <td>0.823506</td>\n",
              "      <td>151</td>\n",
              "      <td>15</td>\n",
              "      <td>52</td>\n",
              "      <td>146</td>\n",
              "      <td>76.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Artificial Network Layers (ANN)</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.811754</td>\n",
              "      <td>0.829712</td>\n",
              "      <td>0.811754</td>\n",
              "      <td>0.812248</td>\n",
              "      <td>0.388154</td>\n",
              "      <td>0.188246</td>\n",
              "      <td>0.234545</td>\n",
              "      <td>0.821862</td>\n",
              "      <td>428</td>\n",
              "      <td>47</td>\n",
              "      <td>158</td>\n",
              "      <td>456</td>\n",
              "      <td>76.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Artificial Network Layers (ANN)</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.824605</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.815746</td>\n",
              "      <td>0.397600</td>\n",
              "      <td>0.184066</td>\n",
              "      <td>0.261037</td>\n",
              "      <td>0.819759</td>\n",
              "      <td>151</td>\n",
              "      <td>20</td>\n",
              "      <td>47</td>\n",
              "      <td>146</td>\n",
              "      <td>76.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Artificial Network Layers (ANN)</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.832289</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.806756</td>\n",
              "      <td>0.376910</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.224778</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>154</td>\n",
              "      <td>12</td>\n",
              "      <td>58</td>\n",
              "      <td>140</td>\n",
              "      <td>76.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Model         Set  Accuracy  Precision  \\\n",
              "0                     Random Forest    Training  1.000000   1.000000   \n",
              "1                     Random Forest  Validation  0.876374   0.879788   \n",
              "2                     Random Forest        Test  0.895604   0.895972   \n",
              "3                               LDA    Training  0.813590   0.822818   \n",
              "4                               LDA  Validation  0.788462   0.789031   \n",
              "5                               LDA        Test  0.895604   0.895972   \n",
              "6                               LDA    Training  0.813590   0.822818   \n",
              "7                               LDA  Validation  0.788462   0.789031   \n",
              "8                               LDA        Test  0.807692   0.815287   \n",
              "9                               LDA    Training  0.795225   0.825122   \n",
              "10                              LDA  Validation  0.813187   0.825011   \n",
              "11                              LDA        Test  0.791209   0.828625   \n",
              "12                              LDA    Training  0.813590   0.822818   \n",
              "13                              LDA  Validation  0.788462   0.789031   \n",
              "14                              LDA        Test  0.807692   0.815287   \n",
              "15                              LDA    Training  0.795225   0.825122   \n",
              "16                              LDA  Validation  0.813187   0.825011   \n",
              "17                              LDA        Test  0.791209   0.828625   \n",
              "18                              LDA    Training  0.795225   0.825122   \n",
              "19                              LDA  Validation  0.813187   0.825011   \n",
              "20                              LDA        Test  0.791209   0.828625   \n",
              "21                              LDA    Training  0.795225   0.825122   \n",
              "22                              LDA  Validation  0.813187   0.825011   \n",
              "23                              LDA        Test  0.791209   0.828625   \n",
              "24                              LDA    Training  0.795225   0.825122   \n",
              "25                              LDA  Validation  0.813187   0.825011   \n",
              "26                              LDA        Test  0.791209   0.828625   \n",
              "27                              LDA    Training  0.795225   0.825122   \n",
              "28                              LDA  Validation  0.813187   0.825011   \n",
              "29                              LDA        Test  0.791209   0.828625   \n",
              "30  Artificial Network Layers (ANN)    Training  0.825528   0.837177   \n",
              "31  Artificial Network Layers (ANN)  Validation  0.824176   0.829271   \n",
              "32  Artificial Network Layers (ANN)        Test  0.815934   0.832502   \n",
              "33  Artificial Network Layers (ANN)    Training  0.811754   0.829712   \n",
              "34  Artificial Network Layers (ANN)  Validation  0.815934   0.824605   \n",
              "35  Artificial Network Layers (ANN)        Test  0.807692   0.832289   \n",
              "\n",
              "      Recall  F1-Score  Adjusted Rand Index  Mean Squared Error  R-squared  \\\n",
              "0   1.000000  1.000000             1.000000            0.000000   1.000000   \n",
              "1   0.876374  0.875637             0.565425            0.123626   0.503681   \n",
              "2   0.895604  0.895349             0.624954            0.104396   0.579165   \n",
              "3   0.813590  0.814348             0.392806            0.186410   0.242013   \n",
              "4   0.788462  0.788598             0.331003            0.211538   0.150744   \n",
              "5   0.895604  0.895349             0.624954            0.104396   0.579165   \n",
              "6   0.813590  0.814348             0.392806            0.186410   0.242013   \n",
              "7   0.788462  0.788598             0.331003            0.211538   0.150744   \n",
              "8   0.807692  0.807971             0.376989            0.192308   0.224778   \n",
              "9   0.795225  0.794968             0.347828            0.204775   0.167334   \n",
              "10  0.813187  0.812735             0.390664            0.186813   0.250008   \n",
              "11  0.791209  0.788820             0.337222            0.208791   0.158330   \n",
              "12  0.813590  0.814348             0.392806            0.186410   0.242013   \n",
              "13  0.788462  0.788598             0.331003            0.211538   0.150744   \n",
              "14  0.807692  0.807971             0.376989            0.192308   0.224778   \n",
              "15  0.795225  0.794968             0.347828            0.204775   0.167334   \n",
              "16  0.813187  0.812735             0.390664            0.186813   0.250008   \n",
              "17  0.791209  0.788820             0.337222            0.208791   0.158330   \n",
              "18  0.795225  0.794968             0.347828            0.204775   0.167334   \n",
              "19  0.813187  0.812735             0.390664            0.186813   0.250008   \n",
              "20  0.791209  0.788820             0.337222            0.208791   0.158330   \n",
              "21  0.795225  0.794968             0.347828            0.204775   0.167334   \n",
              "22  0.813187  0.812735             0.390664            0.186813   0.250008   \n",
              "23  0.791209  0.788820             0.337222            0.208791   0.158330   \n",
              "24  0.795225  0.794968             0.347828            0.204775   0.167334   \n",
              "25  0.813187  0.812735             0.390664            0.186813   0.250008   \n",
              "26  0.791209  0.788820             0.337222            0.208791   0.158330   \n",
              "27  0.795225  0.794968             0.347828            0.204775   0.167334   \n",
              "28  0.813187  0.812735             0.390664            0.186813   0.250008   \n",
              "29  0.791209  0.788820             0.337222            0.208791   0.158330   \n",
              "30  0.825528  0.826200             0.423344            0.174472   0.290554   \n",
              "31  0.824176  0.824229             0.418763            0.175824   0.294125   \n",
              "32  0.815934  0.815677             0.397571            0.184066   0.258002   \n",
              "33  0.811754  0.812248             0.388154            0.188246   0.234545   \n",
              "34  0.815934  0.815746             0.397600            0.184066   0.261037   \n",
              "35  0.807692  0.806756             0.376910            0.192308   0.224778   \n",
              "\n",
              "     AUC-ROC   TN  FP   FN   TP  Global Score  \n",
              "0   1.000000  475   0    0  614        100.00  \n",
              "1   0.872754  139  32   13  180         83.82  \n",
              "2   0.892844  143  23   15  183         86.24  \n",
              "3   0.819439  411  64  139  475         76.50  \n",
              "4   0.788519  135  36   41  152         73.22  \n",
              "5   0.892844  143  23   15  183         86.24  \n",
              "6   0.819439  411  64  139  475         76.50  \n",
              "7   0.788519  135  36   41  152         73.22  \n",
              "8   0.812036  143  23   47  151         75.72  \n",
              "9   0.809587  438  37  186  428         74.81  \n",
              "10  0.817835  153  18   50  143         76.44  \n",
              "11  0.803700  157   9   67  131         74.34  \n",
              "12  0.819439  411  64  139  475         76.50  \n",
              "13  0.788519  135  36   41  152         73.22  \n",
              "14  0.812036  143  23   47  151         75.72  \n",
              "15  0.809587  438  37  186  428         74.81  \n",
              "16  0.817835  153  18   50  143         76.44  \n",
              "17  0.803700  157   9   67  131         74.34  \n",
              "18  0.809587  438  37  186  428         74.81  \n",
              "19  0.817835  153  18   50  143         76.44  \n",
              "20  0.803700  157   9   67  131         74.34  \n",
              "21  0.809587  438  37  186  428         74.81  \n",
              "22  0.817835  153  18   50  143         76.44  \n",
              "23  0.803700  157   9   67  131         74.34  \n",
              "24  0.809587  438  37  186  428         74.81  \n",
              "25  0.817835  153  18   50  143         76.44  \n",
              "26  0.803700  157   9   67  131         74.34  \n",
              "27  0.809587  438  37  186  428         74.81  \n",
              "28  0.817835  153  18   50  143         76.44  \n",
              "29  0.803700  157   9   67  131         74.34  \n",
              "30  0.832885  423  52  138  476         78.01  \n",
              "31  0.826864  149  22   42  151         77.63  \n",
              "32  0.823506  151  15   52  146         76.91  \n",
              "33  0.821862  428  47  158  456         76.51  \n",
              "34  0.819759  151  20   47  146         76.71  \n",
              "35  0.817391  154  12   58  140         76.08  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "# Crear una instancia del modelo de regresión lineal\n",
        "model_ANN = tf.keras.models.Sequential()\n",
        "model_name = \"Artificial Network Layers (ANN)\"\n",
        "print(model_name)\n",
        "\n",
        "def create_model(optimizer='adam', init_mode='uniform', activation='relu', dropout_rate=0.0, neurons=1):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(neurons, kernel_initializer=init_mode, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Crear el modelo KerasClassifier con parámetros por defecto\n",
        "model = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "# Definir el grid de hiperparámetros a buscar\n",
        "param_grid = {\n",
        "    'model__optimizer': ['SGD', 'Adam'],\n",
        "    'model__init_mode': ['uniform', 'lecun_uniform', 'normal'],\n",
        "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
        "    'model__dropout_rate': [0.0, 0.1, 0.2],\n",
        "    'model__neurons': [5, 10, 15],\n",
        "    'batch_size': [10, 20, 40],\n",
        "    'epochs': [50, 100, 150],\n",
        "}\n",
        "\n",
        "# Crear el objeto RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=model,\n",
        "                                   param_distributions=param_grid,\n",
        "                                   n_iter=10,  # Número de combinaciones a probar\n",
        "                                   cv=3,  # Número de folds para la validación cruzada\n",
        "                                   verbose=2,\n",
        "                                   random_state=42,\n",
        "                                   n_jobs=-1)\n",
        "\n",
        "# Entrenar el modelo usando RandomizedSearchCV\n",
        "random_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Obtener los mejores parámetros encontrados\n",
        "best_params = random_search.best_params_\n",
        "print(\"Mejores parámetros encontrados:\", best_params)\n",
        "\n",
        "# Evaluar el mejor modelo en el conjunto de prueba\n",
        "model_ANN = random_search.best_estimator_\n",
        "\n",
        "model_ANN.fit(X_train_prep, y_train, batch_size=32, epochs=50)\n",
        "\n",
        "# Predecir en los conjuntos de datos\n",
        "y_train_pred = model_ANN.predict(X_train_prep)\n",
        "y_val_pred = model_ANN.predict(X_val_prep)\n",
        "y_test_pred = model_ANN.predict(X_test_prep)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Máquinas de vectores de soporte de regresión (SVR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVR\n",
            "Mejores parámetros {'C': 1, 'epsilon': 0.2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.8338\n",
            " - Precision: 0.8439\n",
            " - Recall: 0.8338\n",
            " - F1-Score: 0.8345\n",
            " - Adjusted Rand Index: 0.4452\n",
            " - Mean Squared Error: 0.1662\n",
            " - R-squared: 0.3242\n",
            " - Área bajo la curva : 0.840\n",
            " - Confusion Matrix: \n",
            "[[424  51]\n",
            " [130 484]]\n",
            " - Global Score : 78.98\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8242\n",
            " - Precision: 0.8269\n",
            " - Recall: 0.8242\n",
            " - F1-Score: 0.8243\n",
            " - Adjusted Rand Index: 0.4188\n",
            " - Mean Squared Error: 0.1758\n",
            " - R-squared: 0.2941\n",
            " - Área bajo la curva : 0.826\n",
            " - Confusion Matrix: \n",
            "[[146  25]\n",
            " [ 39 154]]\n",
            " - Global Score : 77.57\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8352\n",
            " - Precision: 0.8513\n",
            " - Recall: 0.8352\n",
            " - F1-Score: 0.8350\n",
            " - Adjusted Rand Index: 0.4478\n",
            " - Mean Squared Error: 0.1648\n",
            " - R-squared: 0.3355\n",
            " - Área bajo la curva : 0.843\n",
            " - Confusion Matrix: \n",
            "[[154  12]\n",
            " [ 48 150]]\n",
            " - Global Score : 79.24\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.840856</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836265</td>\n",
              "      <td>0.450082</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.839222</td>\n",
              "      <td>412</td>\n",
              "      <td>63</td>\n",
              "      <td>116</td>\n",
              "      <td>498</td>\n",
              "      <td>79.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.840856</td>\n",
              "      <td>0.835629</td>\n",
              "      <td>0.836265</td>\n",
              "      <td>0.450082</td>\n",
              "      <td>0.164371</td>\n",
              "      <td>0.331627</td>\n",
              "      <td>0.839222</td>\n",
              "      <td>412</td>\n",
              "      <td>63</td>\n",
              "      <td>116</td>\n",
              "      <td>498</td>\n",
              "      <td>79.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826875</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.826893</td>\n",
              "      <td>0.425937</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.305154</td>\n",
              "      <td>0.826122</td>\n",
              "      <td>139</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>162</td>\n",
              "      <td>77.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.840659</td>\n",
              "      <td>0.847338</td>\n",
              "      <td>0.840659</td>\n",
              "      <td>0.840924</td>\n",
              "      <td>0.462724</td>\n",
              "      <td>0.159341</td>\n",
              "      <td>0.357673</td>\n",
              "      <td>0.844773</td>\n",
              "      <td>148</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>158</td>\n",
              "      <td>79.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.810836</td>\n",
              "      <td>0.846565</td>\n",
              "      <td>0.810836</td>\n",
              "      <td>0.810241</td>\n",
              "      <td>0.385647</td>\n",
              "      <td>0.189164</td>\n",
              "      <td>0.230811</td>\n",
              "      <td>0.827005</td>\n",
              "      <td>453</td>\n",
              "      <td>22</td>\n",
              "      <td>184</td>\n",
              "      <td>430</td>\n",
              "      <td>76.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.802198</td>\n",
              "      <td>0.827413</td>\n",
              "      <td>0.802198</td>\n",
              "      <td>0.800325</td>\n",
              "      <td>0.363523</td>\n",
              "      <td>0.197802</td>\n",
              "      <td>0.205890</td>\n",
              "      <td>0.809472</td>\n",
              "      <td>159</td>\n",
              "      <td>12</td>\n",
              "      <td>60</td>\n",
              "      <td>133</td>\n",
              "      <td>75.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.839830</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.787642</td>\n",
              "      <td>0.337148</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.158330</td>\n",
              "      <td>0.805647</td>\n",
              "      <td>161</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>127</td>\n",
              "      <td>74.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.746556</td>\n",
              "      <td>0.825531</td>\n",
              "      <td>0.746556</td>\n",
              "      <td>0.740081</td>\n",
              "      <td>0.241104</td>\n",
              "      <td>0.253444</td>\n",
              "      <td>-0.030564</td>\n",
              "      <td>0.772861</td>\n",
              "      <td>465</td>\n",
              "      <td>10</td>\n",
              "      <td>266</td>\n",
              "      <td>348</td>\n",
              "      <td>70.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.739011</td>\n",
              "      <td>0.810296</td>\n",
              "      <td>0.739011</td>\n",
              "      <td>0.728137</td>\n",
              "      <td>0.226265</td>\n",
              "      <td>0.260989</td>\n",
              "      <td>-0.047784</td>\n",
              "      <td>0.752219</td>\n",
              "      <td>166</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>103</td>\n",
              "      <td>68.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.706044</td>\n",
              "      <td>0.810539</td>\n",
              "      <td>0.706044</td>\n",
              "      <td>0.689178</td>\n",
              "      <td>0.166587</td>\n",
              "      <td>0.293956</td>\n",
              "      <td>-0.184982</td>\n",
              "      <td>0.728824</td>\n",
              "      <td>164</td>\n",
              "      <td>2</td>\n",
              "      <td>105</td>\n",
              "      <td>93</td>\n",
              "      <td>65.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.833792</td>\n",
              "      <td>0.843900</td>\n",
              "      <td>0.833792</td>\n",
              "      <td>0.834459</td>\n",
              "      <td>0.445165</td>\n",
              "      <td>0.166208</td>\n",
              "      <td>0.324159</td>\n",
              "      <td>0.840453</td>\n",
              "      <td>424</td>\n",
              "      <td>51</td>\n",
              "      <td>130</td>\n",
              "      <td>484</td>\n",
              "      <td>78.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.826912</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.824325</td>\n",
              "      <td>0.418764</td>\n",
              "      <td>0.175824</td>\n",
              "      <td>0.294125</td>\n",
              "      <td>0.825864</td>\n",
              "      <td>146</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "      <td>154</td>\n",
              "      <td>77.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SVR</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.851340</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.834986</td>\n",
              "      <td>0.447799</td>\n",
              "      <td>0.164835</td>\n",
              "      <td>0.335524</td>\n",
              "      <td>0.842643</td>\n",
              "      <td>154</td>\n",
              "      <td>12</td>\n",
              "      <td>48</td>\n",
              "      <td>150</td>\n",
              "      <td>79.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0    SVR    Training  0.835629   0.840856  0.835629  0.836265   \n",
              "1    SVR    Training  0.835629   0.840856  0.835629  0.836265   \n",
              "2    SVR  Validation  0.826923   0.826875  0.826923  0.826893   \n",
              "3    SVR        Test  0.840659   0.847338  0.840659  0.840924   \n",
              "4    SVR    Training  0.810836   0.846565  0.810836  0.810241   \n",
              "5    SVR  Validation  0.802198   0.827413  0.802198  0.800325   \n",
              "6    SVR        Test  0.791209   0.839830  0.791209  0.787642   \n",
              "7    SVR    Training  0.746556   0.825531  0.746556  0.740081   \n",
              "8    SVR  Validation  0.739011   0.810296  0.739011  0.728137   \n",
              "9    SVR        Test  0.706044   0.810539  0.706044  0.689178   \n",
              "10   SVR    Training  0.833792   0.843900  0.833792  0.834459   \n",
              "11   SVR  Validation  0.824176   0.826912  0.824176  0.824325   \n",
              "12   SVR        Test  0.835165   0.851340  0.835165  0.834986   \n",
              "\n",
              "    Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  \\\n",
              "0              0.450082            0.164371   0.331627  0.839222  412  63   \n",
              "1              0.450082            0.164371   0.331627  0.839222  412  63   \n",
              "2              0.425937            0.173077   0.305154  0.826122  139  32   \n",
              "3              0.462724            0.159341   0.357673  0.844773  148  18   \n",
              "4              0.385647            0.189164   0.230811  0.827005  453  22   \n",
              "5              0.363523            0.197802   0.205890  0.809472  159  12   \n",
              "6              0.337148            0.208791   0.158330  0.805647  161   5   \n",
              "7              0.241104            0.253444  -0.030564  0.772861  465  10   \n",
              "8              0.226265            0.260989  -0.047784  0.752219  166   5   \n",
              "9              0.166587            0.293956  -0.184982  0.728824  164   2   \n",
              "10             0.445165            0.166208   0.324159  0.840453  424  51   \n",
              "11             0.418764            0.175824   0.294125  0.825864  146  25   \n",
              "12             0.447799            0.164835   0.335524  0.842643  154  12   \n",
              "\n",
              "     FN   TP  Global Score  \n",
              "0   116  498         79.04  \n",
              "1   116  498         79.04  \n",
              "2    31  162         77.78  \n",
              "3    40  158         79.69  \n",
              "4   184  430         76.79  \n",
              "5    60  133         75.35  \n",
              "6    71  127         74.52  \n",
              "7   266  348         70.00  \n",
              "8    90  103         68.61  \n",
              "9   105   93         65.50  \n",
              "10  130  484         78.98  \n",
              "11   39  154         77.57  \n",
              "12   48  150         79.24  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# TODO + 10 minutos de ejecución -- CORREGIR\n",
        "# Definir el modelo SVR\n",
        "model_name = \"SVR\"\n",
        "print(model_name)\n",
        "svr = SVR()\n",
        "\n",
        "# Definir los hiperparámetros a buscar\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'epsilon': [0.1, 0.2]\n",
        "}\n",
        "\n",
        "''' Tiempo de ejecucion > 13 minutos\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'C': [0.1, 1, 10, 100, 1000],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'epsilon': [0.1, 0.2, 0.5, 0.3]\n",
        "}\n",
        "'''\n",
        "\n",
        "# Definir GridSearchCV\n",
        "grid_search = GridSearchCV(svr, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento y encontrar los mejores hiperparámetros\n",
        "grid_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Obtener el mejor modelo y sus hiperparámetros\n",
        "model_SVR = grid_search.best_estimator_\n",
        "\n",
        "print(f\"Mejores parámetros {grid_search.best_params_}\")\n",
        "\n",
        "y_train_pred = model_SVR.predict(X_train_prep)\n",
        "y_val_pred = model_SVR.predict(X_val_prep)\n",
        "y_test_pred = model_SVR.predict(X_test_prep)\n",
        "\n",
        "umbral = 0.55\n",
        "\n",
        "y_train_pred_binary = (y_train_pred >= umbral).astype(int)\n",
        "y_val_pred_binary = (y_val_pred >= umbral).astype(int)\n",
        "y_test_pred_binary = (y_test_pred >= umbral).astype(int)\n",
        "\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred_binary, \"Training\", model_name, print_roc = \"NO\")\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred_binary, \"Validation\",model_name, print_roc = \"NO\")\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred_binary, \"Test\", model_name, print_roc = \"NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regresión polinomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regresión polinomial\n",
            "Mejores parámetros {'logistic__C': 1, 'logistic__fit_intercept': True, 'poly__degree': 3}\n",
            "[0 1 0 ... 1 1 0]\n",
            "Metrics for Training set :\n",
            " - Accuracy: 0.8512\n",
            " - Precision: 0.8526\n",
            " - Recall: 0.8512\n",
            " - F1-Score: 0.8516\n",
            " - Adjusted Rand Index: 0.4930\n",
            " - Mean Squared Error: 0.1488\n",
            " - R-squared: 0.3951\n",
            " - Área bajo la curva : 0.851\n",
            " - Confusion Matrix: \n",
            "[[405  70]\n",
            " [ 92 522]]\n",
            " - Global Score : 80.8\n",
            "\n",
            "Metrics for Validation set :\n",
            " - Accuracy: 0.8104\n",
            " - Precision: 0.8109\n",
            " - Recall: 0.8104\n",
            " - F1-Score: 0.8099\n",
            " - Adjusted Rand Index: 0.3838\n",
            " - Mean Squared Error: 0.1896\n",
            " - R-squared: 0.2390\n",
            " - Área bajo la curva : 0.808\n",
            " - Confusion Matrix: \n",
            "[[131  40]\n",
            " [ 29 164]]\n",
            " - Global Score : 75.74\n",
            "\n",
            "Metrics for Test set :\n",
            " - Accuracy: 0.8269\n",
            " - Precision: 0.8290\n",
            " - Recall: 0.8269\n",
            " - F1-Score: 0.8272\n",
            " - Adjusted Rand Index: 0.4259\n",
            " - Mean Squared Error: 0.1731\n",
            " - R-squared: 0.3023\n",
            " - Área bajo la curva : 0.828\n",
            " - Confusion Matrix: \n",
            "[[140  26]\n",
            " [ 37 161]]\n",
            " - Global Score : 77.88\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5936\\3849515159.py:270: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  tabla_results_df = pd.concat([tabla_results_df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Adjusted Rand Index</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>R-squared</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regresión polinomial</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.851240</td>\n",
              "      <td>0.852591</td>\n",
              "      <td>0.851240</td>\n",
              "      <td>0.851566</td>\n",
              "      <td>0.492959</td>\n",
              "      <td>0.148760</td>\n",
              "      <td>0.395104</td>\n",
              "      <td>0.851397</td>\n",
              "      <td>405</td>\n",
              "      <td>70</td>\n",
              "      <td>92</td>\n",
              "      <td>522</td>\n",
              "      <td>80.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regresión polinomial</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.810888</td>\n",
              "      <td>0.810440</td>\n",
              "      <td>0.809916</td>\n",
              "      <td>0.383791</td>\n",
              "      <td>0.189560</td>\n",
              "      <td>0.238978</td>\n",
              "      <td>0.807911</td>\n",
              "      <td>131</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>164</td>\n",
              "      <td>75.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regresión polinomial</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.829039</td>\n",
              "      <td>0.826923</td>\n",
              "      <td>0.827226</td>\n",
              "      <td>0.425943</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.828252</td>\n",
              "      <td>140</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>161</td>\n",
              "      <td>77.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model         Set  Accuracy  Precision    Recall  F1-Score  \\\n",
              "0  Regresión polinomial    Training  0.851240   0.852591  0.851240  0.851566   \n",
              "1  Regresión polinomial  Validation  0.810440   0.810888  0.810440  0.809916   \n",
              "2  Regresión polinomial        Test  0.826923   0.829039  0.826923  0.827226   \n",
              "\n",
              "   Adjusted Rand Index  Mean Squared Error  R-squared   AUC-ROC   TN  FP  FN  \\\n",
              "0             0.492959            0.148760   0.395104  0.851397  405  70  92   \n",
              "1             0.383791            0.189560   0.238978  0.807911  131  40  29   \n",
              "2             0.425943            0.173077   0.302300  0.828252  140  26  37   \n",
              "\n",
              "    TP  Global Score  \n",
              "0  522         80.80  \n",
              "1  164         75.74  \n",
              "2  161         77.88  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model_name = \"Regresión polinomial\"\n",
        "print(model_name)\n",
        "\n",
        "# Definir el pipeline para regresión polinomial\n",
        "pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures()),\n",
        "    ('logistic', LogisticRegression(max_iter=10000))\n",
        "])\n",
        "\n",
        "# Definir los hiperparámetros a buscar. Un grado muy alto del polinomio puede llevar a sobreajuste (overfitting)\n",
        "param_grid = {\n",
        "    'poly__degree': [2, 3, 4, 5],  # grados del polinomio\n",
        "    'logistic__C': [0.1, 1, 10, 100],  # regularización\n",
        "    'logistic__fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "# Definir GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento y encontrar los mejores hiperparámetros\n",
        "grid_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Obtener el mejor modelo y sus hiperparámetros\n",
        "model_RPoli = grid_search.best_estimator_\n",
        "\n",
        "print(f\"Mejores parámetros {grid_search.best_params_}\")\n",
        "\n",
        "y_train_pred = model_RPoli.predict(X_train_prep)\n",
        "y_val_pred = model_RPoli.predict(X_val_prep)\n",
        "y_test_pred = model_RPoli.predict(X_test_prep)\n",
        "print(y_train_pred)\n",
        "# Evaluar el modelo\n",
        "mostrar_estadisticas_guardar_tabla(y_train, y_train_pred, \"Training\", model_name, print_roc = \"NO\")\n",
        "mostrar_estadisticas_guardar_tabla(y_val, y_val_pred, \"Validation\",model_name, print_roc = \"NO\")\n",
        "mostrar_estadisticas_guardar_tabla(y_test, y_test_pred, \"Test\", model_name, print_roc = \"NO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Borrar informacion tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Borrar todos los registros\n",
        "tabla_results_df = tabla_results_df.iloc[0:0]\n",
        "tabla_results_NS_df = tabla_results_NS_df.iloc[0:0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aprendizaje no supervisado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering jerárquico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Crear una instancia del modelo de clustering jerárquico\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "model_AC = AgglomerativeClustering(n_clusters=2)\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_AC.fit(X_train_prep)\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "y_pred = model_AC.fit_predict(X_val_prep)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Calcular la precisión\n",
        "precision = precision_score(y_val, y_pred)\n",
        "\n",
        "# Calcular la exhaustividad\n",
        "recall = recall_score(y_val, y_pred)\n",
        "\n",
        "# Calcular la puntuación F1\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "print(\"Matriz de Confusión :\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering K-means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KMeans\n",
            "Número óptimo de clusters según el método del codo: 2\n",
            "Metrics for Training set (KMeans):\n",
            " - Silhouette Score: 0.5892\n",
            " - Davies-Bouldin Index: 1.6353\n",
            " - Calinski-Harabasz Index: 215.7722\n",
            " - Global Score: 87.8223\n",
            "\n",
            "Metrics for Validation set (KMeans):\n",
            " - Silhouette Score: 0.6177\n",
            " - Davies-Bouldin Index: 1.7655\n",
            " - Calinski-Harabasz Index: 65.4537\n",
            " - Global Score: 36.0215\n",
            "\n",
            "Metrics for Test set (KMeans):\n",
            " - Silhouette Score: 0.6531\n",
            " - Davies-Bouldin Index: 1.4111\n",
            " - Calinski-Harabasz Index: 112.5643\n",
            " - Global Score: 58.2229\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Silhouette Score</th>\n",
              "      <th>Davies-Bouldin Index</th>\n",
              "      <th>Calinski-Harabasz Index</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Entrenamiento</td>\n",
              "      <td>0.427582</td>\n",
              "      <td>1.065326</td>\n",
              "      <td>215.248011</td>\n",
              "      <td>93.364851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Evaluación</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>1.149159</td>\n",
              "      <td>72.724670</td>\n",
              "      <td>44.483306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.492667</td>\n",
              "      <td>0.975618</td>\n",
              "      <td>140.325935</td>\n",
              "      <td>72.465829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.458234</td>\n",
              "      <td>0.573478</td>\n",
              "      <td>114.974797</td>\n",
              "      <td>76.846230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Model            Set  Silhouette Score  Davies-Bouldin Index  \\\n",
              "0      KMeans       Training          0.589238              1.635342   \n",
              "1      KMeans     Validation          0.617695              1.765477   \n",
              "2      KMeans           Test          0.653144              1.411056   \n",
              "3      KMeans  Entrenamiento          0.427582              1.065326   \n",
              "4      KMeans     Evaluación          0.512824              1.149159   \n",
              "5      KMeans           Test          0.492667              0.975618   \n",
              "6  Mean Shift       Training          0.458234              0.573478   \n",
              "7      KMeans       Training          0.589238              1.635342   \n",
              "8      KMeans     Validation          0.617695              1.765477   \n",
              "9      KMeans           Test          0.653144              1.411056   \n",
              "\n",
              "   Calinski-Harabasz Index  Global Score  \n",
              "0               215.772165     87.822329  \n",
              "1                65.453656     36.021524  \n",
              "2               112.564337     58.222912  \n",
              "3               215.248011     93.364851  \n",
              "4                72.724670     44.483306  \n",
              "5               140.325935     72.465829  \n",
              "6               114.974797     76.846230  \n",
              "7               215.772165     87.822329  \n",
              "8                65.453656     36.021524  \n",
              "9               112.564337     58.222912  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "model_name = 'KMeans'\n",
        "print(model_name)\n",
        "model_KM = KMeans(random_state=42)\n",
        "\n",
        "# Obtención del número de clusters optimo, escoger entre elbow o silhouette\n",
        "optimal_k = optimal_cluster_number(X_train_prep, X_val_prep, model_KM, method='silhouette')\n",
        "print(\"Número óptimo de clusters según el método del codo:\", optimal_k)\n",
        "\n",
        "# Ajustar el modelo con el número óptimo de clusters\n",
        "model_KM.n_clusters = optimal_k\n",
        "\n",
        "# Entrenar el modelo usando los datos de entrenamiento preprocesados\n",
        "model_KM.fit(X_train_prep)\n",
        "\n",
        "labels_train = model_KM.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_train_prep, labels_train, \"Training\", model_name)\n",
        "\n",
        "labels_val = model_KM.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_val_prep, labels_val, \"Validation\", model_name)\n",
        "\n",
        "labels_test = model_KM.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_test_prep, labels_test, \"Test\", model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KMeans\n",
            "Número de clusteres optimo : 7\n",
            "Metrics for Entrenamiento set (KMeans):\n",
            " - Silhouette Score: 0.4276\n",
            " - Davies-Bouldin Index: 1.0653\n",
            " - Calinski-Harabasz Index: 215.2480\n",
            " - Global Score: 93.3649\n",
            "\n",
            "Metrics for Evaluación set (KMeans):\n",
            " - Silhouette Score: 0.5128\n",
            " - Davies-Bouldin Index: 1.1492\n",
            " - Calinski-Harabasz Index: 72.7247\n",
            " - Global Score: 44.4833\n",
            "\n",
            "Metrics for Test set (KMeans):\n",
            " - Silhouette Score: 0.4927\n",
            " - Davies-Bouldin Index: 0.9756\n",
            " - Calinski-Harabasz Index: 140.3259\n",
            " - Global Score: 72.4658\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Silhouette Score</th>\n",
              "      <th>Davies-Bouldin Index</th>\n",
              "      <th>Calinski-Harabasz Index</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Entrenamiento</td>\n",
              "      <td>0.427582</td>\n",
              "      <td>1.065326</td>\n",
              "      <td>215.248011</td>\n",
              "      <td>93.364851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Evaluación</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>1.149159</td>\n",
              "      <td>72.724670</td>\n",
              "      <td>44.483306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.492667</td>\n",
              "      <td>0.975618</td>\n",
              "      <td>140.325935</td>\n",
              "      <td>72.465829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Model            Set  Silhouette Score  Davies-Bouldin Index  \\\n",
              "0  KMeans       Training          0.589238              1.635342   \n",
              "1  KMeans     Validation          0.617695              1.765477   \n",
              "2  KMeans           Test          0.653144              1.411056   \n",
              "3  KMeans  Entrenamiento          0.427582              1.065326   \n",
              "4  KMeans     Evaluación          0.512824              1.149159   \n",
              "5  KMeans           Test          0.492667              0.975618   \n",
              "\n",
              "   Calinski-Harabasz Index  Global Score  \n",
              "0               215.772165     87.822329  \n",
              "1                65.453656     36.021524  \n",
              "2               112.564337     58.222912  \n",
              "3               215.248011     93.364851  \n",
              "4                72.724670     44.483306  \n",
              "5               140.325935     72.465829  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' Pruebas K-means \n",
        "La función encontrar_numero_optimo_clusters es algo más compleja y puede que ayude a ajustar mejor el modelo K-means\n",
        "Utiliza la predicción con los datos de validación para establecer las métricas para cada valor de cluster (0-10).\n",
        "Con ello, toma una decisión final donde el global_score sea máximo\n",
        "# establece qué número de clusteres es el más correcto, en un tiempo decente de en entorno a 1 min\n",
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_name = 'KMeans'\n",
        "print(model_name)\n",
        "model_KM = KMeans(random_state=42)\n",
        "\n",
        "# Encontrar el número óptimo de clústeres\n",
        "num_clusters_optimo = encontrar_numero_optimo_clusters(X_train_prep, X_val_prep, model_KM, plot_grafica = 'NO')\n",
        "print(\"Número de clusteres optimo : \" + str(num_clusters_optimo))\n",
        "# Entrenar el modelo final con el número óptimo de clústeres usando los datos de entrenamiento\n",
        "kmeans_final = KMeans(n_clusters=num_clusters_optimo, random_state=0)\n",
        "kmeans_final.fit(X_train_prep)\n",
        "labels_train = model_KM.predict(X_train_prep)\n",
        "show_save_results_no_supervised(X_train_prep, labels_train, 'Entrenamiento',  model_name)\n",
        "\n",
        "# Evaluar el modelo en los datos de evaluación\n",
        "labels_val = kmeans_final.predict(X_val_prep)\n",
        "show_save_results_no_supervised(X_val_prep, labels_val,'Evaluación', model_name)\n",
        "\n",
        "labels_test = kmeans_final.predict(X_test_prep)\n",
        "show_save_results_no_supervised(X_test_prep, labels_test,'Test', model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Shift\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\cluster\\_mean_shift.py:293: UserWarning: Binning data failed with provided bin_size=0.100000, using data points as seeds.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bandwidth óptimo: 2.0\n",
            "Mejor Silhouette Score en Validación: 0.49431989853400954\n",
            "Número de clústeres estimados en Validación: 24\n",
            "Metrics for Training set (Mean Shift):\n",
            " - Silhouette Score: 0.4582\n",
            " - Davies-Bouldin Index: 0.5735\n",
            " - Calinski-Harabasz Index: 114.9748\n",
            " - Global Score: 69.7375\n",
            "\n",
            "Metrics for Validation set (Mean Shift):\n",
            " - Silhouette Score: 0.4821\n",
            " - Davies-Bouldin Index: 0.6987\n",
            " - Calinski-Harabasz Index: 74.6950\n",
            " - Global Score: 54.6217\n",
            "\n",
            "Metrics for Test set (Mean Shift):\n",
            " - Silhouette Score: 0.4413\n",
            " - Davies-Bouldin Index: 0.8014\n",
            " - Calinski-Harabasz Index: 68.3151\n",
            " - Global Score: 50.1032\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Silhouette Score</th>\n",
              "      <th>Davies-Bouldin Index</th>\n",
              "      <th>Calinski-Harabasz Index</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Entrenamiento</td>\n",
              "      <td>0.427582</td>\n",
              "      <td>1.065326</td>\n",
              "      <td>215.248011</td>\n",
              "      <td>93.364851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Evaluación</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>1.149159</td>\n",
              "      <td>72.724670</td>\n",
              "      <td>44.483306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.492667</td>\n",
              "      <td>0.975618</td>\n",
              "      <td>140.325935</td>\n",
              "      <td>72.465829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.458234</td>\n",
              "      <td>0.573478</td>\n",
              "      <td>114.974797</td>\n",
              "      <td>76.846230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.458234</td>\n",
              "      <td>0.573478</td>\n",
              "      <td>114.974797</td>\n",
              "      <td>69.737530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.482059</td>\n",
              "      <td>0.698659</td>\n",
              "      <td>74.694969</td>\n",
              "      <td>54.621658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.441301</td>\n",
              "      <td>0.801412</td>\n",
              "      <td>68.315078</td>\n",
              "      <td>50.103171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Model            Set  Silhouette Score  Davies-Bouldin Index  \\\n",
              "0       KMeans       Training          0.589238              1.635342   \n",
              "1       KMeans     Validation          0.617695              1.765477   \n",
              "2       KMeans           Test          0.653144              1.411056   \n",
              "3       KMeans  Entrenamiento          0.427582              1.065326   \n",
              "4       KMeans     Evaluación          0.512824              1.149159   \n",
              "5       KMeans           Test          0.492667              0.975618   \n",
              "6   Mean Shift       Training          0.458234              0.573478   \n",
              "7       KMeans       Training          0.589238              1.635342   \n",
              "8       KMeans     Validation          0.617695              1.765477   \n",
              "9       KMeans           Test          0.653144              1.411056   \n",
              "10  Mean Shift       Training          0.458234              0.573478   \n",
              "11  Mean Shift     Validation          0.482059              0.698659   \n",
              "12  Mean Shift           Test          0.441301              0.801412   \n",
              "\n",
              "    Calinski-Harabasz Index  Global Score  \n",
              "0                215.772165     87.822329  \n",
              "1                 65.453656     36.021524  \n",
              "2                112.564337     58.222912  \n",
              "3                215.248011     93.364851  \n",
              "4                 72.724670     44.483306  \n",
              "5                140.325935     72.465829  \n",
              "6                114.974797     76.846230  \n",
              "7                215.772165     87.822329  \n",
              "8                 65.453656     36.021524  \n",
              "9                112.564337     58.222912  \n",
              "10               114.974797     69.737530  \n",
              "11                74.694969     54.621658  \n",
              "12                68.315078     50.103171  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import MeanShift\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model_name = 'Mean Shift'\n",
        "print(model_name)\n",
        "\n",
        "# Función para realizar la búsqueda de bandwidth óptimo\n",
        "def find_optimal_bandwidth(X, bandwidths):\n",
        "    best_bandwidth = None\n",
        "    best_score = -1\n",
        "    best_labels = None\n",
        "    best_cluster_centers = None\n",
        "    \n",
        "    for bandwidth in bandwidths:\n",
        "        ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
        "        ms.fit(X)\n",
        "        labels = ms.labels_\n",
        "        if len(np.unique(labels)) > 1:\n",
        "            score = silhouette_score(X, labels)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_bandwidth = bandwidth\n",
        "                best_labels = labels\n",
        "                best_cluster_centers = ms.cluster_centers_\n",
        "    \n",
        "    return best_bandwidth, best_labels, best_cluster_centers, best_score\n",
        "\n",
        "# Definir el rango de valores de bandwidth para la búsqueda\n",
        "bandwidths = np.linspace(0.1, 2.0, 20)\n",
        "\n",
        "# Buscar el bandwidth óptimo usando el conjunto de validación\n",
        "optimal_bandwidth, labels_val, cluster_centers, best_score = find_optimal_bandwidth(X_val_prep, bandwidths)\n",
        "\n",
        "print(\"Bandwidth óptimo:\", optimal_bandwidth)\n",
        "print(\"Mejor Silhouette Score en Validación:\", best_score)\n",
        "print(\"Número de clústeres estimados en Validación:\", len(np.unique(labels_val)))\n",
        "\n",
        "def map_clusters_to_labels(labels, true_labels):\n",
        "    from scipy.stats import mode\n",
        "    # Asegurarse de que labels y true_labels sean arreglos\n",
        "    labels = np.asarray(labels)\n",
        "    true_labels = np.asarray(true_labels)\n",
        "    \n",
        "    # Crear una matriz de confusión\n",
        "    conf_matrix = confusion_matrix(true_labels, labels)\n",
        "    \n",
        "    # Crear un arreglo para mapear los clusters a las etiquetas reales\n",
        "    cluster_label_map = np.zeros_like(labels)\n",
        "    \n",
        "    # Asignar la etiqueta de clase más frecuente a cada cluster\n",
        "    for i in range(conf_matrix.shape[1]):\n",
        "        mask = labels == i\n",
        "        if np.any(mask):  # Asegurarse de que el cluster tenga etiquetas\n",
        "            most_common_label = mode(true_labels[mask])[0][0]\n",
        "            cluster_label_map[mask] = most_common_label\n",
        "    \n",
        "    return cluster_label_map\n",
        "\n",
        "# Entrenar el modelo final en el conjunto de entrenamiento usando el bandwidth óptimo\n",
        "ms = MeanShift(bandwidth=optimal_bandwidth, bin_seeding=True)\n",
        "ms.fit(X_train_prep)\n",
        "labels_train = ms.labels_\n",
        "\n",
        "labels_train = ms.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_train_prep, labels_train, \"Training\", model_name)\n",
        "\n",
        "labels_val = ms.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_val_prep, labels_val, \"Validation\", model_name)\n",
        "\n",
        "labels_test = ms.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_test_prep, labels_test, \"Test\", model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DBSCAN\n",
            "Epsilon óptimo: 4.8\n",
            "Mejor Silhouette Score en Entrenamiento: 0.8349455307521673\n",
            "Número de clústeres estimados en Entrenamiento: 2\n",
            "Metrics for Training set (DBSCAN):\n",
            " - Silhouette Score: 0.8349\n",
            " - Davies-Bouldin Index: 1.7217\n",
            " - Calinski-Harabasz Index: 170.5236\n",
            " - Global Score: 75.3953\n",
            "\n",
            "Metrics for Validation set (DBSCAN):\n",
            " - Silhouette Score: 0.8204\n",
            " - Davies-Bouldin Index: 1.6787\n",
            " - Calinski-Harabasz Index: 52.0399\n",
            " - Global Score: 36.3747\n",
            "\n",
            "Metrics for Test set (DBSCAN):\n",
            " - Silhouette Score: 0.8233\n",
            " - Davies-Bouldin Index: 1.1945\n",
            " - Calinski-Harabasz Index: 88.5002\n",
            " - Global Score: 56.6458\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Silhouette Score</th>\n",
              "      <th>Davies-Bouldin Index</th>\n",
              "      <th>Calinski-Harabasz Index</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.834946</td>\n",
              "      <td>1.721699</td>\n",
              "      <td>170.523605</td>\n",
              "      <td>75.395314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.820430</td>\n",
              "      <td>1.678743</td>\n",
              "      <td>52.039884</td>\n",
              "      <td>36.374742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.823251</td>\n",
              "      <td>1.194508</td>\n",
              "      <td>88.500184</td>\n",
              "      <td>56.645778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.834946</td>\n",
              "      <td>1.721699</td>\n",
              "      <td>170.523605</td>\n",
              "      <td>75.395314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.820430</td>\n",
              "      <td>1.678743</td>\n",
              "      <td>52.039884</td>\n",
              "      <td>36.374742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.823251</td>\n",
              "      <td>1.194508</td>\n",
              "      <td>88.500184</td>\n",
              "      <td>56.645778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model         Set  Silhouette Score  Davies-Bouldin Index  \\\n",
              "0   Random Forest    Training          0.229602              1.740380   \n",
              "1   Random Forest  Validation          0.210897              1.816310   \n",
              "2   Random Forest        Test          0.263973              1.729851   \n",
              "3          DBSCAN    Training          0.834946              1.721699   \n",
              "4          DBSCAN  Validation          0.820430              1.678743   \n",
              "5          DBSCAN        Test          0.823251              1.194508   \n",
              "6             PCA    Training          0.229602              1.740380   \n",
              "7             PCA  Validation          0.210897              1.816310   \n",
              "8             PCA        Test          0.263973              1.729851   \n",
              "9             PCA    Training          0.229602              1.740380   \n",
              "10            PCA  Validation          0.210897              1.816310   \n",
              "11            PCA        Test          0.263973              1.729851   \n",
              "12            PCA    Training          0.229602              1.740380   \n",
              "13            PCA  Validation          0.210897              1.816310   \n",
              "14            PCA        Test          0.263973              1.729851   \n",
              "15         DBSCAN    Training          0.834946              1.721699   \n",
              "16         DBSCAN  Validation          0.820430              1.678743   \n",
              "17         DBSCAN        Test          0.823251              1.194508   \n",
              "\n",
              "    Calinski-Harabasz Index  Global Score  \n",
              "0                115.132563     46.531218  \n",
              "1                 36.730034     18.819791  \n",
              "2                 47.569378     24.758483  \n",
              "3                170.523605     75.395314  \n",
              "4                 52.039884     36.374742  \n",
              "5                 88.500184     56.645778  \n",
              "6                115.132563     46.531218  \n",
              "7                 36.730034     18.819791  \n",
              "8                 47.569378     24.758483  \n",
              "9                115.132563     46.531218  \n",
              "10                36.730034     18.819791  \n",
              "11                47.569378     24.758483  \n",
              "12               115.132563     46.531218  \n",
              "13                36.730034     18.819791  \n",
              "14                47.569378     24.758483  \n",
              "15               170.523605     75.395314  \n",
              "16                52.039884     36.374742  \n",
              "17                88.500184     56.645778  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_name = 'DBSCAN'\n",
        "print(model_name)\n",
        "\n",
        "# Función para encontrar el mejor valor de eps\n",
        "def find_optimal_eps(X, eps_values, min_samples):\n",
        "    best_eps = None\n",
        "    best_score = -1\n",
        "    best_labels = None\n",
        "    \n",
        "    for eps in eps_values:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        labels = dbscan.fit_predict(X)\n",
        "        \n",
        "        # Solo evaluar si hay más de un cluster (ignorar ruido)\n",
        "        if len(np.unique(labels)) > 1 and np.sum(labels != -1) > 1:\n",
        "            score = silhouette_score(X, labels)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_eps = eps\n",
        "                best_labels = labels\n",
        "                \n",
        "    return best_eps, best_labels, best_score\n",
        "\n",
        "# Definir el rango de valores de eps para la búsqueda\n",
        "eps_values = np.linspace(0.1, 5.0, 50)\n",
        "min_samples = 5  # Puedes ajustar este valor según sea necesario\n",
        "\n",
        "# Buscar el eps óptimo usando el conjunto de entrenamiento\n",
        "optimal_eps, labels_train, best_score = find_optimal_eps(X_train_prep, eps_values, min_samples)\n",
        "\n",
        "print(\"Epsilon óptimo:\", optimal_eps)\n",
        "print(\"Mejor Silhouette Score en Entrenamiento:\", best_score)\n",
        "print(\"Número de clústeres estimados en Entrenamiento:\", len(np.unique(labels_train)))\n",
        "\n",
        "# Entrenar el modelo final en el conjunto de entrenamiento usando el eps óptimo\n",
        "dbscan_final = DBSCAN(eps=optimal_eps, min_samples=min_samples)\n",
        "\n",
        "labels_train = dbscan_final.fit_predict(X_train_prep)\n",
        "labels_val = dbscan_final.fit_predict(X_val_prep)\n",
        "labels_test = dbscan_final.fit_predict(X_test_prep)\n",
        "\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_train_prep, labels_train, \"Training\", model_name)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_val_prep, labels_val, \"Validation\", model_name)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_test_prep, labels_test, \"Test\", model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering GMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros:  {'gmm__covariance_type': 'spherical', 'gmm__n_components': 2}\n",
            "Metrics for Training set (Mean Shift):\n",
            " - Silhouette Score: 0.4229\n",
            " - Davies-Bouldin Index: 1.7908\n",
            " - Calinski-Harabasz Index: 157.8364\n",
            " - Global Score: 63.1478\n",
            "\n",
            "Metrics for Validation set (Mean Shift):\n",
            " - Silhouette Score: 0.4492\n",
            " - Davies-Bouldin Index: 1.8741\n",
            " - Calinski-Harabasz Index: 54.3106\n",
            " - Global Score: 27.6885\n",
            "\n",
            "Metrics for Test set (Mean Shift):\n",
            " - Silhouette Score: 0.4781\n",
            " - Davies-Bouldin Index: 1.7677\n",
            " - Calinski-Harabasz Index: 66.4847\n",
            " - Global Score: 34.0007\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Silhouette Score</th>\n",
              "      <th>Davies-Bouldin Index</th>\n",
              "      <th>Calinski-Harabasz Index</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Entrenamiento</td>\n",
              "      <td>0.427582</td>\n",
              "      <td>1.065326</td>\n",
              "      <td>215.248011</td>\n",
              "      <td>93.364851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Evaluación</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>1.149159</td>\n",
              "      <td>72.724670</td>\n",
              "      <td>44.483306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.492667</td>\n",
              "      <td>0.975618</td>\n",
              "      <td>140.325935</td>\n",
              "      <td>72.465829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.458234</td>\n",
              "      <td>0.573478</td>\n",
              "      <td>114.974797</td>\n",
              "      <td>76.846230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.589238</td>\n",
              "      <td>1.635342</td>\n",
              "      <td>215.772165</td>\n",
              "      <td>87.822329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.617695</td>\n",
              "      <td>1.765477</td>\n",
              "      <td>65.453656</td>\n",
              "      <td>36.021524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.653144</td>\n",
              "      <td>1.411056</td>\n",
              "      <td>112.564337</td>\n",
              "      <td>58.222912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.458234</td>\n",
              "      <td>0.573478</td>\n",
              "      <td>114.974797</td>\n",
              "      <td>69.737530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.482059</td>\n",
              "      <td>0.698659</td>\n",
              "      <td>74.694969</td>\n",
              "      <td>54.621658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.441301</td>\n",
              "      <td>0.801412</td>\n",
              "      <td>68.315078</td>\n",
              "      <td>50.103171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.422905</td>\n",
              "      <td>1.790767</td>\n",
              "      <td>157.836376</td>\n",
              "      <td>63.147762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.449208</td>\n",
              "      <td>1.874110</td>\n",
              "      <td>54.310631</td>\n",
              "      <td>27.688509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.478050</td>\n",
              "      <td>1.767702</td>\n",
              "      <td>66.484695</td>\n",
              "      <td>34.000696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.422905</td>\n",
              "      <td>1.790767</td>\n",
              "      <td>157.836376</td>\n",
              "      <td>63.147762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.449208</td>\n",
              "      <td>1.874110</td>\n",
              "      <td>54.310631</td>\n",
              "      <td>27.688509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Mean Shift</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.478050</td>\n",
              "      <td>1.767702</td>\n",
              "      <td>66.484695</td>\n",
              "      <td>34.000696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Model            Set  Silhouette Score  Davies-Bouldin Index  \\\n",
              "0       KMeans       Training          0.589238              1.635342   \n",
              "1       KMeans     Validation          0.617695              1.765477   \n",
              "2       KMeans           Test          0.653144              1.411056   \n",
              "3       KMeans  Entrenamiento          0.427582              1.065326   \n",
              "4       KMeans     Evaluación          0.512824              1.149159   \n",
              "5       KMeans           Test          0.492667              0.975618   \n",
              "6   Mean Shift       Training          0.458234              0.573478   \n",
              "7       KMeans       Training          0.589238              1.635342   \n",
              "8       KMeans     Validation          0.617695              1.765477   \n",
              "9       KMeans           Test          0.653144              1.411056   \n",
              "10  Mean Shift       Training          0.458234              0.573478   \n",
              "11  Mean Shift     Validation          0.482059              0.698659   \n",
              "12  Mean Shift           Test          0.441301              0.801412   \n",
              "13  Mean Shift       Training          0.422905              1.790767   \n",
              "14  Mean Shift     Validation          0.449208              1.874110   \n",
              "15  Mean Shift           Test          0.478050              1.767702   \n",
              "16  Mean Shift       Training          0.422905              1.790767   \n",
              "17  Mean Shift     Validation          0.449208              1.874110   \n",
              "18  Mean Shift           Test          0.478050              1.767702   \n",
              "\n",
              "    Calinski-Harabasz Index  Global Score  \n",
              "0                215.772165     87.822329  \n",
              "1                 65.453656     36.021524  \n",
              "2                112.564337     58.222912  \n",
              "3                215.248011     93.364851  \n",
              "4                 72.724670     44.483306  \n",
              "5                140.325935     72.465829  \n",
              "6                114.974797     76.846230  \n",
              "7                215.772165     87.822329  \n",
              "8                 65.453656     36.021524  \n",
              "9                112.564337     58.222912  \n",
              "10               114.974797     69.737530  \n",
              "11                74.694969     54.621658  \n",
              "12                68.315078     50.103171  \n",
              "13               157.836376     63.147762  \n",
              "14                54.310631     27.688509  \n",
              "15                66.484695     34.000696  \n",
              "16               157.836376     63.147762  \n",
              "17                54.310631     27.688509  \n",
              "18                66.484695     34.000696  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define un pipeline que combina un modelo de mezcla gaussiana\n",
        "pipeline = Pipeline([\n",
        "    ('gmm', GaussianMixture(random_state=42))\n",
        "])\n",
        "\n",
        "# Define la cuadrícula de parámetros para buscar\n",
        "param_grid = {\n",
        "    'gmm__n_components': [1, 2, 3, 4, 5],\n",
        "    'gmm__covariance_type': ['full', 'tied', 'diag', 'spherical']\n",
        "}\n",
        "\n",
        "# Crea un objeto GridSearchCV\n",
        "model_GMM = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Ajusta el objeto GridSearchCV a los datos\n",
        "model_GMM.fit(X_train_prep, y_train)\n",
        "\n",
        "# Imprime los mejores parámetros\n",
        "print(\"Mejores parámetros: \", model_GMM.best_params_)\n",
        "\n",
        "\n",
        "labels_train = model_GMM.predict(X_train_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_train_prep, labels_train, \"Training\", model_name)\n",
        "\n",
        "labels_val = model_GMM.predict(X_val_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_val_prep, labels_val, \"Validation\", model_name)\n",
        "\n",
        "labels_test = model_GMM.predict(X_test_prep)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_test_prep, labels_test, \"Test\", model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pasar a formato excel \n",
        "tabla_results_df.to_excel('model_results.xlsx', index=False)\n",
        "tabla_results_NS_df.to_excel('model_results_NS.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis de componentes principales (PCA) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número óptimo de componentes para explicar al menos el 95% de la variancia es de 9 que coincide con el número actual de variables es de 9. \n",
            "Por tanto no se aplica el algoritmo PCA\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Crear y ajustar el modelo PCA para calcular la variancia explicada\n",
        "pca_temp = PCA()\n",
        "pca_temp.fit(X_train_prep)\n",
        "\n",
        "# Calcular la variancia explicada acumulada\n",
        "explained_variance = np.cumsum(pca_temp.explained_variance_ratio_)\n",
        "\n",
        "# Determinar el número de componentes que explican al menos el 95% de la variancia\n",
        "n_components = np.argmax(explained_variance >= 0.95) + 1\n",
        "\n",
        "if n_components == X_train_prep.shape[1] :\n",
        "    print(f\"Número óptimo de componentes para explicar al menos el 95% de la variancia es de {n_components}\" \n",
        "      f\" que coincide con el número actual de variables es de {X_train_prep.shape[1]}. \\n\"\n",
        "       \"Por tanto no se aplica el algoritmo PCA\")\n",
        "    \n",
        "else :\n",
        "    print(f\"Número óptimo de componentes para explicar al menos el 95% de la variancia: {n_components} \")\n",
        "\n",
        "    # Crear y ajustar el modelo PCA con el número óptimo de componentes\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train_prep)\n",
        "    X_val_pca = pca.transform(X_val_prep)\n",
        "    X_test_pca = pca.transform(X_test_prep)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis discriminante lineal (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA\n",
            "Best parameters : {'n_components': None, 'solver': 'svd'}\n",
            "Metrics for Training set (LDA):\n",
            " - Silhouette Score: 0.3091\n",
            " - Davies-Bouldin Index: 1.7594\n",
            " - Calinski-Harabasz Index: 133.1994\n",
            " - Global Score: 53.5623\n",
            "\n",
            "Metrics for Validation set (LDA):\n",
            " - Silhouette Score: 0.2775\n",
            " - Davies-Bouldin Index: 1.8459\n",
            " - Calinski-Harabasz Index: 41.1149\n",
            " - Global Score: 20.8976\n",
            "\n",
            "Metrics for Test set (LDA):\n",
            " - Silhouette Score: 0.3448\n",
            " - Davies-Bouldin Index: 1.7564\n",
            " - Calinski-Harabasz Index: 53.9366\n",
            " - Global Score: 27.7848\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Set</th>\n",
              "      <th>Silhouette Score</th>\n",
              "      <th>Davies-Bouldin Index</th>\n",
              "      <th>Calinski-Harabasz Index</th>\n",
              "      <th>Global Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.834946</td>\n",
              "      <td>1.721699</td>\n",
              "      <td>170.523605</td>\n",
              "      <td>75.395314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.820430</td>\n",
              "      <td>1.678743</td>\n",
              "      <td>52.039884</td>\n",
              "      <td>36.374742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.823251</td>\n",
              "      <td>1.194508</td>\n",
              "      <td>88.500184</td>\n",
              "      <td>56.645778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.229602</td>\n",
              "      <td>1.740380</td>\n",
              "      <td>115.132563</td>\n",
              "      <td>46.531218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.210897</td>\n",
              "      <td>1.816310</td>\n",
              "      <td>36.730034</td>\n",
              "      <td>18.819791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PCA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.263973</td>\n",
              "      <td>1.729851</td>\n",
              "      <td>47.569378</td>\n",
              "      <td>24.758483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.834946</td>\n",
              "      <td>1.721699</td>\n",
              "      <td>170.523605</td>\n",
              "      <td>75.395314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.820430</td>\n",
              "      <td>1.678743</td>\n",
              "      <td>52.039884</td>\n",
              "      <td>36.374742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.823251</td>\n",
              "      <td>1.194508</td>\n",
              "      <td>88.500184</td>\n",
              "      <td>56.645778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.231252</td>\n",
              "      <td>1.753035</td>\n",
              "      <td>114.951883</td>\n",
              "      <td>46.287582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.193475</td>\n",
              "      <td>1.844831</td>\n",
              "      <td>34.742839</td>\n",
              "      <td>17.391673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>DBSCAN</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.229651</td>\n",
              "      <td>1.767221</td>\n",
              "      <td>43.197879</td>\n",
              "      <td>22.106459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.229651</td>\n",
              "      <td>1.767221</td>\n",
              "      <td>43.197879</td>\n",
              "      <td>22.106459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.309113</td>\n",
              "      <td>1.759360</td>\n",
              "      <td>133.199381</td>\n",
              "      <td>53.562338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.277450</td>\n",
              "      <td>1.845891</td>\n",
              "      <td>41.114890</td>\n",
              "      <td>20.897624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.344773</td>\n",
              "      <td>1.756416</td>\n",
              "      <td>53.936624</td>\n",
              "      <td>27.784813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.309113</td>\n",
              "      <td>1.759360</td>\n",
              "      <td>133.199381</td>\n",
              "      <td>53.562338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.277450</td>\n",
              "      <td>1.845891</td>\n",
              "      <td>41.114890</td>\n",
              "      <td>20.897624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.344773</td>\n",
              "      <td>1.756416</td>\n",
              "      <td>53.936624</td>\n",
              "      <td>27.784813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.309113</td>\n",
              "      <td>1.759360</td>\n",
              "      <td>133.199381</td>\n",
              "      <td>53.562338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.277450</td>\n",
              "      <td>1.845891</td>\n",
              "      <td>41.114890</td>\n",
              "      <td>20.897624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.344773</td>\n",
              "      <td>1.756416</td>\n",
              "      <td>53.936624</td>\n",
              "      <td>27.784813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Training</td>\n",
              "      <td>0.309113</td>\n",
              "      <td>1.759360</td>\n",
              "      <td>133.199381</td>\n",
              "      <td>53.562338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Validation</td>\n",
              "      <td>0.277450</td>\n",
              "      <td>1.845891</td>\n",
              "      <td>41.114890</td>\n",
              "      <td>20.897624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>LDA</td>\n",
              "      <td>Test</td>\n",
              "      <td>0.344773</td>\n",
              "      <td>1.756416</td>\n",
              "      <td>53.936624</td>\n",
              "      <td>27.784813</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model         Set  Silhouette Score  Davies-Bouldin Index  \\\n",
              "0   Random Forest    Training          0.229602              1.740380   \n",
              "1   Random Forest  Validation          0.210897              1.816310   \n",
              "2   Random Forest        Test          0.263973              1.729851   \n",
              "3          DBSCAN    Training          0.834946              1.721699   \n",
              "4          DBSCAN  Validation          0.820430              1.678743   \n",
              "5          DBSCAN        Test          0.823251              1.194508   \n",
              "6             PCA    Training          0.229602              1.740380   \n",
              "7             PCA  Validation          0.210897              1.816310   \n",
              "8             PCA        Test          0.263973              1.729851   \n",
              "9             PCA    Training          0.229602              1.740380   \n",
              "10            PCA  Validation          0.210897              1.816310   \n",
              "11            PCA        Test          0.263973              1.729851   \n",
              "12            PCA    Training          0.229602              1.740380   \n",
              "13            PCA  Validation          0.210897              1.816310   \n",
              "14            PCA        Test          0.263973              1.729851   \n",
              "15         DBSCAN    Training          0.834946              1.721699   \n",
              "16         DBSCAN  Validation          0.820430              1.678743   \n",
              "17         DBSCAN        Test          0.823251              1.194508   \n",
              "18         DBSCAN    Training          0.231252              1.753035   \n",
              "19         DBSCAN  Validation          0.193475              1.844831   \n",
              "20         DBSCAN        Test          0.229651              1.767221   \n",
              "21            LDA        Test          0.229651              1.767221   \n",
              "22            LDA    Training          0.309113              1.759360   \n",
              "23            LDA  Validation          0.277450              1.845891   \n",
              "24            LDA        Test          0.344773              1.756416   \n",
              "25            LDA    Training          0.309113              1.759360   \n",
              "26            LDA  Validation          0.277450              1.845891   \n",
              "27            LDA        Test          0.344773              1.756416   \n",
              "28            LDA    Training          0.309113              1.759360   \n",
              "29            LDA  Validation          0.277450              1.845891   \n",
              "30            LDA        Test          0.344773              1.756416   \n",
              "31            LDA    Training          0.309113              1.759360   \n",
              "32            LDA  Validation          0.277450              1.845891   \n",
              "33            LDA        Test          0.344773              1.756416   \n",
              "\n",
              "    Calinski-Harabasz Index  Global Score  \n",
              "0                115.132563     46.531218  \n",
              "1                 36.730034     18.819791  \n",
              "2                 47.569378     24.758483  \n",
              "3                170.523605     75.395314  \n",
              "4                 52.039884     36.374742  \n",
              "5                 88.500184     56.645778  \n",
              "6                115.132563     46.531218  \n",
              "7                 36.730034     18.819791  \n",
              "8                 47.569378     24.758483  \n",
              "9                115.132563     46.531218  \n",
              "10                36.730034     18.819791  \n",
              "11                47.569378     24.758483  \n",
              "12               115.132563     46.531218  \n",
              "13                36.730034     18.819791  \n",
              "14                47.569378     24.758483  \n",
              "15               170.523605     75.395314  \n",
              "16                52.039884     36.374742  \n",
              "17                88.500184     56.645778  \n",
              "18               114.951883     46.287582  \n",
              "19                34.742839     17.391673  \n",
              "20                43.197879     22.106459  \n",
              "21                43.197879     22.106459  \n",
              "22               133.199381     53.562338  \n",
              "23                41.114890     20.897624  \n",
              "24                53.936624     27.784813  \n",
              "25               133.199381     53.562338  \n",
              "26                41.114890     20.897624  \n",
              "27                53.936624     27.784813  \n",
              "28               133.199381     53.562338  \n",
              "29                41.114890     20.897624  \n",
              "30                53.936624     27.784813  \n",
              "31               133.199381     53.562338  \n",
              "32                41.114890     20.897624  \n",
              "33                53.936624     27.784813  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_name = 'LDA'\n",
        "print(model_name)\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "n_features = X_train_prep.shape[1]\n",
        "n_classes = len(np.unique(y_train))\n",
        "max_components = min(n_features, n_classes - 1)\n",
        "\n",
        "# Definir los hiperparámetros a buscar\n",
        "param_grid = {\n",
        "    'solver': ['svd', 'lsqr', 'eigen'],\n",
        "    'n_components': [None] + list(range(1, max_components + 1))\n",
        "}\n",
        "\n",
        "# Definir GridSearchCV\n",
        "grid_search = GridSearchCV(lda, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento y encontrar los mejores hiperparámetros\n",
        "grid_search.fit(X_train_prep, y_train)\n",
        "\n",
        "# Obtener el mejor modelo y sus hiperparámetros\n",
        "model_LDA = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters : {best_params}\")\n",
        "\n",
        "model_LDA.fit(X_train_prep, y_train)\n",
        "\n",
        "labels_train = model_LDA.predict(X_train_prep)\n",
        "labels_val = model_LDA.predict(X_val_prep)\n",
        "labels_test = model_LDA.predict(X_test_prep)\n",
        "\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_train_prep, labels_train, \"Training\", model_name)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_val_prep, labels_val, \"Validation\", model_name)\n",
        "mostrar_estadisticas_guardar_tabla_NS(X_test_prep, labels_test, \"Test\", model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pruebas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5.2 Peso de cada variable en la predicción de la variable objetivo"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pesos del estudio original \n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verificación del \"Information Gain\" o peso de la variable frente a la variable objetivo a predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.5.2.1 Método 1 Variables continuas, variable objetivo binaria --> Correlación de Pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Teniendo variables predictivas numéricas continuas y una variable objetivo binaria, se hace uso del coeficiente de correlación de Pearson\n",
            "\tCorrelación de Pearson : \n",
            "Tumor type                              1.000000\n",
            "CancerSEEK Logistic Regression Score    0.732341\n",
            "CancerSEEK Test Result                  0.640972\n",
            "OPN (pg/ml)                             0.458352\n",
            "Prolactin (pg/ml)                       0.324378\n",
            "TIMP-1 (pg/ml)                          0.300539\n",
            "GDF15 (ng/ml)                           0.247428\n",
            "HGF (pg/ml)                             0.242512\n",
            "Myeloperoxidase (ng/ml)                 0.221877\n",
            "FGF2 (pg/ml)                            0.192212\n",
            "IL-6 (pg/ml)                            0.186625\n",
            "Galectin-3 (ng/ml)                      0.180836\n",
            "Angiopoietin-2 (pg/ml)                  0.170233\n",
            "OPG (ng/ml)                             0.147721\n",
            "Omega score                             0.146759\n",
            "HE4 (pg/ml)                             0.139689\n",
            "Follistatin (pg/ml)                     0.137546\n",
            "CEA (pg/ml)                             0.126718\n",
            "G-CSF (pg/ml)                           0.125556\n",
            "Thrombospondin-2 (pg/ml)                0.113892\n",
            "SHBG (nM)                               0.103730\n",
            "Mesothelin (ng/ml)                      0.099196\n",
            "CA-125 (U/ml)                           0.095708\n",
            "CA 15-3 (U/ml)                          0.093855\n",
            "AFP (pg/ml)                             0.093452\n",
            "Midkine (pg/ml)                         0.090919\n",
            "IL-8 (pg/ml)                            0.080777\n",
            "CA19-9 (U/ml)                           0.078404\n",
            "CYFRA 21-1 (pg/ml)                      0.058790\n",
            "PAR (pg/ml)                             0.052930\n",
            "Kallikrein-6 (pg/ml)                    0.042339\n",
            "AXL (pg/ml)                             0.032260\n",
            "TGFa (pg/ml)                            0.028200\n",
            "TIMP-2 (pg/ml)                          0.019388\n",
            "sHER2/sEGFR2/sErbB2 (pg/ml)             0.015588\n",
            "DKK1 (ng/ml)                            0.015159\n",
            "CD44 (ng/ml)                            0.003697\n",
            "Endoglin (pg/ml)                       -0.011759\n",
            "sFas (pg/ml)                           -0.022677\n",
            "Leptin (pg/ml)                         -0.041766\n",
            "sPECAM-1 (pg/ml)                       -0.058772\n",
            "NSE (ng/ml)                            -0.099372\n",
            "sEGFR (pg/ml)                          -0.279246\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"[INFO] Teniendo variables predictivas numéricas continuas y una variable objetivo binaria, se hace uso del coeficiente de correlación de Pearson\")\n",
        "df_numericas = df.select_dtypes(include=['number'])\n",
        "correlaciones = df_numericas.corrwith(df['Tumor type']).sort_values(ascending=False)\n",
        "\n",
        "print(\"\\tCorrelación de Pearson : \")\n",
        "print(correlaciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.5.2.2 Método 2 - Variables discretas (KBinsDiscretizer()), variable objetivo binaria --> Correlación "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CancerSEEK Logistic Regression Score    0.707618\n",
            "IL-8 (pg/ml)                            0.577839\n",
            "OPN (pg/ml)                             0.576522\n",
            "IL-6 (pg/ml)                            0.475775\n",
            "GDF15 (ng/ml)                           0.474454\n",
            "Prolactin (pg/ml)                       0.447670\n",
            "HGF (pg/ml)                             0.444292\n",
            "Omega score                             0.379398\n",
            "Myeloperoxidase (ng/ml)                 0.349025\n",
            "TGFa (pg/ml)                            0.326160\n",
            "sEGFR (pg/ml)                           0.320633\n",
            "TIMP-1 (pg/ml)                          0.301831\n",
            "CEA (pg/ml)                             0.301361\n",
            "CA-125 (U/ml)                           0.288792\n",
            "CA19-9 (U/ml)                           0.275198\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 42 are removed. Consider decreasing the number of bins.\n",
            "  warnings.warn(\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[:, None]\n",
            "c:\\Users\\danie\\.virtualenvs\\Repositorio_compartido-Xxik1eBC\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[None, :]\n"
          ]
        }
      ],
      "source": [
        "# Prueba discretización rápida + correlaciones \n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "df_numericas = df.select_dtypes(include=['number'])\n",
        "# Inicializar el discretizador basado en cuantiles\n",
        "discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='quantile')\n",
        "\n",
        "# Discretizar las variables numéricas continuas\n",
        "df_numericas_discretas = pd.DataFrame(discretizer.fit_transform(df_numericas), columns=df_numericas.columns)\n",
        "\n",
        "# Calcular el coeficiente de correlación entre las variables numéricas discretas y la variable objetivo binaria\n",
        "correlaciones_discretas = df_numericas_discretas.corrwith(df['Tumor type'])\n",
        "\n",
        "# Ordenar las correlaciones de mayor a menor\n",
        "correlaciones_discretas_ordenadas = correlaciones_discretas.abs().sort_values(ascending=False)\n",
        "\n",
        "# Obtener las top 10 variables numéricas discretas con las correlaciones más altas\n",
        "top_15_correlaciones_discretas = correlaciones_discretas_ordenadas.nlargest(15)\n",
        "\n",
        "# Imprimir las top 10 correlaciones\n",
        "print(top_15_correlaciones_discretas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.5.2.3 Método 3 - Variables discretizado (Arbol de decisión (max_depth = 15)), variable objetivo binaria --> Correlación "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tumor type                              1.000000\n",
            "CancerSEEK Logistic Regression Score    0.713090\n",
            "CancerSEEK Test Result                  0.640972\n",
            "OPN (pg/ml)                             0.575480\n",
            "IL-6 (pg/ml)                            0.483620\n",
            "IL-8 (pg/ml)                            0.464828\n",
            "HGF (pg/ml)                             0.454991\n",
            "Prolactin (pg/ml)                       0.453270\n",
            "Omega score                             0.378112\n",
            "GDF15 (ng/ml)                           0.365248\n",
            "CYFRA 21-1 (pg/ml)                      0.356245\n",
            "Myeloperoxidase (ng/ml)                 0.351481\n",
            "sEGFR (pg/ml)                           0.319982\n",
            "CA-125 (U/ml)                           0.312094\n",
            "CEA (pg/ml)                             0.308045\n",
            "TIMP-1 (pg/ml)                          0.301340\n",
            "CA19-9 (U/ml)                           0.266444\n",
            "Angiopoietin-2 (pg/ml)                  0.233881\n",
            "HE4 (pg/ml)                             0.232766\n",
            "Galectin-3 (ng/ml)                      0.232425\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "def discretizar_df_arboles(df, max_depth=15, rango_discretizacion=(-np.inf, np.inf)):\n",
        "    df_discretizado = pd.DataFrame()\n",
        "    \n",
        "    # Iterar sobre todas las columnas del dataframe original\n",
        "    for columna in df.columns:\n",
        "        if df[columna].dtype.kind in 'biufc': # (CHULO) Comprueba si el tipo de datos de la columna es numérico ('b' para booleano, 'i' para entero, 'u' para sin signo, 'f' para flotante o 'c' para complejo)\n",
        "            # Si la columna es numérica, realizar la discretización\n",
        "            dt = DecisionTreeRegressor(max_depth=max_depth)\n",
        "            dt.fit(df[columna].values.reshape(-1, 1), df[columna])\n",
        "            puntos_corte = dt.tree_.threshold[dt.tree_.threshold != -2] # Extrae los puntos de corte del árbol de decisión para la columna numérica específica, ignorando aquellos puntos de corte asociados con nodos hoja (-2)\n",
        "            puntos_corte = np.sort(puntos_corte)\n",
        "            puntos_corte = np.concatenate(([rango_discretizacion[0]], puntos_corte, [rango_discretizacion[1]]))\n",
        "            # print(f\"\\t Columna : {columna} \\n Puntos de Corte : \\n {puntos_corte}\")\n",
        "            df_discretizado[f'{columna}'] = pd.cut(df[columna], bins=puntos_corte, labels=range(len(puntos_corte)-1))\n",
        "        else:\n",
        "            # Si la columna no es numérica, simplemente copiarla al dataframe resultante\n",
        "            df_discretizado[columna] = df[columna]\n",
        "            \n",
        "    return df_discretizado\n",
        "\n",
        "df_discret = discretizar_df_arboles(df.select_dtypes(include=['number']))\n",
        "\n",
        "# Calcular el coeficiente de correlación entre las variables numéricas discretas y la variable objetivo binaria\n",
        "correlaciones_discretas = df_discret.corrwith(df_discret['Tumor type'])\n",
        "\n",
        "# Ordenar las correlaciones de mayor a menor\n",
        "correlaciones_discretas_ordenadas = correlaciones_discretas.abs().sort_values(ascending=False)\n",
        "\n",
        "# Obtener las top 20 variables numéricas discretas con las correlaciones más altas\n",
        "top_20_correlaciones_discretas = correlaciones_discretas_ordenadas.nlargest(20)\n",
        "\n",
        "# Imprimir las top 20 correlaciones\n",
        "print(top_20_correlaciones_discretas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.5.2.4 Método 4 [PAPER] - Variables discretizado (Random forest (n_estimators=250, criterion='gini') + cross validation), variable objetivo binaria --> Correlación "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CancerSEEK Logistic Regression Score: 0.16011521821126884\n",
            "CancerSEEK Test Result: 0.10032455550714223\n",
            "IL-8 (pg/ml): 0.0892343245533053\n",
            "IL-6 (pg/ml): 0.06832820072008074\n",
            "OPN (pg/ml): 0.059120792139012876\n",
            "HGF (pg/ml): 0.04190430644931378\n",
            "CYFRA 21-1 (pg/ml): 0.0389622350146014\n",
            "GDF15 (ng/ml): 0.03771616270368018\n",
            "Prolactin (pg/ml): 0.036723660119006796\n",
            "TGFa (pg/ml): 0.03509116397981573\n",
            "NSE (ng/ml): 0.02216511811777052\n",
            "CA19-9 (U/ml): 0.022153042393356474\n",
            "CA-125 (U/ml): 0.02127492298345869\n",
            "HE4 (pg/ml): 0.019285642050482516\n",
            "sFas (pg/ml): 0.016896473234596154\n",
            "Thrombospondin-2 (pg/ml): 0.0157848630570856\n",
            "Omega score: 0.01566884911588872\n",
            "sEGFR (pg/ml): 0.014660936558307091\n",
            "DKK1 (ng/ml): 0.01417835809212938\n",
            "OPG (ng/ml): 0.010820906632388997\n",
            "G-CSF (pg/ml): 0.010785879153216858\n",
            "CD44 (ng/ml): 0.010611486937910457\n",
            "Myeloperoxidase (ng/ml): 0.009729251590072008\n",
            "sHER2/sEGFR2/sErbB2 (pg/ml): 0.009612473421891617\n",
            "AFP (pg/ml): 0.008814860854754043\n",
            "TIMP-1 (pg/ml): 0.008517105026723216\n",
            "CEA (pg/ml): 0.008212379293061182\n",
            "FGF2 (pg/ml): 0.008069080708753017\n",
            "Galectin-3 (ng/ml): 0.007928487011008015\n",
            "Midkine (pg/ml): 0.007805203265104099\n",
            "TIMP-2 (pg/ml): 0.007689649470517164\n",
            "Kallikrein-6 (pg/ml): 0.0063998241136890704\n",
            "PAR (pg/ml): 0.006235905811073801\n",
            "Mesothelin (ng/ml): 0.006196578094590706\n",
            "Follistatin (pg/ml): 0.006097625315518989\n",
            "sPECAM-1 (pg/ml): 0.0059122548597008535\n",
            "SHBG (nM): 0.005896719128702153\n",
            "Leptin (pg/ml): 0.005314791730514475\n",
            "AXL (pg/ml): 0.005106817009184768\n",
            "Angiopoietin-2 (pg/ml): 0.005046293950890316\n",
            "CA 15-3 (U/ml): 0.004882504945865195\n",
            "Endoglin (pg/ml): 0.004725096674566051\n"
          ]
        }
      ],
      "source": [
        "# Mismo principio del papear : 5-fold cross-validations are run on the random forests of 250 Gini decision trees for 300 times to give the means and standard deviations as visualized on the error bars.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract features (X) and target variable (y)\n",
        "X = df.select_dtypes(include=['number']).drop(columns=['Tumor type']).values  # Features\n",
        "y = df['Tumor type'].values  # Target variable\n",
        "feature_names = df.select_dtypes(include=['number']).drop(columns=['Tumor type']).columns  # Feature names\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=250, criterion='gini')\n",
        "\n",
        "# Train the Random Forest model on the entire dataset\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "\n",
        "# Step 4: Perform Cross-Validation to get impurity decrease for each fold\n",
        "cv_scores = []\n",
        "for train_index, test_index in KFold(n_splits=5, shuffle=True, random_state=42).split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    # Train a model on the training data\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    \n",
        "    # Get impurity decrease for this fold\n",
        "    fold_importances = rf_classifier.feature_importances_\n",
        "    \n",
        "    # Append impurity decrease to the list\n",
        "    cv_scores.append(fold_importances)\n",
        "\n",
        "# Convert list of arrays to a NumPy array\n",
        "cv_scores = np.array(cv_scores)\n",
        "\n",
        "# Calculate mean of feature importances for each feature\n",
        "mean_feature_importances = np.mean(cv_scores, axis=0)\n",
        "\n",
        "# Combine feature names and mean importances\n",
        "feature_importance_pairs = list(zip(feature_names, mean_feature_importances))\n",
        "\n",
        "# Sort features by mean importance (highest to lowest)\n",
        "sorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display feature names and their corresponding importances\n",
        "for feature, importance in sorted_feature_importance_pairs:\n",
        "    print(f\"{feature}: {importance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.5.2.5 Métodos de prueba --> Discretizar uniformemente y por percentiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discretizar_frecuencia_uniforme(data, num_bins):\n",
        "    bins = pd.cut(data, bins=num_bins, labels=False)\n",
        "    return bins\n",
        "\n",
        "def discretizar_percentiles(data, num_bins):\n",
        "    bins = pd.qcut(data, q=num_bins, labels=False, duplicates='drop')\n",
        "    return bins\n",
        "def discretizar_uniforme_prueba_1(df):\n",
        "    df_discretizado_prueba1 = pd.DataFrame()\n",
        "    for columna in df.select_dtypes(include=['number']).columns:\n",
        "            if df[columna].dtype.kind in 'biufc': # (CHULO) Comprueba si el tipo de datos de la columna es numérico ('b' para booleano, 'i' para entero, 'u' para sin signo, 'f' para flotante o 'c' para complejo)\n",
        "                num_bins = int(1 + np.log2(len(df[columna])) + np.log2(np.std(df[columna])))\n",
        "                print(f\" Feature : {columna}, número de bins : {num_bins}\")\n",
        "                df_discretizado_prueba1[columna] = discretizar_frecuencia_uniforme(df[columna], num_bins)\n",
        "            else:\n",
        "                # Si la columna no es numérica, simplemente copiarla al dataframe resultante\n",
        "                df_discretizado_prueba1[columna] = df[columna]\n",
        "\n",
        "    # Calcular el coeficiente de correlación entre las variables numéricas discretas y la variable objetivo binaria\n",
        "    correlaciones_discretas_p1 = df_discretizado_prueba1.corrwith(df_discretizado_prueba1['Tumor type'])\n",
        "\n",
        "    # Ordenar las correlaciones de mayor a menor\n",
        "    correlaciones_discretas_ordenadas_p1 = correlaciones_discretas_p1.abs().sort_values(ascending=False)\n",
        "\n",
        "    # Obtener las top 20 variables numéricas discretas con las correlaciones más altas\n",
        "    top_20_correlaciones_discretas_p1 = correlaciones_discretas_ordenadas_p1.nlargest(20)\n",
        "\n",
        "    # Imprimir las top 20 correlaciones\n",
        "    print(top_20_correlaciones_discretas_p1)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def discretizar_percentiles_prueba_1(df):\n",
        "    df_discretizado_prueba1 = pd.DataFrame()\n",
        "    for columna in df.select_dtypes(include=['number']).columns:\n",
        "        if df[columna].dtype.kind in 'biufc': # Comprueba si el tipo de datos de la columna es numérico\n",
        "            num_bins = int(1 + np.log2(len(df[columna])) + np.log2(np.std(df[columna])))\n",
        "\n",
        "            # Verificar si hay NaNs en los datos originales\n",
        "            if df[columna].isnull().any():\n",
        "                print(f\"Advertencia: La columna '{columna}' contiene valores NaN.\")\n",
        "\n",
        "            # Discretizar solo si no hay NaNs en los datos originales\n",
        "            if not df[columna].isnull().any():\n",
        "                df_discretizado_prueba1[columna] = discretizar_percentiles(df[columna], num_bins)\n",
        "                print(f\"Feature : {columna}, número de bins : {num_bins}\")\n",
        "\n",
        "        else:\n",
        "            # Si la columna no es numérica, simplemente copiarla al dataframe resultante\n",
        "            df_discretizado_prueba1[columna] = df[columna]\n",
        "\n",
        "    print(df_discretizado_prueba1.head(10))\n",
        "\n",
        "    # Verificar si hay NaNs en los datos discretizados\n",
        "    if df_discretizado_prueba1.isnull().any().any():\n",
        "        print(\"Advertencia: Se han generado valores NaN durante la discretización.\")\n",
        "\n",
        "    # Calcular el coeficiente de correlación solo si no hay NaNs en los datos discretizados\n",
        "    if not df_discretizado_prueba1.isnull().any().any():\n",
        "        correlaciones_discretas_p1 = df_discretizado_prueba1.corrwith(df_discretizado_prueba1['Tumor type'])\n",
        "\n",
        "        # Ordenar las correlaciones de mayor a menor\n",
        "        correlaciones_discretas_ordenadas_p1 = correlaciones_discretas_p1.abs().sort_values(ascending=False)\n",
        "\n",
        "        # Obtener las top 20 variables numéricas discretas con las correlaciones más altas\n",
        "        top_20_correlaciones_discretas_p1 = correlaciones_discretas_ordenadas_p1.nlargest(20)\n",
        "\n",
        "        # Imprimir las top 20 correlaciones\n",
        "        print(top_20_correlaciones_discretas_p1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discretizar_uniforme_prueba_1(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# No funciona, muestra todas las corelaciones como NaN\n",
        "discretizar_percentiles_prueba_1(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5.3 Comparación de resultados de information gain\n",
        "\n",
        "- Método 1 - Variables continuas, variable objetivo binaria --> Correlación de Pearson\n",
        "- Método 2 - Variables discretas (KBinsDiscretizer()), variable objetivo binaria --> Correlación \n",
        "- Método 3 - Variables discretizado (Arbol de decisión (max_depth = 15)), variable objetivo binaria --> Correlación\n",
        "\n",
        " ------------- Método 1 ---------------------------------- Método 2 --------------------------- Método 3 -----------\n",
        "\n",
        "|Variable|Valor|Variable|Valor|Variable|Valor|\n",
        "|------------------------|--------------|-----------|-----------|--------------|------------|\n",
        "| OPN (pg/ml)          |                 0.458352 | IL-8 (pg/ml)                 |           0.578037 |OPN (pg/ml)                  |         0.575480\n",
        "Prolactin (pg/ml)       |                0.324378 | OPN (pg/ml)                   |          0.571791 |IL-6 (pg/ml)                  |           0.483620\n",
        "TIMP-1 (pg/ml)          |                0.300539 | IL-6 (pg/ml)                  |          0.480112 |IL-8 (pg/ml)                  |          0.464828\n",
        "GDF15 (ng/ml)           |                0.247428 | GDF15 (ng/ml)                 |          0.474477 |HGF (pg/ml)                |          0.454991\n",
        "HGF (pg/ml)              |               0.242512 | Prolactin (pg/ml)              |         0.452567 |Prolactin (pg/ml)              |         0.453270\n",
        "Myeloperoxidase (ng/ml)  |               0.221877 | HGF (pg/ml)                   |          0.447965 |Omega score                    |        0.378112\n",
        "FGF2 (pg/ml)              |              0.192212 | Omega score                   |          0.363410 |GDF15 (ng/ml)                   |         0.365248\n",
        "IL-6 (pg/ml)              |              0.186625 | Myeloperoxidase (ng/ml)       |          0.344990 |CYFRA 21-1 (pg/ml)         |         0.356245\n",
        "Galectin-3 (ng/ml)        |              0.180836 | sEGFR (pg/ml)                 |          0.320824 |Myeloperoxidase (ng/ml)                 |          0.351481\n",
        "Angiopoietin-2 (pg/ml)     |             0.170233 | CA19-9 (U/ml)                 |          0.311742 |sEGFR (pg/ml)                   |        0.319982\n",
        "OPG (ng/ml)                |             0.147721 | TGFa (pg/ml)                   |         0.302511 |CA-125 (U/ml)                  |          0.312094\n",
        "Omega score                |             0.146759 | TIMP-1 (pg/ml)                |          0.302504 |CEA (pg/ml)                |            0.308045\n",
        "HE4 (pg/ml)                 |            0.139689 | CEA (pg/ml)                    |         0.300193 |TIMP-1 (pg/ml)                  |          0.301340\n",
        "Follistatin (pg/ml)         |            0.137546 | CA-125 (U/ml)                 |         0.295434  |CA19-9 (U/ml)               |          0.266444\n",
        "CEA (pg/ml)                 |            0.126718 | | | Angiopoietin-2 (pg/ml) |0.233881"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PAPER : \"Contrary to the information gain ranking on Table S1, the cancer\n",
        "antigen markers are no longer the top predictive features. Instead, we observe the opposite trend for the\n",
        "purity and accuracy measurements; such a phenomenon exemplifies the underlying complex behavior for\n",
        "cancer detection\"\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
